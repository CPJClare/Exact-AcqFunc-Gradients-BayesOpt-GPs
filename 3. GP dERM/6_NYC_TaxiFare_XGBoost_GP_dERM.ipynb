{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6. NYC_TaxiFare_XGBoost_GP_dERM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: NYC Taxi-Fare Predictor\n",
        "\n",
        "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7PwmXsgZO8D",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "6bc9ba24-8a74-4267-a125-fcc149850ebf"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e0ea7104-011f-4fbc-92ef-37eb5bc0991c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e0ea7104-011f-4fbc-92ef-37eb5bc0991c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"conorc2006\",\"key\":\"c5c5a6382a7d50c022aab991694fc17f\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMwbJ6hjZltI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10c9869-2ae2-4ab5-9e46-d0a20cbc6e4b"
      },
      "source": [
        "## Ensure the kaggle.json file is present:\n",
        "!ls -lha kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 66 Feb 24 12:32 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Pu-UlWZovH"
      },
      "source": [
        "## Next, install the Kaggle API client:\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUOQ4SE7Zuj3"
      },
      "source": [
        "## The Kaggle API Client expects this file to be ~/.kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJcEztjCZxOn"
      },
      "source": [
        "## Permissions' change\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-u4Tmj7ZUD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8da6c02-9710-4119-c854-9233cddc1cb2"
      },
      "source": [
        "!kaggle competitions download -c new-york-city-taxi-fare-prediction"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/960k [00:00<?, ?B/s]\n",
            "100% 960k/960k [00:00<00:00, 64.8MB/s]\n",
            "Downloading GCP-Coupons-Instructions.rtf to /content\n",
            "  0% 0.00/486 [00:00<?, ?B/s]\n",
            "100% 486/486 [00:00<00:00, 1.10MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/335k [00:00<?, ?B/s]\n",
            "100% 335k/335k [00:00<00:00, 117MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "100% 1.55G/1.56G [00:19<00:00, 71.8MB/s]\n",
            "100% 1.56G/1.56G [00:19<00:00, 85.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b3db5d-a045-4df7-d97c-1e3a662725c3"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyGPGO\n",
            "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.5)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Requirement already satisfied: Theano-PyMC in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.2)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (3.11.4)\n",
            "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.11.4)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (3.10.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.2)\n",
            "Requirement already satisfied: semver>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.6.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.5.8)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.18.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n",
            "Building wheels for collected packages: pyGPGO\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19879 sha256=971257dd85de810899a6f30d3d120d0f621f3e1775006d7cd00d305a6891a297\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5d/0b/2160114e2f1b87791c51b66cf07f89831dbb6f49167950316f\n",
            "Successfully built pyGPGO\n",
            "Installing collected packages: pyGPGO\n",
            "Successfully installed pyGPGO-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import norm, t\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.surrogates.tStudentProcess import logpdf\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "\n",
        "df_train =  pd.read_csv('/content/train.csv.zip', nrows = 1_000_000, parse_dates=[\"pickup_datetime\"])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2e2f0cb4-a2e1-4394-9a45-0680b7b57df2"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ef3cca19-a930-450b-92dc-1844cd2c5560\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-06-15 17:26:21.0000001</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2009-06-15 17:26:21+00:00</td>\n",
              "      <td>-73.844311</td>\n",
              "      <td>40.721319</td>\n",
              "      <td>-73.841610</td>\n",
              "      <td>40.712278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-05 16:52:16.0000002</td>\n",
              "      <td>16.9</td>\n",
              "      <td>2010-01-05 16:52:16+00:00</td>\n",
              "      <td>-74.016048</td>\n",
              "      <td>40.711303</td>\n",
              "      <td>-73.979268</td>\n",
              "      <td>40.782004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-08-18 00:35:00.00000049</td>\n",
              "      <td>5.7</td>\n",
              "      <td>2011-08-18 00:35:00+00:00</td>\n",
              "      <td>-73.982738</td>\n",
              "      <td>40.761270</td>\n",
              "      <td>-73.991242</td>\n",
              "      <td>40.750562</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-04-21 04:30:42.0000001</td>\n",
              "      <td>7.7</td>\n",
              "      <td>2012-04-21 04:30:42+00:00</td>\n",
              "      <td>-73.987130</td>\n",
              "      <td>40.733143</td>\n",
              "      <td>-73.991567</td>\n",
              "      <td>40.758092</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-03-09 07:51:00.000000135</td>\n",
              "      <td>5.3</td>\n",
              "      <td>2010-03-09 07:51:00+00:00</td>\n",
              "      <td>-73.968095</td>\n",
              "      <td>40.768008</td>\n",
              "      <td>-73.956655</td>\n",
              "      <td>40.783762</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef3cca19-a930-450b-92dc-1844cd2c5560')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef3cca19-a930-450b-92dc-1844cd2c5560 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef3cca19-a930-450b-92dc-1844cd2c5560');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             key  ...  passenger_count\n",
              "0    2009-06-15 17:26:21.0000001  ...                1\n",
              "1    2010-01-05 16:52:16.0000002  ...                1\n",
              "2   2011-08-18 00:35:00.00000049  ...                2\n",
              "3    2012-04-21 04:30:42.0000001  ...                1\n",
              "4  2010-03-09 07:51:00.000000135  ...                1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9fZujMycFMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725dbed7-f265-47a8-80c3-2d556d3ba909"
      },
      "source": [
        "# Format 'pickup_datetime' variable:\n",
        "\n",
        "df_train['pickup_datetime'] =  pd.to_datetime(df_train['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
        "df_train['pickup_datetime'].head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   2009-06-15 17:26:21+00:00\n",
              "1   2010-01-05 16:52:16+00:00\n",
              "2   2011-08-18 00:35:00+00:00\n",
              "3   2012-04-21 04:30:42+00:00\n",
              "4   2010-03-09 07:51:00+00:00\n",
              "Name: pickup_datetime, dtype: datetime64[ns, UTC]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nReKu62HcVFI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c9aa3c3c-8b25-42d3-aabf-2b9e70f59464"
      },
      "source": [
        "df_train.sort_values(by = 'pickup_datetime').tail() ### June 2015 the final month\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f5b3987e-7a70-4785-9658-4ad228aa8919\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>286276</th>\n",
              "      <td>2015-06-30 23:38:21.0000003</td>\n",
              "      <td>26.5</td>\n",
              "      <td>2015-06-30 23:38:21+00:00</td>\n",
              "      <td>-74.008385</td>\n",
              "      <td>40.711571</td>\n",
              "      <td>-73.884071</td>\n",
              "      <td>40.737385</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955575</th>\n",
              "      <td>2015-06-30 23:45:57.0000003</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2015-06-30 23:45:57+00:00</td>\n",
              "      <td>-74.002342</td>\n",
              "      <td>40.739819</td>\n",
              "      <td>-74.005829</td>\n",
              "      <td>40.745239</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915826</th>\n",
              "      <td>2015-06-30 23:48:35.0000005</td>\n",
              "      <td>30.5</td>\n",
              "      <td>2015-06-30 23:48:35+00:00</td>\n",
              "      <td>-73.983826</td>\n",
              "      <td>40.729546</td>\n",
              "      <td>-73.927917</td>\n",
              "      <td>40.661186</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751350</th>\n",
              "      <td>2015-06-30 23:53:23.0000002</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2015-06-30 23:53:23+00:00</td>\n",
              "      <td>-73.978020</td>\n",
              "      <td>40.757439</td>\n",
              "      <td>-73.980705</td>\n",
              "      <td>40.753544</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>785182</th>\n",
              "      <td>2015-06-30 23:53:49.0000003</td>\n",
              "      <td>7.5</td>\n",
              "      <td>2015-06-30 23:53:49+00:00</td>\n",
              "      <td>-73.959969</td>\n",
              "      <td>40.762405</td>\n",
              "      <td>-73.953064</td>\n",
              "      <td>40.782688</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5b3987e-7a70-4785-9658-4ad228aa8919')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5b3987e-7a70-4785-9658-4ad228aa8919 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5b3987e-7a70-4785-9658-4ad228aa8919');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                key  ...  passenger_count\n",
              "286276  2015-06-30 23:38:21.0000003  ...                5\n",
              "955575  2015-06-30 23:45:57.0000003  ...                1\n",
              "915826  2015-06-30 23:48:35.0000005  ...                2\n",
              "751350  2015-06-30 23:53:23.0000002  ...                1\n",
              "785182  2015-06-30 23:53:49.0000003  ...                1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9j9LnIfcXcX"
      },
      "source": [
        "# Add time variables:\n",
        "\n",
        "df_train['hour'] = df_train['pickup_datetime'].dt.hour\n",
        "df_train['weekday'] = df_train['pickup_datetime'].dt.weekday\n",
        "df_train['month'] = df_train['pickup_datetime'].dt.month\n",
        "df_train['year'] = df_train['pickup_datetime'].dt.year\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVyFZIVIcaj3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ab26b09b-5804-4c65-bac4-67f1dd47071d"
      },
      "source": [
        "df_train = df_train.drop(['pickup_datetime','key'], axis = 1)\n",
        "df_train.head()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-582faded-d6ea-4ee9-99c3-19bb67f51538\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.5</td>\n",
              "      <td>-73.844311</td>\n",
              "      <td>40.721319</td>\n",
              "      <td>-73.841610</td>\n",
              "      <td>40.712278</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16.9</td>\n",
              "      <td>-74.016048</td>\n",
              "      <td>40.711303</td>\n",
              "      <td>-73.979268</td>\n",
              "      <td>40.782004</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.7</td>\n",
              "      <td>-73.982738</td>\n",
              "      <td>40.761270</td>\n",
              "      <td>-73.991242</td>\n",
              "      <td>40.750562</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.7</td>\n",
              "      <td>-73.987130</td>\n",
              "      <td>40.733143</td>\n",
              "      <td>-73.991567</td>\n",
              "      <td>40.758092</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.3</td>\n",
              "      <td>-73.968095</td>\n",
              "      <td>40.768008</td>\n",
              "      <td>-73.956655</td>\n",
              "      <td>40.783762</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-582faded-d6ea-4ee9-99c3-19bb67f51538')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-582faded-d6ea-4ee9-99c3-19bb67f51538 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-582faded-d6ea-4ee9-99c3-19bb67f51538');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   fare_amount  pickup_longitude  pickup_latitude  ...  weekday  month  year\n",
              "0          4.5        -73.844311        40.721319  ...        0      6  2009\n",
              "1         16.9        -74.016048        40.711303  ...        1      1  2010\n",
              "2          5.7        -73.982738        40.761270  ...        3      8  2011\n",
              "3          7.7        -73.987130        40.733143  ...        5      4  2012\n",
              "4          5.3        -73.968095        40.768008  ...        1      3  2010\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVfm-KSqcdVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76146d10-d5ea-4e8f-e37a-4db26fdd8f19"
      },
      "source": [
        "# Remove negative fares and postive outliers:\n",
        "\n",
        "df_train = df_train[df_train.fare_amount>=0]\n",
        "df_train = df_train[df_train.fare_amount<=60]\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 997297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb78c05-edd2-4aab-e798-d0958ed61170"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 997288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUYksJ2cclVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81c2b01-ffc3-4609-ae00-c4171242ead1"
      },
      "source": [
        "# June 2015 NYC taxi data (Wu et al, 2017):\n",
        "\n",
        "df_train = df_train[df_train.month==6]\n",
        "df_train = df_train[df_train.year==2015]\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 11269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "7cd48735-e247-4a3d-e493-d452ec8c4a19"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train[df_train.fare_amount<15].fare_amount.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('June 2015 Fares', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5099a379-7a94-402b-a7c9-6faf5a0bcf0a"
      },
      "source": [
        "y = df_train.fare_amount.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.54,  8.  , 34.  , ...,  4.5 ,  6.5 ,  7.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7834f80e-8319-4d75-9dc8-91a926c9d113"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f9cc84b0-2b7a-4699-8650-9b59299ee728\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>22.54</td>\n",
              "      <td>-74.010483</td>\n",
              "      <td>40.717667</td>\n",
              "      <td>-73.985771</td>\n",
              "      <td>40.660366</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>8.00</td>\n",
              "      <td>-74.010727</td>\n",
              "      <td>40.710091</td>\n",
              "      <td>-73.998100</td>\n",
              "      <td>40.722900</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>34.00</td>\n",
              "      <td>-73.974899</td>\n",
              "      <td>40.751095</td>\n",
              "      <td>-73.908546</td>\n",
              "      <td>40.881878</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>8.00</td>\n",
              "      <td>-73.961784</td>\n",
              "      <td>40.759579</td>\n",
              "      <td>-73.978943</td>\n",
              "      <td>40.772606</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>11.50</td>\n",
              "      <td>-73.957443</td>\n",
              "      <td>40.761703</td>\n",
              "      <td>-73.973236</td>\n",
              "      <td>40.787079</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9cc84b0-2b7a-4699-8650-9b59299ee728')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9cc84b0-2b7a-4699-8650-9b59299ee728 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9cc84b0-2b7a-4699-8650-9b59299ee728');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     fare_amount  pickup_longitude  pickup_latitude  ...  weekday  month  year\n",
              "31         22.54        -74.010483        40.717667  ...        6      6  2015\n",
              "310         8.00        -74.010727        40.710091  ...        5      6  2015\n",
              "314        34.00        -73.974899        40.751095  ...        1      6  2015\n",
              "321         8.00        -73.961784        40.759579  ...        0      6  2015\n",
              "486        11.50        -73.957443        40.761703  ...        0      6  2015\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f7ff5102-93d4-4d5e-fb9f-41128d8c7a13"
      },
      "source": [
        "X = df_train.drop(['fare_amount', 'month', 'year'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-54de683f-01a9-440e-b32e-edb3d255a84a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>hour</th>\n",
              "      <th>weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-74.010483</td>\n",
              "      <td>40.717667</td>\n",
              "      <td>-73.985771</td>\n",
              "      <td>40.660366</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>-74.010727</td>\n",
              "      <td>40.710091</td>\n",
              "      <td>-73.998100</td>\n",
              "      <td>40.722900</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>-73.974899</td>\n",
              "      <td>40.751095</td>\n",
              "      <td>-73.908546</td>\n",
              "      <td>40.881878</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>-73.961784</td>\n",
              "      <td>40.759579</td>\n",
              "      <td>-73.978943</td>\n",
              "      <td>40.772606</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>-73.957443</td>\n",
              "      <td>40.761703</td>\n",
              "      <td>-73.973236</td>\n",
              "      <td>40.787079</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54de683f-01a9-440e-b32e-edb3d255a84a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54de683f-01a9-440e-b32e-edb3d255a84a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54de683f-01a9-440e-b32e-edb3d255a84a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     pickup_longitude  pickup_latitude  ...  hour  weekday\n",
              "31         -74.010483        40.717667  ...    21        6\n",
              "310        -74.010727        40.710091  ...     9        5\n",
              "314        -73.974899        40.751095  ...    23        1\n",
              "321        -73.961784        40.759579  ...    21        0\n",
              "486        -73.957443        40.761703  ...    19        0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util_approx = 'ExpectedRegret'\n",
        "util_exact = 'dERM_GP'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.667\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 3"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJsNX29c_xA"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "cov_func = squaredExponential()\n",
        "\n",
        "def kronDelta(X, Xstar):                     # Kronecker's Delta method\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\n",
        "\n",
        "def se(X, Xstar, sigmaf, l, sigman):         # S.E. kernel method\n",
        "    return sigmaf * np.exp(-0.5 * cdist(X, Xstar) ** 2 / l ** 2) + sigman * kronDelta(X, Xstar)\n",
        "\n",
        "def delta(X, Xstar):                         # Distance between training X and test Xstar vectors\n",
        "    return (X - Xstar)\n",
        "   \n",
        "def der_covmat(X, Xstar, sigmaf, l, sigman): # Covariance matrix derivative terms (i.e. exact, first-order)\n",
        "    nx = len(X)\n",
        "    ny = len(Xstar)\n",
        "    return np.round(np.array([(delta(np.atleast_2d(i), np.atleast_2d(j))[0] * se(np.atleast_2d(i), np.atleast_2d(j), sigmaf, l, sigman)[0]).sum() for (i, j) in itertools.product(X, Xstar)]).reshape(nx, ny), 8)\n",
        "\n",
        "class dGaussianProcess(GaussianProcess):    # Via inheritance, also optimises hyperparameters when opt = TRUE\n",
        "    \n",
        "    def AcqGrad(self, Xstar):               # Method returning exact, first-order derivatives of the GP's posterior mean and standard deviation\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = self.covfunc.K(self.X, Xstar).T\n",
        "        \n",
        "        dKstar = der_covmat(self.X, Xstar, self.covfunc.sigmaf, self.covfunc.l, self.covfunc.sigman).T\n",
        "        alpha_Kstar = np.dot(np.linalg.inv(self.K + (self.covfunc.sigman**2) * np.eye(len(self.X))), Kstar.T)\n",
        "        \n",
        "        dm = np.dot(dKstar, self.alpha)\n",
        "        ds = -2 * np.dot(dKstar, alpha_Kstar)\n",
        "        \n",
        "        return dm, ds\n",
        "        "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 0\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJMhL70fdHz_"
      },
      "source": [
        "class Acquisition_new(Acquisition):    \n",
        "    def __init__(self, mode, eps=eps, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'ExpectedRegret': self.ExpectedRegret,\n",
        "            'dERM_GP': self.dERM_GP\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def ExpectedRegret(self, tau, mean, std):\n",
        "        z = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        return (mean - y_global_orig) * norm.cdf(z) + std * norm.pdf(z)[0]\n",
        "\n",
        "\n",
        "    def dERM_GP(self, tau, mean, std, ds, dm):\n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        gamma_h = (mean - tau) / (std + self.eps)\n",
        "        dsdx = ds / (2 * (std + self.eps))\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "        \n",
        "        f = (std + self.eps) * (gamma * norm.cdf(gamma) + norm.pdf(gamma))\n",
        "        df1 = f / (std + self.eps) * dsdx \n",
        "        df2 = (std + self.eps) * norm.cdf(gamma) * dmdx\n",
        "        df = (df1 + df2)[0]\n",
        "        df_arr = []\n",
        "\n",
        "        for j in range(0, dim):\n",
        "          df_arr.append(df)\n",
        "        return f, np.asarray(df_arr).transpose()\n",
        "        \n",
        "    def d_eval(self, tau, mean, std, ds, dm):\n",
        "    \n",
        "        return self.f(tau, mean, std, ds, dm, **self.params)\n",
        "        "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAK8N5bwfuJ7"
      },
      "source": [
        "## GPGO_multi: Multistart changed to variable 'n_start_AcqFunc'\n",
        "\n",
        "class GPGO_multi(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def _optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        \n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        if self.n_jobs == 1:\n",
        "            for index, start_point in enumerate(start_points_arr):\n",
        "                res = minimize(self._acqWrapper, x0=start_point, method=method,\n",
        "                               bounds=self.parameter_range)\n",
        "                x_best[index], f_best[index] = res.x, np.atleast_1d(res.fun)[0]\n",
        "        else:\n",
        "            opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self._acqWrapper,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "            x_best = np.array([res.x for res in opt])\n",
        "            f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S422jNLsdIMm"
      },
      "source": [
        "## dGPGO:\n",
        "\n",
        "grad = 1\n",
        "\n",
        "class dGPGO(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfunc,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "\n",
        "        return x_best, f_best\n",
        "    \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self.logger._printInit(self)\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self.logger._printCurrent(self)\n",
        "\n",
        "    def acqfunc(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f, -df * grad\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6f6540-c74b-4b41-fa1d-6c26fa83905d"
      },
      "source": [
        "start_approx = time.time()\n",
        "start_approx"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1645706201.616742"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc25a0a-98d3-4796-decb-541f47be4213"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_approx_1 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_1 = GPGO_multi(surrogate_approx_1, Acquisition_new(util_approx), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "approx_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_1 = approx_1.getResult()[0]\n",
        "params_approx_1['max_depth'] = int(params_approx_1['max_depth'])\n",
        "params_approx_1['min_child_weight'] = int(params_approx_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_approx_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_approx_1 = xgb.train(params_approx_1, dX_approx_train1)\n",
        "pred_approx_1 = model_approx_1.predict(dX_approx_test1)\n",
        "\n",
        "rmse_approx_1 = np.sqrt(mean_squared_error(pred_approx_1, y_test1))\n",
        "rmse_approx_1"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [5.48813504 7.15189366 8.         0.92897281 8.         0.48128932]. \t  -0.5626915313589341 \t -0.46143572360276275\n",
            "init   \t [ 6.45894113  4.37587211 11.          0.52835649 13.          0.44509737]. \t  -0.5772881365468763 \t -0.46143572360276275\n",
            "init   \t [ 7.91725038  5.2889492  13.          0.6963924  14.          0.40365654]. \t  -0.5870544636272766 \t -0.46143572360276275\n",
            "init   \t [ 6.48171872  3.6824154  10.          0.88907838 16.          0.88307853]. \t  -0.46143572360276275 \t -0.46143572360276275\n",
            "init   \t [4.73608045 8.00910752 8.         0.83943977 8.         0.67592892]. \t  -0.5051288806760134 \t -0.46143572360276275\n",
            "1      \t [ 0.96098408  9.76459465  7.          0.75481219 17.          0.64436097]. \t  -0.5149059967458438 \t -0.46143572360276275\n",
            "2      \t [ 0.25662718  2.07470075 13.          0.86522109  6.          0.51721788]. \t  -0.5609779944418447 \t -0.46143572360276275\n",
            "3      \t [ 9.79573252  1.48478088 12.          0.94838058  2.          0.62192116]. \t  -0.5054179573676033 \t -0.46143572360276275\n",
            "4      \t [ 0.62636003  2.41901704  5.          0.63031433 15.          0.7957752 ]. \t  -0.5075878491448556 \t -0.46143572360276275\n",
            "5      \t [1.50934897 3.30267036 6.         0.75645266 2.         0.16196677]. \t  -0.6730063390911496 \t -0.46143572360276275\n",
            "6      \t [8.51808583 9.62395074 8.         0.60054801 1.         0.9981946 ]. \t  -0.4825618268670315 \t -0.46143572360276275\n",
            "7      \t [ 9.82999135  9.82247777  7.          0.69029769 18.          0.32011265]. \t  -0.5962489471366647 \t -0.46143572360276275\n",
            "8      \t [ 0.44571111  9.13283596 10.          0.7789937   1.          0.17342299]. \t  -0.6758674152983395 \t -0.46143572360276275\n",
            "9      \t [9.15647011 0.95123437 9.         0.70846698 8.         0.21386088]. \t  -0.6731394995355806 \t -0.46143572360276275\n",
            "10     \t [ 1.96496846  0.2988114  14.          0.81090497 13.          0.73057001]. \t  -0.46331696604270556 \t -0.46143572360276275\n",
            "11     \t [ 0.27653157  6.60338596 14.          0.97720044 12.          0.7490783 ]. \t  \u001b[92m-0.45756183431510866\u001b[0m \t -0.45756183431510866\n",
            "12     \t [ 9.2626588   6.61763595 13.          0.5647657   8.          0.88069027]. \t  -0.47709042961004594 \t -0.45756183431510866\n",
            "13     \t [ 5.72317016  8.9486974  14.          0.8917696  19.          0.5025906 ]. \t  -0.5627757357340591 \t -0.45756183431510866\n",
            "14     \t [ 6.07241549  9.39130505 13.          0.92732273  4.          0.89714856]. \t  \u001b[92m-0.44909528461553966\u001b[0m \t -0.44909528461553966\n",
            "15     \t [ 9.61554311  1.21538233  6.          0.81124244 13.          0.27856607]. \t  -0.6710935853736035 \t -0.44909528461553966\n",
            "16     \t [ 2.88789937  0.86885671 13.          0.91265131 19.          0.89339396]. \t  -0.4536607483476357 \t -0.44909528461553966\n",
            "17     \t [8.92113335 3.82853306 5.         0.69106787 3.         0.87547395]. \t  -0.4902059108431949 \t -0.44909528461553966\n",
            "18     \t [3.2356921  0.01782017 8.         0.7922415  9.         0.17131332]. \t  -0.6719586373645567 \t -0.44909528461553966\n",
            "19     \t [ 0.81613888  6.61027976  9.          0.6283712  12.          0.45647669]. \t  -0.5692300920679163 \t -0.44909528461553966\n",
            "20     \t [ 1.44727249  4.8949721  14.          0.69589636  1.          0.97822332]. \t  -0.46374563204707747 \t -0.44909528461553966\n",
            "21     \t [0.57290039 5.56719442 5.         0.67279386 7.         0.53348581]. \t  -0.5895638008235796 \t -0.44909528461553966\n",
            "22     \t [ 5.23613335  7.27640954  6.          0.99641005 16.          0.208195  ]. \t  -0.6701550204042249 \t -0.44909528461553966\n",
            "23     \t [ 4.38793869  1.41142449  7.          0.86080475 19.          0.94489508]. \t  -0.4777873033950965 \t -0.44909528461553966\n",
            "24     \t [ 9.40616888  0.20590479 13.          0.50408138 13.          0.1229284 ]. \t  -0.6773911354249613 \t -0.44909528461553966\n",
            "25     \t [ 0.08469059  7.41533336 14.          0.70266774 17.          0.58674994]. \t  -0.5015730938813691 \t -0.44909528461553966\n",
            "26     \t [ 5.77665295  1.35161366 14.61183468  0.5         1.          1.        ]. \t  \u001b[92m-0.4447314497276613\u001b[0m \t -0.4447314497276613\n",
            "27     \t [ 9.27681941  7.73458868  6.          0.79893762 12.          0.43190703]. \t  -0.579892224440537 \t -0.4447314497276613\n",
            "28     \t [ 6.32121666  8.48993661 15.          0.5        11.34447089  1.        ]. \t  -0.4457393265625916 \t -0.4447314497276613\n",
            "29     \t [10.          4.87685279 12.29291936  0.68868168 20.          1.        ]. \t  \u001b[92m-0.4420900522308651\u001b[0m \t -0.4420900522308651\n",
            "30     \t [ 5.16085178 10.         10.03891165  1.         12.87537734  1.        ]. \t  \u001b[92m-0.43228055320323494\u001b[0m \t -0.43228055320323494\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.825774204956716"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f5ea4e-5436-4706-e44c-9b0e0d3aae5c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_approx_2 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_2 = GPGO_multi(surrogate_approx_2, Acquisition_new(util_approx), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "approx_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_2 = approx_2.getResult()[0]\n",
        "params_approx_2['max_depth'] = int(params_approx_2['max_depth'])\n",
        "params_approx_2['min_child_weight'] = int(params_approx_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_approx_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_approx_2 = xgb.train(params_approx_2, dX_approx_train2)\n",
        "pred_approx_2 = model_approx_2.predict(dX_approx_test2)\n",
        "\n",
        "rmse_approx_2 = np.sqrt(mean_squared_error(pred_approx_2, y_test2))\n",
        "rmse_approx_2"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]. \t  -0.5147867600449749 \t -0.4765694615523879\n",
            "init   \t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]. \t  -0.4765694615523879 \t -0.4765694615523879\n",
            "init   \t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]. \t  -0.4946399399702889 \t -0.4765694615523879\n",
            "init   \t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]. \t  -0.5884370816585467 \t -0.4765694615523879\n",
            "init   \t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]. \t  -0.584982798458911 \t -0.4765694615523879\n",
            "1      \t [9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]. \t  -0.47692913742153503 \t -0.4765694615523879\n",
            "2      \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]. \t  \u001b[92m-0.42932966844762255\u001b[0m \t -0.42932966844762255\n",
            "3      \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]. \t  -0.5235565502085555 \t -0.42932966844762255\n",
            "4      \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]. \t  -0.5840366351865409 \t -0.42932966844762255\n",
            "5      \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]. \t  -0.5185020925938802 \t -0.42932966844762255\n",
            "6      \t [ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]. \t  -0.49484140351085004 \t -0.42932966844762255\n",
            "7      \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]. \t  -0.5305156688763031 \t -0.42932966844762255\n",
            "8      \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]. \t  -0.6754055457447411 \t -0.42932966844762255\n",
            "9      \t [ 4.57706999  8.33565192 11.          0.6188546   7.          0.54017925]. \t  -0.5200991055645933 \t -0.42932966844762255\n",
            "10     \t [2.51973603 9.74135258 5.         0.69633293 8.         0.1952065 ]. \t  -0.6747225214274138 \t -0.42932966844762255\n",
            "11     \t [ 8.6330652   9.62113163 11.          0.50355876 13.          0.80231095]. \t  -0.4776294844111158 \t -0.42932966844762255\n",
            "12     \t [ 9.73810496  3.32466832  6.          0.67226447 13.          0.93959986]. \t  \u001b[92m-0.42816051226467755\u001b[0m \t -0.42816051226467755\n",
            "13     \t [ 7.86086296  9.53235807  5.          0.78700181 16.          0.22516618]. \t  -0.6752838593350439 \t -0.42816051226467755\n",
            "14     \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]. \t  -0.5119371184217966 \t -0.42816051226467755\n",
            "15     \t [ 8.6950785   0.99410218 13.          0.66782851 17.          0.9323419 ]. \t  \u001b[92m-0.4078190519864161\u001b[0m \t -0.4078190519864161\n",
            "16     \t [9.70003354 0.07825472 7.         0.79315177 1.         0.1995403 ]. \t  -0.6760869491796593 \t -0.4078190519864161\n",
            "17     \t [ 9.61885664  9.78589131 14.          0.8903706   1.          0.14094172]. \t  -0.6776999663731892 \t -0.4078190519864161\n",
            "18     \t [ 5.64670451  8.85432647 14.          0.95807607 10.          0.35707694]. \t  -0.5833806584348222 \t -0.4078190519864161\n",
            "19     \t [ 0.34964202  6.10551304 14.          0.81887518  8.          0.79373024]. \t  -0.46222390225012616 \t -0.4078190519864161\n",
            "20     \t [0.62273619 1.29124124 6.         0.81123451 8.         0.42451055]. \t  -0.5869340733116714 \t -0.4078190519864161\n",
            "21     \t [8.31655833 8.60825609 5.         0.85952394 8.         0.28298607]. \t  -0.6763184433475262 \t -0.4078190519864161\n",
            "22     \t [ 0.51057799  7.98632671  8.          0.8773209  13.          0.97148281]. \t  \u001b[92m-0.40355178385918367\u001b[0m \t -0.40355178385918367\n",
            "23     \t [ 1.14769908  9.46854425 10.          0.58022432 19.          0.87672068]. \t  -0.4067785949580019 \t -0.40355178385918367\n",
            "24     \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]. \t  -0.5934955971475885 \t -0.40355178385918367\n",
            "25     \t [ 2.55390985  1.0433692  14.          0.50090092 18.          0.75542228]. \t  -0.47232898855681815 \t -0.40355178385918367\n",
            "26     \t [ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]. \t  \u001b[92m-0.40183965244004105\u001b[0m \t -0.40183965244004105\n",
            "27     \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]. \t  -0.47327191349354314 \t -0.40183965244004105\n",
            "28     \t [ 4.11831219  1.06523616 12.          0.63008078 16.          0.53873389]. \t  -0.5223430672538264 \t -0.40183965244004105\n",
            "29     \t [7.32389195 0.24180135 7.58336952 1.         9.41322918 0.1       ]. \t  -0.6372999638687372 \t -0.40183965244004105\n",
            "30     \t [4.59810674 1.74332022 5.         0.67256858 5.         0.56916425]. \t  -0.5368509986096546 \t -0.40183965244004105\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.67160405397526"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc353bab-2e75-48c6-c03a-e619458f162e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_approx_3 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_3 = GPGO_multi(surrogate_approx_3, Acquisition_new(util_approx), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "approx_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_3 = approx_3.getResult()[0]\n",
        "params_approx_3['max_depth'] = int(params_approx_3['max_depth'])\n",
        "params_approx_3['min_child_weight'] = int(params_approx_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_approx_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_approx_3 = xgb.train(params_approx_3, dX_approx_train3)\n",
        "pred_approx_3 = model_approx_3.predict(dX_approx_test3)\n",
        "\n",
        "rmse_approx_3 = np.sqrt(mean_squared_error(pred_approx_3, y_test3))\n",
        "rmse_approx_3"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]. \t  -0.7165783188757435 \t -0.6409647951145182\n",
            "init   \t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]. \t  -0.7204431346766296 \t -0.6409647951145182\n",
            "init   \t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]. \t  -0.6409647951145182 \t -0.6409647951145182\n",
            "init   \t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]. \t  -0.7214290072967551 \t -0.6409647951145182\n",
            "init   \t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]. \t  -0.6558401549443296 \t -0.6409647951145182\n",
            "1      \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]. \t  -0.652766690473656 \t -0.6409647951145182\n",
            "2      \t [ 7.69133691  0.25025283 10.          0.52101543 12.          0.10383979]. \t  -0.7148542073105238 \t -0.6409647951145182\n",
            "3      \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]. \t  -0.7211360280437672 \t -0.6409647951145182\n",
            "4      \t [ 4.06522402  9.52384028  5.          0.68629723 13.          0.87617671]. \t  \u001b[92m-0.49349103668500904\u001b[0m \t -0.49349103668500904\n",
            "5      \t [3.68953475 2.95525094 5.         0.6894371  8.         0.99869195]. \t  \u001b[92m-0.4907212254462726\u001b[0m \t -0.4907212254462726\n",
            "6      \t [9.87422438 6.71772444 5.         0.63287091 5.         0.98483042]. \t  -0.4976483799089211 \t -0.4907212254462726\n",
            "7      \t [ 9.93262812  9.85709216 10.          0.50642105 13.          0.46421679]. \t  -0.6562876473129815 \t -0.4907212254462726\n",
            "8      \t [2.6278521  1.48922274 6.         0.63082487 1.         0.15934029]. \t  -0.7204252076734962 \t -0.4907212254462726\n",
            "9      \t [ 2.90369752  3.11254054  6.          0.81932406 16.          0.23613277]. \t  -0.7197796376906721 \t -0.4907212254462726\n",
            "10     \t [ 4.43398983  0.1775468  13.          0.67757521 18.          0.85307217]. \t  -0.5210602575470441 \t -0.4907212254462726\n",
            "11     \t [ 1.02918863  9.32189805 13.          0.88333707  1.          0.86998588]. \t  \u001b[92m-0.45190108244647254\u001b[0m \t -0.45190108244647254\n",
            "12     \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]. \t  -0.4804793139396266 \t -0.45190108244647254\n",
            "13     \t [ 9.38226635  4.01107902 14.          0.88645966 17.          0.87374815]. \t  -0.47315524396225167 \t -0.45190108244647254\n",
            "14     \t [0.86375274 7.69964496 8.         0.67182269 1.         0.12474838]. \t  -0.7214117317911921 \t -0.45190108244647254\n",
            "15     \t [ 9.51708919  0.58391709 12.          0.88753946  6.          0.24646931]. \t  -0.7209982167226172 \t -0.45190108244647254\n",
            "16     \t [ 1.04436425  9.32284009 12.          0.59300158  7.          0.9522161 ]. \t  -0.46635534339044915 \t -0.45190108244647254\n",
            "17     \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]. \t  -0.5237424802632007 \t -0.45190108244647254\n",
            "18     \t [ 8.50267404  2.17033522  6.          0.50604942 19.          0.82390736]. \t  -0.537393179824783 \t -0.45190108244647254\n",
            "19     \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]. \t  -0.7096913524170247 \t -0.45190108244647254\n",
            "20     \t [8.97398363 2.41897649 7.         0.81773512 8.         0.28324604]. \t  -0.7196336258157527 \t -0.45190108244647254\n",
            "21     \t [7.66786548 9.63378327 6.         0.67341055 1.         0.88994805]. \t  -0.4780947471860609 \t -0.45190108244647254\n",
            "22     \t [ 8.78137031  9.07562973 14.          0.81240153 17.          0.56901188]. \t  -0.65831579458922 \t -0.45190108244647254\n",
            "23     \t [ 6.64966697  8.448574    5.          0.65443865 19.          0.53636799]. \t  -0.6532290988903501 \t -0.45190108244647254\n",
            "24     \t [ 0.04997226  0.57243486  5.          0.9748128  12.          0.24835402]. \t  -0.7195165728779045 \t -0.45190108244647254\n",
            "25     \t [8.10694301 4.17712073 5.         0.80634144 1.         0.66433498]. \t  -0.6304028686629369 \t -0.45190108244647254\n",
            "26     \t [0.33454906 4.8293531  6.         0.75998498 5.         0.78354586]. \t  -0.5258469010005469 \t -0.45190108244647254\n",
            "27     \t [ 0.50161196  6.73842363  5.          0.62422734 11.          0.68966684]. \t  -0.6257414714048529 \t -0.45190108244647254\n",
            "28     \t [10.          0.          7.44923706  0.5         3.7434012   0.4906844 ]. \t  -0.6587480255568455 \t -0.45190108244647254\n",
            "29     \t [0.33715852 0.41541443 9.         0.53276138 6.         0.26454539]. \t  -0.7162762004378923 \t -0.45190108244647254\n",
            "30     \t [ 0.50646974  6.72570721  7.          0.51798099 18.          0.75487674]. \t  -0.530130659897067 \t -0.45190108244647254\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.649527586702978"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d7956d-fb92-49ba-b29b-3ac5d6a8a950"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_approx_4 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_4 = GPGO_multi(surrogate_approx_4, Acquisition_new(util_approx), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "approx_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_4 = approx_4.getResult()[0]\n",
        "params_approx_4['max_depth'] = int(params_approx_4['max_depth'])\n",
        "params_approx_4['min_child_weight'] = int(params_approx_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_approx_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_approx_4 = xgb.train(params_approx_4, dX_approx_train4)\n",
        "pred_approx_4 = model_approx_4.predict(dX_approx_test4)\n",
        "\n",
        "rmse_approx_4 = np.sqrt(mean_squared_error(pred_approx_4, y_test4))\n",
        "rmse_approx_4"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]. \t  -0.5993772224326677 \t -0.4983304913999733\n",
            "init   \t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]. \t  -0.6069567430422909 \t -0.4983304913999733\n",
            "init   \t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]. \t  -0.7139334307278753 \t -0.4983304913999733\n",
            "init   \t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]. \t  -0.4983304913999733 \t -0.4983304913999733\n",
            "init   \t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]. \t  -0.7091576633146701 \t -0.4983304913999733\n",
            "1      \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]. \t  -0.7189305559932541 \t -0.4983304913999733\n",
            "2      \t [ 0.90674561  6.32290535 11.          0.94435129  1.          0.40346185]. \t  -0.659235838187788 \t -0.4983304913999733\n",
            "3      \t [ 7.37481669  1.69273565 11.          0.93066167  4.          0.26673965]. \t  -0.71175266619209 \t -0.4983304913999733\n",
            "4      \t [ 5.92074392  7.05411368 14.          0.56897417 18.          0.54051446]. \t  -0.6311960055652813 \t -0.4983304913999733\n",
            "5      \t [ 5.20011211  1.13096048 14.          0.976894    9.          0.7504566 ]. \t  -0.5890525510373767 \t -0.4983304913999733\n",
            "6      \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]. \t  -0.7111637954440517 \t -0.4983304913999733\n",
            "7      \t [0.85218043 8.76361565 5.         0.95141234 5.         0.18096954]. \t  -0.7117027216773544 \t -0.4983304913999733\n",
            "8      \t [3.86538132 1.78391589 5.         0.96297978 2.         0.70393647]. \t  -0.6123381001992111 \t -0.4983304913999733\n",
            "9      \t [ 3.4576838   6.55355466  6.          0.72569372 18.          0.65149337]. \t  -0.6118718217318108 \t -0.4983304913999733\n",
            "10     \t [ 9.3450382   8.82768787 11.          0.76868692  7.          0.8502727 ]. \t  -0.5942242759669181 \t -0.4983304913999733\n",
            "11     \t [ 9.65147322  0.33792642 12.          0.92327424 17.          0.84355403]. \t  -0.5882916778627522 \t -0.4983304913999733\n",
            "12     \t [ 5.62120366  6.01550411 10.          0.77467151 12.          0.88994317]. \t  -0.502188309278306 \t -0.4983304913999733\n",
            "13     \t [0.69118951 0.05924245 6.         0.53870729 9.         0.9249957 ]. \t  -0.517996124617491 \t -0.4983304913999733\n",
            "14     \t [ 0.51187296  7.77314276 11.          0.63389119 15.          0.16589245]. \t  -0.7108031779087576 \t -0.4983304913999733\n",
            "15     \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]. \t  -0.6194547986660568 \t -0.4983304913999733\n",
            "16     \t [ 1.59376327  9.3637724   5.          0.56698742 13.          0.29635446]. \t  -0.6589347550965012 \t -0.4983304913999733\n",
            "17     \t [ 5.61148944  3.45544791  5.          0.91442364 14.          0.13327309]. \t  -0.713301488457895 \t -0.4983304913999733\n",
            "18     \t [6.18461978 1.56321293 5.         0.63345598 8.         0.11755092]. \t  -0.7106668018948927 \t -0.4983304913999733\n",
            "19     \t [ 4.48345626  0.23255296 14.          0.72333385 14.          0.12095971]. \t  -0.7121558919593358 \t -0.4983304913999733\n",
            "20     \t [ 7.97119076  8.60858359  5.          0.89580835 19.          0.23533594]. \t  -0.7136095797815774 \t -0.4983304913999733\n",
            "21     \t [ 2.5544629   5.29923202 14.          0.70981162  6.          0.74924795]. \t  -0.596475574503418 \t -0.4983304913999733\n",
            "22     \t [ 2.56416717  0.15610938 12.          0.9617952   2.          0.74332064]. \t  -0.5934264209641744 \t -0.4983304913999733\n",
            "23     \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]. \t  -0.7139636713851948 \t -0.4983304913999733\n",
            "24     \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]. \t  -0.524958204283032 \t -0.4983304913999733\n",
            "25     \t [ 2.07051041  1.52366516 10.          0.69512439 11.          0.21098416]. \t  -0.7130630485402061 \t -0.4983304913999733\n",
            "26     \t [4.98189219 9.19296718 7.         0.90407002 2.         0.86829268]. \t  -0.5080233187811342 \t -0.4983304913999733\n",
            "27     \t [ 9.91261585  5.61754498 12.          0.63287563 16.          0.73825779]. \t  -0.5947175646134379 \t -0.4983304913999733\n",
            "28     \t [ 9.328728    0.19822705 12.          0.75281018 11.          0.88551078]. \t  -0.5025340927558902 \t -0.4983304913999733\n",
            "29     \t [ 0.98351466  3.488579   13.59151427  0.50729483 13.768731    0.50609436]. \t  -0.6293682520064305 \t -0.4983304913999733\n",
            "30     \t [ 1.72078221  1.85338202  5.          0.88677213 19.          0.37340399]. \t  -0.6587324919539517 \t -0.4983304913999733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.04081354533672"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62963ac-12fa-4918-ede7-4b1d1c7f5e55"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_approx_5 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_5 = GPGO_multi(surrogate_approx_5, Acquisition_new(util_approx), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "approx_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_5 = approx_5.getResult()[0]\n",
        "params_approx_5['max_depth'] = int(params_approx_5['max_depth'])\n",
        "params_approx_5['min_child_weight'] = int(params_approx_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_approx_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_approx_5 = xgb.train(params_approx_5, dX_approx_train5)\n",
        "pred_approx_5 = model_approx_5.predict(dX_approx_test5)\n",
        "\n",
        "rmse_approx_5 = np.sqrt(mean_squared_error(pred_approx_5, y_test5))\n",
        "rmse_approx_5"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]. \t  -0.5323233521622429 \t -0.4868347596133297\n",
            "init   \t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]. \t  -0.4868347596133297 \t -0.4868347596133297\n",
            "init   \t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]. \t  -0.586475577548452 \t -0.4868347596133297\n",
            "init   \t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]. \t  -0.633609225551848 \t -0.4868347596133297\n",
            "init   \t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]. \t  -0.6326249738244012 \t -0.4868347596133297\n",
            "1      \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]. \t  -0.5882279171378358 \t -0.4868347596133297\n",
            "2      \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]. \t  -0.6326090413479479 \t -0.4868347596133297\n",
            "3      \t [ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]. \t  -0.5345515814760515 \t -0.4868347596133297\n",
            "4      \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]. \t  -0.63240536298746 \t -0.4868347596133297\n",
            "5      \t [ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]. \t  \u001b[92m-0.465844229386987\u001b[0m \t -0.465844229386987\n",
            "6      \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]. \t  -0.5654109525719464 \t -0.465844229386987\n",
            "7      \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]. \t  -0.5157271802459567 \t -0.465844229386987\n",
            "8      \t [ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]. \t  \u001b[92m-0.43338395515567535\u001b[0m \t -0.43338395515567535\n",
            "9      \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]. \t  -0.6323995483897046 \t -0.43338395515567535\n",
            "10     \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]. \t  -0.44834224855405436 \t -0.43338395515567535\n",
            "11     \t [ 9.88162042  4.98501997  7.          0.71514689 11.          0.88825005]. \t  -0.4486026878328516 \t -0.43338395515567535\n",
            "12     \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]. \t  -0.47422527111773516 \t -0.43338395515567535\n",
            "13     \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]. \t  -0.5043962477805882 \t -0.43338395515567535\n",
            "14     \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]. \t  -0.463354057486635 \t -0.43338395515567535\n",
            "15     \t [ 0.69381482  7.09764326  5.          0.79260103 13.          0.36148114]. \t  -0.5865660625355444 \t -0.43338395515567535\n",
            "16     \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]. \t  -0.5641284322471574 \t -0.43338395515567535\n",
            "17     \t [ 6.56637184  9.40150707  8.          0.97457564 11.          0.85712178]. \t  -0.4660785797917318 \t -0.43338395515567535\n",
            "18     \t [ 9.73541293  8.42044427 14.          0.53390677 16.          0.10576782]. \t  -0.6335354580978965 \t -0.43338395515567535\n",
            "19     \t [ 0.72954578  7.46073967  5.          0.5        17.89485214  0.53902386]. \t  -0.5715186260641276 \t -0.43338395515567535\n",
            "20     \t [ 1.1246472   2.50523123 12.          0.73015278  7.          0.68499751]. \t  -0.49641414079446805 \t -0.43338395515567535\n",
            "21     \t [ 2.198289    3.67796949 10.          0.90046315 19.          0.21147767]. \t  -0.6328870147791277 \t -0.43338395515567535\n",
            "22     \t [ 6.66341284  6.4082082  14.02398067  0.85749646  5.62989293  0.61577549]. \t  -0.49710196773109966 \t -0.43338395515567535\n",
            "23     \t [ 0.14337166  3.83051228 13.          0.67084469 13.          0.27589041]. \t  -0.6332186654719546 \t -0.43338395515567535\n",
            "24     \t [5.80891976 6.22815082 5.         0.60791835 2.         0.19304152]. \t  -0.633210503254255 \t -0.43338395515567535\n",
            "25     \t [10.         10.          5.          1.         12.98334776  1.        ]. \t  -0.44633299281625105 \t -0.43338395515567535\n",
            "26     \t [ 7.30373317  0.         14.56233773  0.5         8.7309529   0.54320595]. \t  -0.5455564639323065 \t -0.43338395515567535\n",
            "27     \t [ 6.72997514  0.60780575 14.          0.89835235 18.          0.97859978]. \t  -0.437571922818659 \t -0.43338395515567535\n",
            "28     \t [ 6.60924517  5.47852198 12.          0.79248846 15.          0.38107311]. \t  -0.5649283414532984 \t -0.43338395515567535\n",
            "29     \t [ 6.50667582  4.95331312 14.46849836  1.         20.          0.1       ]. \t  -0.6025254341225523 \t -0.43338395515567535\n",
            "30     \t [ 0.47608975  0.         12.70946538  1.          1.          0.1       ]. \t  -0.6113585009454721 \t -0.43338395515567535\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.826369186532375"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c0323d-13a3-418a-f177-2137631594ed"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_approx_6 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_6 = GPGO_multi(surrogate_approx_6, Acquisition_new(util_approx), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "approx_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_6 = approx_6.getResult()[0]\n",
        "params_approx_6['max_depth'] = int(params_approx_6['max_depth'])\n",
        "params_approx_6['min_child_weight'] = int(params_approx_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_approx_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_approx_6 = xgb.train(params_approx_6, dX_approx_train6)\n",
        "pred_approx_6 = model_approx_6.predict(dX_approx_test6)\n",
        "\n",
        "rmse_approx_6 = np.sqrt(mean_squared_error(pred_approx_6, y_test6))\n",
        "rmse_approx_6"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]. \t  -0.5719256944003751 \t -0.5405445954433028\n",
            "init   \t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]. \t  -0.6047098118480896 \t -0.5405445954433028\n",
            "init   \t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]. \t  -0.5405445954433028 \t -0.5405445954433028\n",
            "init   \t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]. \t  -0.5678490550489279 \t -0.5405445954433028\n",
            "init   \t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]. \t  -0.6145131146454834 \t -0.5405445954433028\n",
            "1      \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]. \t  -0.691031094679315 \t -0.5405445954433028\n",
            "2      \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]. \t  -0.6923819935110469 \t -0.5405445954433028\n",
            "3      \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]. \t  -0.6304772827355849 \t -0.5405445954433028\n",
            "4      \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]. \t  -0.6918663560679601 \t -0.5405445954433028\n",
            "5      \t [ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]. \t  \u001b[92m-0.476867228842187\u001b[0m \t -0.476867228842187\n",
            "6      \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]. \t  -0.6072185980939964 \t -0.476867228842187\n",
            "7      \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]. \t  -0.6950359736000904 \t -0.476867228842187\n",
            "8      \t [ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]. \t  -0.483135560233687 \t -0.476867228842187\n",
            "9      \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]. \t  -0.6357205486843573 \t -0.476867228842187\n",
            "10     \t [ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]. \t  \u001b[92m-0.46984611815932203\u001b[0m \t -0.46984611815932203\n",
            "11     \t [ 9.49126464  2.25575335  7.          0.89398566 13.          0.76947203]. \t  -0.5406134678021616 \t -0.46984611815932203\n",
            "12     \t [ 1.03080361  6.70895845  7.          0.73336025 19.          0.31104879]. \t  -0.6191870905906407 \t -0.46984611815932203\n",
            "13     \t [0.2400873  1.61429062 5.         0.72296529 1.         0.1077861 ]. \t  -0.6912677535150268 \t -0.46984611815932203\n",
            "14     \t [9.89801174 9.77563967 9.         0.68555662 3.         0.83921118]. \t  -0.5428995234335529 \t -0.46984611815932203\n",
            "15     \t [ 0.50127522  1.94924928 11.          0.89270197 19.          0.91286914]. \t  \u001b[92m-0.4669311845911867\u001b[0m \t -0.4669311845911867\n",
            "16     \t [6.55109905 2.29203942 6.         0.7269974  8.         0.87997636]. \t  -0.4859637689299886 \t -0.4669311845911867\n",
            "17     \t [ 3.50815226  9.13058689  5.          0.80778314 15.          0.92212261]. \t  -0.49222778043308246 \t -0.4669311845911867\n",
            "18     \t [0.75190021 2.99821111 7.         0.73112778 8.         0.11979456]. \t  -0.691424380511367 \t -0.4669311845911867\n",
            "19     \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]. \t  -0.692321289717216 \t -0.4669311845911867\n",
            "20     \t [ 0.08217017  5.74710834 10.          0.94165761  5.          0.50303435]. \t  -0.6043436168396833 \t -0.4669311845911867\n",
            "21     \t [4.70222718 7.76335614 9.         0.92367012 9.         0.28724782]. \t  -0.6151742953973676 \t -0.4669311845911867\n",
            "22     \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]. \t  \u001b[92m-0.4643061698441667\u001b[0m \t -0.4643061698441667\n",
            "23     \t [ 9.64840425  4.78632167 14.          0.99048758  8.          0.60934972]. \t  -0.560188356880304 \t -0.4643061698441667\n",
            "24     \t [ 2.99692198  8.36222876 10.          0.68219036  2.          0.34753861]. \t  -0.6175339526603174 \t -0.4643061698441667\n",
            "25     \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]. \t  -0.48611573402244906 \t -0.4643061698441667\n",
            "26     \t [ 1.67558043  3.52622775 11.48632496  0.75526761 10.83747746  0.1       ]. \t  -0.6933064108715309 \t -0.4643061698441667\n",
            "27     \t [ 1.79878043  2.49249815 12.64577692  0.5         1.          0.39985991]. \t  -0.6316325567760778 \t -0.4643061698441667\n",
            "28     \t [ 9.53788062  3.60144894 11.00232786  0.5        16.31576243  0.40524244]. \t  -0.6288614934269726 \t -0.4643061698441667\n",
            "29     \t [ 4.53888743  8.66146858 14.28004771  0.5         7.66514018  1.        ]. \t  -0.48013934497832034 \t -0.4643061698441667\n",
            "30     \t [1.73594604 9.55863667 8.         0.6088793  6.         0.86433392]. \t  -0.48156444515001906 \t -0.4643061698441667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.666730740909481"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e3516d-d8ea-4764-b058-1324dd25bdd5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_approx_7 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_7 = GPGO_multi(surrogate_approx_7, Acquisition_new(util_approx), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "approx_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_7 = approx_7.getResult()[0]\n",
        "params_approx_7['max_depth'] = int(params_approx_7['max_depth'])\n",
        "params_approx_7['min_child_weight'] = int(params_approx_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_approx_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_approx_7 = xgb.train(params_approx_7, dX_approx_train7)\n",
        "pred_approx_7 = model_approx_7.predict(dX_approx_test7)\n",
        "\n",
        "rmse_approx_7 = np.sqrt(mean_squared_error(pred_approx_7, y_test7))\n",
        "rmse_approx_7"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]. \t  -0.44500885348659536 \t -0.44173641078261416\n",
            "init   \t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]. \t  -0.4488374676936292 \t -0.44173641078261416\n",
            "init   \t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]. \t  -0.5669653799025498 \t -0.44173641078261416\n",
            "init   \t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]. \t  -0.4661284696195417 \t -0.44173641078261416\n",
            "init   \t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]. \t  -0.44173641078261416 \t -0.44173641078261416\n",
            "1      \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]. \t  -0.5720117286339644 \t -0.44173641078261416\n",
            "2      \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]. \t  -0.5040023079321674 \t -0.44173641078261416\n",
            "3      \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]. \t  -0.4697830241358748 \t -0.44173641078261416\n",
            "4      \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]. \t  -0.4882732220224809 \t -0.44173641078261416\n",
            "5      \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]. \t  -0.568100519925974 \t -0.44173641078261416\n",
            "6      \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]. \t  -0.44744611331217216 \t -0.44173641078261416\n",
            "7      \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]. \t  -0.6941989633599238 \t -0.44173641078261416\n",
            "8      \t [ 1.95327375  0.09413692  7.          0.63967551 19.          0.52105045]. \t  -0.5139990320068838 \t -0.44173641078261416\n",
            "9      \t [5.70513125 8.30861013 6.         0.98680016 3.         0.16134411]. \t  -0.68192707596936 \t -0.44173641078261416\n",
            "10     \t [ 0.25030147  5.86047618  7.          0.62148035 15.          0.70956246]. \t  -0.49234467840129764 \t -0.44173641078261416\n",
            "11     \t [ 6.35215     9.71205645 11.          0.67733044  6.          0.80174708]. \t  -0.45650768247894014 \t -0.44173641078261416\n",
            "12     \t [9.93412004 7.01728008 6.         0.60790736 8.         0.46475011]. \t  -0.5281857371452437 \t -0.44173641078261416\n",
            "13     \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]. \t  -0.49177211555059996 \t -0.44173641078261416\n",
            "14     \t [ 5.05369665  2.67147005  5.          0.51290284 10.          0.64085   ]. \t  -0.5141066990730631 \t -0.44173641078261416\n",
            "15     \t [ 0.30180848  0.36339665 10.          0.99951435 11.          0.54137142]. \t  -0.48320505631505073 \t -0.44173641078261416\n",
            "16     \t [ 1.46233253  4.21473795 12.          0.82588689  8.          0.69701346]. \t  -0.4617035154312951 \t -0.44173641078261416\n",
            "17     \t [ 0.08258912  2.04682383 12.          0.59206459 18.          0.58057909]. \t  -0.47949559740392883 \t -0.44173641078261416\n",
            "18     \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]. \t  -0.44594195084588784 \t -0.44173641078261416\n",
            "19     \t [ 8.02008913  6.8951761  13.          0.63880909 19.          0.69330995]. \t  -0.4851967971772767 \t -0.44173641078261416\n",
            "20     \t [ 9.02606866  9.9399456   5.          0.69325176 13.          0.80731892]. \t  -0.48390390130528715 \t -0.44173641078261416\n",
            "21     \t [ 9.27376043  7.79309168 10.          0.72898828  1.          0.60101244]. \t  -0.4807641306108092 \t -0.44173641078261416\n",
            "22     \t [ 2.21548548  9.34072297 10.          0.96109934 13.          0.7636836 ]. \t  -0.4515743659972008 \t -0.44173641078261416\n",
            "23     \t [ 7.84623251  5.26126936  9.4249521   1.         11.54299419  0.1       ]. \t  -0.6323237603343299 \t -0.44173641078261416\n",
            "24     \t [0.70527907 5.59255728 5.         0.86863619 1.         0.35457337]. \t  -0.5667766789352335 \t -0.44173641078261416\n",
            "25     \t [ 3.10690541  8.2550526  14.          0.5876892  10.          0.54629175]. \t  -0.5023701082007483 \t -0.44173641078261416\n",
            "26     \t [ 5.03032449  1.46993678 12.          0.54826603 16.          0.88093043]. \t  -0.46556482001154686 \t -0.44173641078261416\n",
            "27     \t [9.91546913 0.35662679 7.         0.87706909 8.         0.31009443]. \t  -0.5699297548076715 \t -0.44173641078261416\n",
            "28     \t [ 5.2904658   8.22056718  5.          0.61065019 19.          0.97301687]. \t  -0.48431230364593975 \t -0.44173641078261416\n",
            "29     \t [ 9.92745389  2.10791379  6.          0.91867901 19.          0.37494465]. \t  -0.5713292909071361 \t -0.44173641078261416\n",
            "30     \t [0.37391981 2.40019589 5.         0.63958121 7.         0.86382806]. \t  -0.4789632866798484 \t -0.44173641078261416\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.499924380514474"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90b23dec-6822-4d72-ac5a-77a055d5dcf3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_approx_8 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_8 = GPGO_multi(surrogate_approx_8, Acquisition_new(util_approx), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "approx_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_8 = approx_8.getResult()[0]\n",
        "params_approx_8['max_depth'] = int(params_approx_8['max_depth'])\n",
        "params_approx_8['min_child_weight'] = int(params_approx_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_approx_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_approx_8 = xgb.train(params_approx_8, dX_approx_train8)\n",
        "pred_approx_8 = model_approx_8.predict(dX_approx_test8)\n",
        "\n",
        "rmse_approx_8 = np.sqrt(mean_squared_error(pred_approx_8, y_test8))\n",
        "rmse_approx_8"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]. \t  -0.5450023023990902 \t -0.47785117417083445\n",
            "init   \t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]. \t  -0.48415390639601685 \t -0.47785117417083445\n",
            "init   \t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]. \t  -0.5514374023096014 \t -0.47785117417083445\n",
            "init   \t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]. \t  -0.509390123714371 \t -0.47785117417083445\n",
            "init   \t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]. \t  -0.47785117417083445 \t -0.47785117417083445\n",
            "1      \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]. \t  -0.4933129789895931 \t -0.47785117417083445\n",
            "2      \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]. \t  -0.6339615084112526 \t -0.47785117417083445\n",
            "3      \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]. \t  -0.5297996778038847 \t -0.47785117417083445\n",
            "4      \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]. \t  -0.5527447722333402 \t -0.47785117417083445\n",
            "5      \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]. \t  -0.5047189705784817 \t -0.47785117417083445\n",
            "6      \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]. \t  -0.4848490795565376 \t -0.47785117417083445\n",
            "7      \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]. \t  -0.5564925838622898 \t -0.47785117417083445\n",
            "8      \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]. \t  -0.5530199153286809 \t -0.47785117417083445\n",
            "9      \t [ 0.45485069  5.92046568 13.          0.54575641 15.          0.3753516 ]. \t  -0.5549518005921394 \t -0.47785117417083445\n",
            "10     \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]. \t  -0.4791797818281145 \t -0.47785117417083445\n",
            "11     \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]. \t  -0.635838370822804 \t -0.47785117417083445\n",
            "12     \t [3.47378168 0.90493309 7.         0.70332668 6.         0.717685  ]. \t  -0.501005699748404 \t -0.47785117417083445\n",
            "13     \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]. \t  -0.6330775313057753 \t -0.47785117417083445\n",
            "14     \t [1.36072521 8.96337054 5.         0.74382165 2.         0.12580076]. \t  -0.6310296426785355 \t -0.47785117417083445\n",
            "15     \t [ 3.32794564  9.35873285 13.          0.95404271 12.          0.46503428]. \t  -0.5317909356674381 \t -0.47785117417083445\n",
            "16     \t [ 6.35979139  1.00897047 10.          0.55338934  9.          0.8992107 ]. \t  -0.48522152812259406 \t -0.47785117417083445\n",
            "17     \t [0.26711089 1.47965823 5.         0.94483199 1.         0.67844469]. \t  -0.5241359942934816 \t -0.47785117417083445\n",
            "18     \t [ 8.81884199  0.29557486 11.          0.94612367  2.          0.80082225]. \t  \u001b[92m-0.4752232906149384\u001b[0m \t -0.4752232906149384\n",
            "19     \t [ 4.10272358  0.68972827 14.          0.96902802  1.          0.19814279]. \t  -0.6329380619232359 \t -0.4752232906149384\n",
            "20     \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]. \t  -0.4812223540836058 \t -0.4752232906149384\n",
            "21     \t [8.49304258 9.45420615 6.         0.52298498 5.         0.36186114]. \t  -0.5693257561055802 \t -0.4752232906149384\n",
            "22     \t [ 0.76637948  1.6718521   5.          0.89180884 15.          0.76035097]. \t  -0.5096944757591124 \t -0.4752232906149384\n",
            "23     \t [ 6.06290916  9.61279022 14.04964342  0.5         2.10143797  0.1       ]. \t  -0.6402927064756617 \t -0.4752232906149384\n",
            "24     \t [ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]. \t  -0.4805143253081433 \t -0.4752232906149384\n",
            "25     \t [ 2.00363843  0.25557305 13.          0.79852696 19.          0.41982126]. \t  -0.5500644701753457 \t -0.4752232906149384\n",
            "26     \t [ 5.22462526  0.         15.          0.5        15.16451416  0.1       ]. \t  -0.6383015530476221 \t -0.4752232906149384\n",
            "27     \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]. \t  -0.5440457259258048 \t -0.4752232906149384\n",
            "28     \t [ 1.06330602  9.84698732  5.          0.70744161 15.          0.6986094 ]. \t  -0.5340764790757249 \t -0.4752232906149384\n",
            "29     \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]. \t  -0.5059919280994952 \t -0.4752232906149384\n",
            "30     \t [ 6.56126126  1.25177273  5.          0.60554055 11.          0.89113205]. \t  -0.5069378077097564 \t -0.4752232906149384\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.5410977772226735"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03354809-5530-4445-b307-f1db2cae16b5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_approx_9 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_9 = GPGO_multi(surrogate_approx_9, Acquisition_new(util_approx), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "approx_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_9 = approx_9.getResult()[0]\n",
        "params_approx_9['max_depth'] = int(params_approx_9['max_depth'])\n",
        "params_approx_9['min_child_weight'] = int(params_approx_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_approx_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_approx_9 = xgb.train(params_approx_9, dX_approx_train9)\n",
        "pred_approx_9 = model_approx_9.predict(dX_approx_test9)\n",
        "\n",
        "rmse_approx_9 = np.sqrt(mean_squared_error(pred_approx_9, y_test9))\n",
        "rmse_approx_9"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]. \t  -0.6545930802207814 \t -0.4584168030068045\n",
            "init   \t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]. \t  -0.7166132091943936 \t -0.4584168030068045\n",
            "init   \t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]. \t  -0.4584168030068045 \t -0.4584168030068045\n",
            "init   \t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]. \t  -0.48839211091816903 \t -0.4584168030068045\n",
            "init   \t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]. \t  -0.46354466019784824 \t -0.4584168030068045\n",
            "1      \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]. \t  -0.7145926373770018 \t -0.4584168030068045\n",
            "2      \t [ 8.16285902  8.43489929  9.          0.96605421 10.          0.79940153]. \t  -0.48073960577713015 \t -0.4584168030068045\n",
            "3      \t [ 3.67545472  4.78145311 14.          0.63123486 17.          0.4863889 ]. \t  -0.4908200532861475 \t -0.4584168030068045\n",
            "4      \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]. \t  -0.489212631501365 \t -0.4584168030068045\n",
            "5      \t [ 1.86381009  9.16177979  5.          0.9344438  17.          0.81379931]. \t  -0.4912030349766601 \t -0.4584168030068045\n",
            "6      \t [ 2.35563756  1.41309797  5.          0.61127581 14.          0.85229383]. \t  -0.4988542621089159 \t -0.4584168030068045\n",
            "7      \t [ 0.65024006  0.20015298 14.          0.90298726 13.          0.95798937]. \t  \u001b[92m-0.4476685066942845\u001b[0m \t -0.4476685066942845\n",
            "8      \t [ 9.89935012  1.80411649  9.          0.642097   16.          0.9768379 ]. \t  -0.4801384356428805 \t -0.4476685066942845\n",
            "9      \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]. \t  -0.47774087957331524 \t -0.4476685066942845\n",
            "10     \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]. \t  -0.48879793709138014 \t -0.4476685066942845\n",
            "11     \t [2.63920029 2.84662126 8.         0.81372528 9.         0.70958016]. \t  -0.481015707138382 \t -0.4476685066942845\n",
            "12     \t [1.13081555 8.89608809 5.         0.68242063 1.         0.25767085]. \t  -0.7144450806724659 \t -0.4476685066942845\n",
            "13     \t [ 8.01493798  7.33950965 10.          0.50609192 18.          0.9957267 ]. \t  -0.48185656494615825 \t -0.4476685066942845\n",
            "14     \t [ 8.08392893  1.91862949 14.          0.6384648  17.          0.1890016 ]. \t  -0.715142540640623 \t -0.4476685066942845\n",
            "15     \t [ 4.11263305  1.10911111  7.          0.99254999 19.          0.81125017]. \t  -0.49028030505090714 \t -0.4476685066942845\n",
            "16     \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]. \t  -0.4919610294417671 \t -0.4476685066942845\n",
            "17     \t [ 3.27325644  1.7873584  14.          0.93313351  7.          0.76979578]. \t  -0.4628858988004011 \t -0.4476685066942845\n",
            "18     \t [ 9.00084206  1.85673124 10.          0.98011614  2.          0.25530052]. \t  -0.7164537739094682 \t -0.4476685066942845\n",
            "19     \t [ 1.5375546   6.06327242 13.          0.75086004 12.          0.81590341]. \t  -0.4754995179849649 \t -0.4476685066942845\n",
            "20     \t [ 4.49089064  7.04035213 10.          0.71518167  6.          0.54341653]. \t  -0.48344393889093185 \t -0.4476685066942845\n",
            "21     \t [0.93748744 2.66462057 5.         0.77408223 4.         0.19936714]. \t  -0.7160819872924715 \t -0.4476685066942845\n",
            "22     \t [ 4.99585633  9.84423212 13.          0.58601629 15.          0.62308889]. \t  -0.4890091779718368 \t -0.4476685066942845\n",
            "23     \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]. \t  -0.6320298567588886 \t -0.4476685066942845\n",
            "24     \t [ 3.74834789  9.93946975 10.          0.52571565  1.          0.6614516 ]. \t  -0.4870655352258547 \t -0.4476685066942845\n",
            "25     \t [8.16570029 0.40949439 8.         0.67704692 8.         0.10446623]. \t  -0.7143816307896056 \t -0.4476685066942845\n",
            "26     \t [ 2.6116157   9.96913447 13.          0.85452594  8.          0.87833359]. \t  \u001b[92m-0.4475083824683078\u001b[0m \t -0.4475083824683078\n",
            "27     \t [10.          1.45746223 14.74097812  0.62778659  2.          0.59521258]. \t  -0.4896308892846604 \t -0.4475083824683078\n",
            "28     \t [0.06433695 6.57876132 6.         0.81327092 7.         0.85975218]. \t  -0.46583285163728017 \t -0.4475083824683078\n",
            "29     \t [5.63583903 8.76359675 5.         0.6782879  2.         0.67940326]. \t  -0.4937074420630406 \t -0.4475083824683078\n",
            "30     \t [ 6.14078962  2.31372054 11.          0.9240952  13.          0.361681  ]. \t  -0.6258949059114924 \t -0.4475083824683078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.635844534922092"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990e49db-d462-4897-f2b4-4c45c8d1d83f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_approx_10 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_10 = GPGO_multi(surrogate_approx_10, Acquisition_new(util_approx), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "approx_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_10 = approx_10.getResult()[0]\n",
        "params_approx_10['max_depth'] = int(params_approx_10['max_depth'])\n",
        "params_approx_10['min_child_weight'] = int(params_approx_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_approx_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_approx_10 = xgb.train(params_approx_10, dX_approx_train10)\n",
        "pred_approx_10 = model_approx_10.predict(dX_approx_test10)\n",
        "\n",
        "rmse_approx_10 = np.sqrt(mean_squared_error(pred_approx_10, y_test10))\n",
        "rmse_approx_10"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]. \t  -0.7090674967614334 \t -0.4737745634473992\n",
            "init   \t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]. \t  -0.4737745634473992 \t -0.4737745634473992\n",
            "init   \t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]. \t  -0.4755277191484213 \t -0.4737745634473992\n",
            "init   \t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]. \t  -0.48811859212530173 \t -0.4737745634473992\n",
            "init   \t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]. \t  -0.7057210222477256 \t -0.4737745634473992\n",
            "1      \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]. \t  \u001b[92m-0.46336171949490257\u001b[0m \t -0.46336171949490257\n",
            "2      \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]. \t  -0.5661654396843121 \t -0.46336171949490257\n",
            "3      \t [ 2.20772511  4.37663949 11.          0.65455258  3.          0.57545511]. \t  -0.47392585264437637 \t -0.46336171949490257\n",
            "4      \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]. \t  -0.5586941817481679 \t -0.46336171949490257\n",
            "5      \t [ 3.75041373  9.81989522 14.          0.71370546 14.          0.97207881]. \t  \u001b[92m-0.4452927087494185\u001b[0m \t -0.4452927087494185\n",
            "6      \t [ 9.8195229   7.4353827   6.          0.61370759 10.          0.85798549]. \t  -0.4774086118126461 \t -0.4452927087494185\n",
            "7      \t [8.82521763 9.96779345 8.         0.82356907 1.         0.3598298 ]. \t  -0.6084949388262864 \t -0.4452927087494185\n",
            "8      \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]. \t  -0.5719468802009684 \t -0.4452927087494185\n",
            "9      \t [ 7.94637587  1.09220418 14.          0.87360164  2.          0.44305882]. \t  -0.5655799355515964 \t -0.4452927087494185\n",
            "10     \t [ 3.19739287  9.35044843 14.          0.99107667  1.          0.93375799]. \t  \u001b[92m-0.43231064565707733\u001b[0m \t -0.43231064565707733\n",
            "11     \t [5.00762913 1.53619492 9.         0.56892944 8.         0.96567366]. \t  -0.46105702925642705 \t -0.43231064565707733\n",
            "12     \t [2.84027732 0.55785004 6.         0.52193432 3.         0.45391352]. \t  -0.583838358053568 \t -0.43231064565707733\n",
            "13     \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]. \t  -0.7078125731141747 \t -0.43231064565707733\n",
            "14     \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]. \t  -0.7058594746055183 \t -0.43231064565707733\n",
            "15     \t [ 9.72703693  6.521415    7.          0.50173837 17.          0.28475777]. \t  -0.712139282553683 \t -0.43231064565707733\n",
            "16     \t [ 0.79209787  5.77655365 11.          0.54385846 15.          0.82704826]. \t  -0.4677570207234939 \t -0.43231064565707733\n",
            "17     \t [ 0.10132441  5.76858385  6.          0.51450173 13.          0.7107056 ]. \t  -0.511324047499245 \t -0.43231064565707733\n",
            "18     \t [ 8.50962734  5.65812077 12.          0.90655791  3.          0.57438618]. \t  -0.47465003449423443 \t -0.43231064565707733\n",
            "19     \t [ 2.35513569  1.93380053  5.          0.59075001 11.          0.47226935]. \t  -0.5812864776092782 \t -0.43231064565707733\n",
            "20     \t [ 8.21917736  9.97884934 12.          0.94944316  6.          0.39898081]. \t  -0.6055387493463118 \t -0.43231064565707733\n",
            "21     \t [ 7.22258807  6.23065969 12.          0.56635095 13.          0.86573749]. \t  -0.46161814155237757 \t -0.43231064565707733\n",
            "22     \t [ 9.43678992  0.9880373   6.          0.64942758 10.          0.75777997]. \t  -0.48440674681729484 \t -0.43231064565707733\n",
            "23     \t [ 4.47829069  7.43510935  7.          0.67276165 10.          0.2175314 ]. \t  -0.7094943624920795 \t -0.43231064565707733\n",
            "24     \t [ 5.51729858  7.6511781  12.          0.76854013 17.          0.79510362]. \t  -0.4575071851041896 \t -0.43231064565707733\n",
            "25     \t [4.66195218 5.96776172 7.         0.68043003 1.         0.11094684]. \t  -0.7112331451390336 \t -0.43231064565707733\n",
            "26     \t [ 9.76455747  9.71578983 14.          0.66293675 18.          0.1137209 ]. \t  -0.711142014680554 \t -0.43231064565707733\n",
            "27     \t [ 6.33995605  4.86053965 12.          0.92988931  7.          0.51826086]. \t  -0.5586584946009204 \t -0.43231064565707733\n",
            "28     \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]. \t  -0.7046801666998048 \t -0.43231064565707733\n",
            "29     \t [10.          7.37416092  7.53814958  0.5         4.61941259  0.1       ]. \t  -0.7123898913339612 \t -0.43231064565707733\n",
            "30     \t [ 7.48523074  9.74348988  9.          0.66544612 14.          0.64199162]. \t  -0.4812784019833874 \t -0.43231064565707733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.576218981652964"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7d5f8f-25d8-4b7b-8def-ee2b70a13f82"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_approx_11 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_11 = GPGO_multi(surrogate_approx_11, Acquisition_new(util_approx), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "approx_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_11 = approx_11.getResult()[0]\n",
        "params_approx_11['max_depth'] = int(params_approx_11['max_depth'])\n",
        "params_approx_11['min_child_weight'] = int(params_approx_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_approx_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_approx_11 = xgb.train(params_approx_11, dX_approx_train11)\n",
        "pred_approx_11 = model_approx_11.predict(dX_approx_test11)\n",
        "\n",
        "rmse_approx_11 = np.sqrt(mean_squared_error(pred_approx_11, y_test11))\n",
        "rmse_approx_11"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]. \t  -0.5922349044250168 \t -0.49898623219170346\n",
            "init   \t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]. \t  -0.49898623219170346 \t -0.49898623219170346\n",
            "init   \t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]. \t  -0.5404544349803458 \t -0.49898623219170346\n",
            "init   \t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]. \t  -0.5108833748715963 \t -0.49898623219170346\n",
            "init   \t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]. \t  -0.5545314939891337 \t -0.49898623219170346\n",
            "1      \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]. \t  -0.5252491147925742 \t -0.49898623219170346\n",
            "2      \t [ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]. \t  \u001b[92m-0.47168134756234376\u001b[0m \t -0.47168134756234376\n",
            "3      \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]. \t  -0.6079929413869166 \t -0.47168134756234376\n",
            "4      \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]. \t  -0.6940792524812075 \t -0.47168134756234376\n",
            "5      \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]. \t  -0.5917636590409376 \t -0.47168134756234376\n",
            "6      \t [ 3.67323902  7.86608025  9.          0.6017103  12.          0.8976084 ]. \t  -0.48417119344714443 \t -0.47168134756234376\n",
            "7      \t [ 8.8168337   8.37959662 14.          0.86429866 15.          0.72516241]. \t  -0.4849992543698768 \t -0.47168134756234376\n",
            "8      \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]. \t  -0.5804776283328665 \t -0.47168134756234376\n",
            "9      \t [ 4.65266155  1.51144578 13.          0.9981878   8.          0.76538736]. \t  -0.4762746893996949 \t -0.47168134756234376\n",
            "10     \t [ 9.96434657  9.7457538   7.          0.51716335 13.          0.80468719]. \t  -0.5247207840192685 \t -0.47168134756234376\n",
            "11     \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]. \t  -0.6899450978623416 \t -0.47168134756234376\n",
            "12     \t [ 8.75969772  9.81259093 13.          0.73915202  9.          0.12048735]. \t  -0.6894993636607551 \t -0.47168134756234376\n",
            "13     \t [ 3.5878055   9.95198178 13.          0.88500021 19.          0.14789414]. \t  -0.6866833714007038 \t -0.47168134756234376\n",
            "14     \t [ 8.71522337  2.64896453  8.          0.8880663  13.          0.19932467]. \t  -0.6865009211934154 \t -0.47168134756234376\n",
            "15     \t [0.61700864 1.88368662 5.         0.7080512  1.         0.20173876]. \t  -0.6917985842631214 \t -0.47168134756234376\n",
            "16     \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]. \t  -0.4964959167917179 \t -0.47168134756234376\n",
            "17     \t [4.68258101 8.96288202 5.         0.97630328 6.         0.39227084]. \t  -0.5913707400607938 \t -0.47168134756234376\n",
            "18     \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]. \t  -0.5472760809270729 \t -0.47168134756234376\n",
            "19     \t [ 8.36668527  4.27683386  5.          0.69635843 18.10656698  1.        ]. \t  -0.4990359880006562 \t -0.47168134756234376\n",
            "20     \t [9.22875209 9.1986098  9.         0.90439491 3.         0.27523226]. \t  -0.6865002905691453 \t -0.47168134756234376\n",
            "21     \t [ 4.20382838  8.11840794 14.          0.97060995 11.          0.52636944]. \t  -0.571300068106338 \t -0.47168134756234376\n",
            "22     \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]. \t  -0.5035711766098606 \t -0.47168134756234376\n",
            "23     \t [ 9.97716226  3.28825714 13.          0.55185778 13.          0.23012169]. \t  -0.6936577667491837 \t -0.47168134756234376\n",
            "24     \t [0.35274751 4.60721825 8.         0.98940661 8.         0.99370153]. \t  \u001b[92m-0.47039294880610416\u001b[0m \t -0.47039294880610416\n",
            "25     \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]. \t  -0.6952750251234912 \t -0.47039294880610416\n",
            "26     \t [1.64455594 0.         5.         0.5        5.62669631 1.        ]. \t  -0.504900262867256 \t -0.47039294880610416\n",
            "27     \t [ 4.17264203  2.30078668  6.61018839  0.52587798 19.36088067  0.19290674]. \t  -0.6978447998332197 \t -0.47039294880610416\n",
            "28     \t [ 1.9144183   6.0983121   9.          0.90157057 18.          0.30859982]. \t  -0.5749672570847622 \t -0.47039294880610416\n",
            "29     \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]. \t  -0.4848121108917608 \t -0.47039294880610416\n",
            "30     \t [4.8041921  4.06620309 5.         0.94317975 9.         0.20395595]. \t  -0.6877076361943525 \t -0.47039294880610416\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.001524750828825"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8659d87-1a07-4a9c-b8cd-1a746e69eb50"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_approx_12 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_12 = GPGO_multi(surrogate_approx_12, Acquisition_new(util_approx), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "approx_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_12 = approx_12.getResult()[0]\n",
        "params_approx_12['max_depth'] = int(params_approx_12['max_depth'])\n",
        "params_approx_12['min_child_weight'] = int(params_approx_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_approx_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_approx_12 = xgb.train(params_approx_12, dX_approx_train12)\n",
        "pred_approx_12 = model_approx_12.predict(dX_approx_test12)\n",
        "\n",
        "rmse_approx_12 = np.sqrt(mean_squared_error(pred_approx_12, y_test12))\n",
        "rmse_approx_12"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]. \t  -0.6840535846029854 \t -0.5032799564384677\n",
            "init   \t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]. \t  -0.6305456734924068 \t -0.5032799564384677\n",
            "init   \t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]. \t  -0.6144010633484512 \t -0.5032799564384677\n",
            "init   \t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]. \t  -0.5032799564384677 \t -0.5032799564384677\n",
            "init   \t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]. \t  -0.6516977337723864 \t -0.5032799564384677\n",
            "1      \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]. \t  -0.5227768283895782 \t -0.5032799564384677\n",
            "2      \t [ 7.57473716  9.63637997 12.          0.83444517 10.          0.18761713]. \t  -0.6734912089891107 \t -0.5032799564384677\n",
            "3      \t [ 9.04517621  0.80881017 13.          0.96890904  5.          0.75400021]. \t  \u001b[92m-0.4806753007187634\u001b[0m \t -0.4806753007187634\n",
            "4      \t [ 2.73241117  0.55778587 14.          0.70282167 15.          0.8966204 ]. \t  \u001b[92m-0.4777748953827142\u001b[0m \t -0.4777748953827142\n",
            "5      \t [ 6.66970674  0.03985694  6.          0.76922453 11.          0.18327615]. \t  -0.6744989447281609 \t -0.4777748953827142\n",
            "6      \t [ 1.23389285  0.85357459 13.          0.93854198  3.          0.52598214]. \t  -0.6188016111425869 \t -0.4777748953827142\n",
            "7      \t [ 0.57203639  5.0857779   9.          0.68290949 10.          0.94408458]. \t  -0.4796925982784261 \t -0.4777748953827142\n",
            "8      \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]. \t  -0.658514740722844 \t -0.4777748953827142\n",
            "9      \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]. \t  -0.5048487748496318 \t -0.4777748953827142\n",
            "10     \t [ 0.14475494  9.8292754  12.          0.60331385  2.          0.9622215 ]. \t  -0.4793528614807392 \t -0.4777748953827142\n",
            "11     \t [ 3.24107348  8.27034509 14.          0.92485614 16.          0.53812048]. \t  -0.6108249049014036 \t -0.4777748953827142\n",
            "12     \t [ 7.55307662  2.76896497 12.          0.93049335 17.          0.33736097]. \t  -0.6325286612401115 \t -0.4777748953827142\n",
            "13     \t [ 0.04787228  7.48596331  8.          0.52068382 16.          0.7086396 ]. \t  -0.5480409890266915 \t -0.4777748953827142\n",
            "14     \t [4.27099049 1.84437193 8.         0.60505752 3.         0.28835442]. \t  -0.6449257366707647 \t -0.4777748953827142\n",
            "15     \t [ 5.00288594  8.63257736  7.          0.63451109 10.          0.4931163 ]. \t  -0.6200967125674864 \t -0.4777748953827142\n",
            "16     \t [ 0.77892218  8.99624404 13.          0.66723238  9.          0.47803353]. \t  -0.6191917060428856 \t -0.4777748953827142\n",
            "17     \t [ 8.92040797  9.99421763 13.          0.88657464 18.          0.32294618]. \t  -0.632890825873186 \t -0.4777748953827142\n",
            "18     \t [0.25978025 0.         5.         1.         1.         1.        ]. \t  \u001b[92m-0.4725727379006825\u001b[0m \t -0.4725727379006825\n",
            "19     \t [1.35226985 0.         5.         0.5746227  6.70856189 0.1       ]. \t  -0.6836855058630442 \t -0.4725727379006825\n",
            "20     \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]. \t  -0.6350082940586608 \t -0.4725727379006825\n",
            "21     \t [ 6.26649824  4.98006493 14.          0.7181208   9.          0.25218732]. \t  -0.6772913973454617 \t -0.4725727379006825\n",
            "22     \t [ 2.4392947   0.43599832  8.81502317  1.         10.71084247  1.        ]. \t  \u001b[92m-0.46703580992643684\u001b[0m \t -0.46703580992643684\n",
            "23     \t [9.99675486 4.75786893 6.         0.97752073 8.         0.29304564]. \t  -0.6447319523266304 \t -0.46703580992643684\n",
            "24     \t [ 2.05358338  0.          9.80447106  0.5        18.59425716  0.46548003]. \t  -0.6226128617911535 \t -0.46703580992643684\n",
            "25     \t [ 3.96205991  9.89622107  8.          0.50097572 19.          0.66768637]. \t  -0.5545814169322449 \t -0.46703580992643684\n",
            "26     \t [8.97886962 5.1990592  8.         0.6115526  3.         0.92989751]. \t  -0.48850324642436094 \t -0.46703580992643684\n",
            "27     \t [ 8.56581326  7.68795383  5.          0.5        18.72407784  0.1       ]. \t  -0.6824820807192671 \t -0.46703580992643684\n",
            "28     \t [ 9.13327668  0.92433654 12.          0.91412474 10.          0.85058075]. \t  -0.48583373996276313 \t -0.46703580992643684\n",
            "29     \t [ 3.8544074   5.22723842 10.          0.76354194  1.          0.13710805]. \t  -0.6788335648158361 \t -0.46703580992643684\n",
            "30     \t [ 6.74942196  4.17860351  9.62514141  0.5        11.84947115  1.        ]. \t  -0.4867986781869732 \t -0.46703580992643684\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.822198171549157"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3708db20-4d2b-48cf-d29e-ac33de9f3142"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_approx_13 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_13 = GPGO_multi(surrogate_approx_13, Acquisition_new(util_approx), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "approx_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_13 = approx_13.getResult()[0]\n",
        "params_approx_13['max_depth'] = int(params_approx_13['max_depth'])\n",
        "params_approx_13['min_child_weight'] = int(params_approx_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_approx_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_approx_13 = xgb.train(params_approx_13, dX_approx_train13)\n",
        "pred_approx_13 = model_approx_13.predict(dX_approx_test13)\n",
        "\n",
        "rmse_approx_13 = np.sqrt(mean_squared_error(pred_approx_13, y_test13))\n",
        "rmse_approx_13"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]. \t  -0.5099204187421568 \t -0.5099204187421568\n",
            "init   \t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]. \t  -0.7086153631136594 \t -0.5099204187421568\n",
            "init   \t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]. \t  -0.6372461781857162 \t -0.5099204187421568\n",
            "init   \t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]. \t  -0.5702017504451442 \t -0.5099204187421568\n",
            "init   \t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]. \t  -0.7101125715665313 \t -0.5099204187421568\n",
            "1      \t [1.1119361  5.43221306 6.         0.56899303 8.         0.32100319]. \t  -0.6493427493033831 \t -0.5099204187421568\n",
            "2      \t [ 6.78607938  6.56608561 12.          0.84765686  1.          0.65153116]. \t  -0.587676594976195 \t -0.5099204187421568\n",
            "3      \t [ 9.24780874  8.51103418  5.          0.85105015 14.          0.11807471]. \t  -0.7114804394826701 \t -0.5099204187421568\n",
            "4      \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]. \t  -0.5162956828123637 \t -0.5099204187421568\n",
            "5      \t [0.54332874 9.16801531 5.         0.98374535 2.         0.17662624]. \t  -0.7151583517662211 \t -0.5099204187421568\n",
            "6      \t [ 1.86840748  0.75206083 14.          0.81141351 17.          0.47108772]. \t  -0.6160846256715893 \t -0.5099204187421568\n",
            "7      \t [2.42114726 2.21731466 7.         0.52977639 2.         0.33969965]. \t  -0.6396660621664843 \t -0.5099204187421568\n",
            "8      \t [ 1.89221513  8.5037767  14.          0.86717015  6.          0.11990372]. \t  -0.7161815730157779 \t -0.5099204187421568\n",
            "9      \t [9.52796793 0.5269077  7.         0.61130342 2.         0.41024487]. \t  -0.646488116516862 \t -0.5099204187421568\n",
            "10     \t [ 8.13982065  8.36144474 10.          0.55339983  6.          0.72558941]. \t  -0.5272458084896392 \t -0.5099204187421568\n",
            "11     \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]. \t  -0.5916305851001364 \t -0.5099204187421568\n",
            "12     \t [ 7.42000681  1.27539351  5.          0.54650948 11.          0.38725518]. \t  -0.6590542581211495 \t -0.5099204187421568\n",
            "13     \t [ 1.24784615  8.5302667   7.          0.99055025 14.          0.52610034]. \t  -0.6214626581302563 \t -0.5099204187421568\n",
            "14     \t [5.58295275 4.44059522 8.         0.59586926 6.         0.4310912 ]. \t  -0.6208233678912233 \t -0.5099204187421568\n",
            "15     \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]. \t  \u001b[92m-0.4816663211789673\u001b[0m \t -0.4816663211789673\n",
            "16     \t [ 7.07993587  3.46281488 14.          0.82366487  7.          0.56206532]. \t  -0.616023338612747 \t -0.4816663211789673\n",
            "17     \t [7.55403251 6.23917493 5.         0.63649547 1.         0.75229567]. \t  -0.5374292281718862 \t -0.4816663211789673\n",
            "18     \t [ 0.94229296  2.02450761 13.          0.65000924  1.          0.22250131]. \t  -0.7194219871093057 \t -0.4816663211789673\n",
            "19     \t [ 8.70212257  9.22072414 13.          0.93050035 17.          0.7479803 ]. \t  -0.5116607500666849 \t -0.4816663211789673\n",
            "20     \t [ 9.35280568  2.44132886  8.          0.87489385 18.          0.92170626]. \t  -0.49123124118162603 \t -0.4816663211789673\n",
            "21     \t [ 1.23850137  5.96524691 14.          0.65167204 16.          0.56763255]. \t  -0.6196449278548123 \t -0.4816663211789673\n",
            "22     \t [ 7.07595863  4.38601269 14.          0.69575224 18.          0.84020485]. \t  -0.5094677114975921 \t -0.4816663211789673\n",
            "23     \t [ 2.05622909  9.08047387  8.          0.8397078  17.          0.73365999]. \t  -0.5126218176815447 \t -0.4816663211789673\n",
            "24     \t [ 0.537802    3.33621713  8.          0.77943172 18.          0.5870313 ]. \t  -0.5738505862362491 \t -0.4816663211789673\n",
            "25     \t [ 5.52481546  5.87728353  6.          0.91974564 12.          0.91476175]. \t  -0.503940866762763 \t -0.4816663211789673\n",
            "26     \t [9.09105874 6.58287092 6.         0.6008869  5.         0.92518653]. \t  -0.505393062426751 \t -0.4816663211789673\n",
            "27     \t [ 7.47527868 10.         14.05454009  0.98775784  8.02271963  0.97941201]. \t  \u001b[92m-0.4726187699044283\u001b[0m \t -0.4726187699044283\n",
            "28     \t [ 2.90896848  6.7951465  15.          0.75749676  1.          0.1       ]. \t  -0.7164820585036945 \t -0.4726187699044283\n",
            "29     \t [ 0.42060893  0.71670801  5.          0.74681906 13.          0.66880385]. \t  -0.5904291451896722 \t -0.4726187699044283\n",
            "30     \t [0.43091775 0.3532639  5.         0.76123896 7.         0.49074528]. \t  -0.6279630584555015 \t -0.4726187699044283\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.561033228585927"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c198259-bd6b-4f60-d8d3-725e2a2d9bc9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_approx_14 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_14 = GPGO_multi(surrogate_approx_14, Acquisition_new(util_approx), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "approx_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_14 = approx_14.getResult()[0]\n",
        "params_approx_14['max_depth'] = int(params_approx_14['max_depth'])\n",
        "params_approx_14['min_child_weight'] = int(params_approx_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_approx_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_approx_14 = xgb.train(params_approx_14, dX_approx_train14)\n",
        "pred_approx_14 = model_approx_14.predict(dX_approx_test14)\n",
        "\n",
        "rmse_approx_14 = np.sqrt(mean_squared_error(pred_approx_14, y_test14))\n",
        "rmse_approx_14"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]. \t  -0.558794499921046 \t -0.4448140077853999\n",
            "init   \t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]. \t  -0.49979629433789113 \t -0.4448140077853999\n",
            "init   \t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]. \t  -0.5741697988899073 \t -0.4448140077853999\n",
            "init   \t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]. \t  -0.4448140077853999 \t -0.4448140077853999\n",
            "init   \t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]. \t  -0.6214151152359092 \t -0.4448140077853999\n",
            "1      \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]. \t  -0.6294794339238933 \t -0.4448140077853999\n",
            "2      \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]. \t  -0.5666498709303299 \t -0.4448140077853999\n",
            "3      \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]. \t  -0.45935750652191915 \t -0.4448140077853999\n",
            "4      \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]. \t  -0.6240299412135976 \t -0.4448140077853999\n",
            "5      \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]. \t  -0.5637683506571429 \t -0.4448140077853999\n",
            "6      \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]. \t  -0.6233774536812148 \t -0.4448140077853999\n",
            "7      \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]. \t  -0.4578630344523679 \t -0.4448140077853999\n",
            "8      \t [ 0.63353879  9.61017877  8.          0.96421247 18.          0.39200727]. \t  -0.5519186326582054 \t -0.4448140077853999\n",
            "9      \t [ 6.82711248  9.86843937 13.          0.52138031 17.          0.20003272]. \t  -0.6291207366201794 \t -0.4448140077853999\n",
            "10     \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]. \t  -0.5095746789782988 \t -0.4448140077853999\n",
            "11     \t [ 9.30217735  6.23147787  8.          0.97503033 15.          0.52511943]. \t  -0.5012787962633106 \t -0.4448140077853999\n",
            "12     \t [ 1.50285169  4.17593259 14.          0.69234646  6.          0.74044842]. \t  -0.4686692466684221 \t -0.4448140077853999\n",
            "13     \t [ 0.25039867  4.81148287 14.          0.83239345 15.          0.88911818]. \t  \u001b[92m-0.43183090108974975\u001b[0m \t -0.43183090108974975\n",
            "14     \t [4.48522578 6.54261798 5.         0.79314226 1.         0.29945677]. \t  -0.555676418412214 \t -0.43183090108974975\n",
            "15     \t [ 1.13909448  9.99750981 12.          0.83097832  8.          0.96211319]. \t  -0.43448557497453333 \t -0.43183090108974975\n",
            "16     \t [ 5.21920054  9.35580917 14.          0.81835368  4.          0.54800317]. \t  -0.4907240663685837 \t -0.43183090108974975\n",
            "17     \t [ 4.83871117  1.89317253 13.          0.87688851 13.          0.10679344]. \t  -0.6230760569149346 \t -0.43183090108974975\n",
            "18     \t [ 9.40706915  0.91600736 13.          0.648599    7.          0.62885715]. \t  -0.5088292837339503 \t -0.43183090108974975\n",
            "19     \t [2.50634417 7.18764527 7.         0.74380288 7.         0.36061143]. \t  -0.5554831731836115 \t -0.43183090108974975\n",
            "20     \t [2.03544962 0.82234782 9.         0.75192666 8.         0.57674562]. \t  -0.4958158998018211 \t -0.43183090108974975\n",
            "21     \t [ 1.52900897  2.49551652 10.          0.74070159  3.          0.79386687]. \t  -0.47442912742215454 \t -0.43183090108974975\n",
            "22     \t [ 0.33151889 10.         13.95870808  0.5         2.57742144  0.1       ]. \t  -0.6346613984732796 \t -0.43183090108974975\n",
            "23     \t [10.          0.         11.99997569  1.          1.          0.1       ]. \t  -0.6052630014888551 \t -0.43183090108974975\n",
            "24     \t [ 6.55062625  9.63146322  5.          0.68406751 18.          0.23627226]. \t  -0.6249350214618472 \t -0.43183090108974975\n",
            "25     \t [ 6.71198965  0.7988094   6.          0.93755772 17.          0.83354732]. \t  -0.4835304794698844 \t -0.43183090108974975\n",
            "26     \t [ 6.58726115  5.15136775 14.          0.85920414  6.          0.77914131]. \t  -0.46437714036564437 \t -0.43183090108974975\n",
            "27     \t [10.          0.         12.30047875  0.5        12.18479332  1.        ]. \t  -0.456312054470569 \t -0.43183090108974975\n",
            "28     \t [ 9.70174036  9.71799099 14.          0.84593857  8.          0.66512595]. \t  -0.492151770581115 \t -0.43183090108974975\n",
            "29     \t [ 5.89991801 10.          9.99231908  1.          1.          1.        ]. \t  \u001b[92m-0.4308110622159235\u001b[0m \t -0.4308110622159235\n",
            "30     \t [ 1.26617981  4.03386415  8.          0.85223134 19.          0.86958504]. \t  -0.4481330730823694 \t -0.4308110622159235\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.975961114903651"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c897d3ee-22b1-48da-f522-31a1b7bafbd1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_approx_15 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_15 = GPGO_multi(surrogate_approx_15, Acquisition_new(util_approx), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "approx_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_15 = approx_15.getResult()[0]\n",
        "params_approx_15['max_depth'] = int(params_approx_15['max_depth'])\n",
        "params_approx_15['min_child_weight'] = int(params_approx_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_approx_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_approx_15 = xgb.train(params_approx_15, dX_approx_train15)\n",
        "pred_approx_15 = model_approx_15.predict(dX_approx_test15)\n",
        "\n",
        "rmse_approx_15 = np.sqrt(mean_squared_error(pred_approx_15, y_test15))\n",
        "rmse_approx_15"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]. \t  -0.489437914006383 \t -0.489437914006383\n",
            "init   \t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]. \t  -0.6992441679399787 \t -0.489437914006383\n",
            "init   \t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]. \t  -0.69945028775584 \t -0.489437914006383\n",
            "init   \t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]. \t  -0.6264981748624211 \t -0.489437914006383\n",
            "init   \t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]. \t  -0.6964615643692806 \t -0.489437914006383\n",
            "1      \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]. \t  -0.56524595824364 \t -0.489437914006383\n",
            "2      \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]. \t  -0.6976766501007658 \t -0.489437914006383\n",
            "3      \t [ 1.91126037  0.99517267  5.          0.54111286 13.          0.82351196]. \t  -0.5203297112050622 \t -0.489437914006383\n",
            "4      \t [ 9.65016643  9.36315476  6.          0.59817648 12.          0.93115055]. \t  -0.5035725842878749 \t -0.489437914006383\n",
            "5      \t [ 7.92634325  7.5869497  10.          0.81214373  5.          0.71583728]. \t  \u001b[92m-0.48077564047020915\u001b[0m \t -0.48077564047020915\n",
            "6      \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]. \t  -0.6854377590797448 \t -0.48077564047020915\n",
            "7      \t [ 1.16848639  8.05538533  5.          0.78038294 17.          0.39890654]. \t  -0.6820374964576017 \t -0.48077564047020915\n",
            "8      \t [ 2.92030295  6.55213539  7.          0.85743112 11.          0.10721562]. \t  -0.6994232506027507 \t -0.48077564047020915\n",
            "9      \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]. \t  -0.512561519837635 \t -0.48077564047020915\n",
            "10     \t [ 7.63220266  0.71776488 13.          0.94235703 19.          0.50312607]. \t  -0.6214609326165444 \t -0.48077564047020915\n",
            "11     \t [7.86329715 0.45193827 6.         0.68312899 1.         0.69810196]. \t  -0.5708964123226768 \t -0.48077564047020915\n",
            "12     \t [ 9.84885491  3.44589736 14.          0.68420761  1.          0.79220009]. \t  -0.48343162855817534 \t -0.48077564047020915\n",
            "13     \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]. \t  -0.4948532295288583 \t -0.48077564047020915\n",
            "14     \t [ 7.74771021  6.65318771  6.          0.83647538 17.          0.81072392]. \t  -0.5116796961222467 \t -0.48077564047020915\n",
            "15     \t [ 6.65116837  8.16324548 14.          0.95750787  1.          0.74925927]. \t  \u001b[92m-0.4743330993644729\u001b[0m \t -0.4743330993644729\n",
            "16     \t [ 1.01000548  1.96777104 12.          0.51504561  8.          0.68970296]. \t  -0.5746890275202554 \t -0.4743330993644729\n",
            "17     \t [ 4.37932047  6.20385796 12.          0.97766072  9.          0.88967325]. \t  \u001b[92m-0.4658895846734884\u001b[0m \t -0.4658895846734884\n",
            "18     \t [ 1.86027286  4.35430307 13.          0.53536444 15.          0.92334731]. \t  -0.4824087135892917 \t -0.4658895846734884\n",
            "19     \t [ 6.18689053  4.41947903 10.          0.55970253  2.          0.89284311]. \t  -0.47929144896934517 \t -0.4658895846734884\n",
            "20     \t [6.19035513 9.21397751 5.         0.86618004 7.         1.        ]. \t  -0.4827451972171186 \t -0.4658895846734884\n",
            "21     \t [8.81149616 6.28323965 6.         0.50689458 2.         0.19421846]. \t  -0.7005581625473822 \t -0.4658895846734884\n",
            "22     \t [ 9.31305405  2.68340802  7.          0.59348541 12.          0.97471219]. \t  -0.4968862489406364 \t -0.4658895846734884\n",
            "23     \t [ 7.26711337  0.14235978  5.          0.76462611 16.          0.41351262]. \t  -0.6846390670115327 \t -0.4658895846734884\n",
            "24     \t [ 2.81158295  0.14163964 12.          0.70854558 13.          0.79112734]. \t  -0.4842462210120286 \t -0.4658895846734884\n",
            "25     \t [ 3.88306366  3.40148813  9.          0.63469791 14.          0.97570386]. \t  -0.48649649646557247 \t -0.4658895846734884\n",
            "26     \t [ 7.4679151   6.11968454 14.          0.59617872 16.          0.1338107 ]. \t  -0.6993379322173302 \t -0.4658895846734884\n",
            "27     \t [ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]. \t  -0.4745561015346341 \t -0.4658895846734884\n",
            "28     \t [ 0.17423277  9.28464895 11.          0.86455659  1.          0.87456687]. \t  \u001b[92m-0.46266030027567673\u001b[0m \t -0.46266030027567673\n",
            "29     \t [ 9.86958766  9.71945286 10.          0.93465271  9.          0.31222907]. \t  -0.6892292934561406 \t -0.46266030027567673\n",
            "30     \t [ 9.40435768  7.598465   10.          0.97457018 15.          0.31309738]. \t  -0.6891569408822912 \t -0.46266030027567673\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.570230628583621"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f048aef5-1981-45ab-ef4d-1e9ae0fe535a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_approx_16 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_16 = GPGO_multi(surrogate_approx_16, Acquisition_new(util_approx), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "approx_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_16 = approx_16.getResult()[0]\n",
        "params_approx_16['max_depth'] = int(params_approx_16['max_depth'])\n",
        "params_approx_16['min_child_weight'] = int(params_approx_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_approx_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_approx_16 = xgb.train(params_approx_16, dX_approx_train16)\n",
        "pred_approx_16 = model_approx_16.predict(dX_approx_test16)\n",
        "\n",
        "rmse_approx_16 = np.sqrt(mean_squared_error(pred_approx_16, y_test16))\n",
        "rmse_approx_16"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]. \t  -0.6357813258069683 \t -0.6345701590947206\n",
            "init   \t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]. \t  -0.7029752724132097 \t -0.6345701590947206\n",
            "init   \t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]. \t  -0.6345701590947206 \t -0.6345701590947206\n",
            "init   \t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]. \t  -0.7076230970293895 \t -0.6345701590947206\n",
            "init   \t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]. \t  -0.7061563820165734 \t -0.6345701590947206\n",
            "1      \t [ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]. \t  \u001b[92m-0.5498317738591506\u001b[0m \t -0.5498317738591506\n",
            "2      \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]. \t  -0.5694622631948656 \t -0.5498317738591506\n",
            "3      \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]. \t  -0.5668863692096254 \t -0.5498317738591506\n",
            "4      \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]. \t  -0.7034666397019427 \t -0.5498317738591506\n",
            "5      \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]. \t  -0.5723152354991565 \t -0.5498317738591506\n",
            "6      \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]. \t  \u001b[92m-0.5394691206821607\u001b[0m \t -0.5394691206821607\n",
            "7      \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]. \t  -0.6464801434165215 \t -0.5394691206821607\n",
            "8      \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]. \t  -0.5469067821272691 \t -0.5394691206821607\n",
            "9      \t [6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]. \t  \u001b[92m-0.459858810359861\u001b[0m \t -0.459858810359861\n",
            "10     \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]. \t  -0.5000126867450256 \t -0.459858810359861\n",
            "11     \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]. \t  -0.7073064797779202 \t -0.459858810359861\n",
            "12     \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]. \t  -0.5373324936054761 \t -0.459858810359861\n",
            "13     \t [ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]. \t  \u001b[92m-0.45152053563727684\u001b[0m \t -0.45152053563727684\n",
            "14     \t [0.50474552 1.15372476 8.         0.52058641 1.         0.43046119]. \t  -0.5790419770781896 \t -0.45152053563727684\n",
            "15     \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]. \t  -0.6336754873953304 \t -0.45152053563727684\n",
            "16     \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]. \t  -0.5493386366741839 \t -0.45152053563727684\n",
            "17     \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]. \t  -0.7009377489720375 \t -0.45152053563727684\n",
            "18     \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]. \t  -0.6372685525181103 \t -0.45152053563727684\n",
            "19     \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]. \t  -0.6403104298000886 \t -0.45152053563727684\n",
            "20     \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]. \t  -0.5829323144677231 \t -0.45152053563727684\n",
            "21     \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]. \t  -0.7036971150142254 \t -0.45152053563727684\n",
            "22     \t [ 8.74525186 10.          5.          0.5        17.20478531  0.1       ]. \t  -0.7124579708539022 \t -0.45152053563727684\n",
            "23     \t [0.58596137 5.71336149 9.         0.70354751 9.         0.28160967]. \t  -0.7049522924957982 \t -0.45152053563727684\n",
            "24     \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]. \t  -0.5511376842555078 \t -0.45152053563727684\n",
            "25     \t [ 9.01141716  1.23452325  9.          0.70620993 16.          0.46074297]. \t  -0.5736906301272524 \t -0.45152053563727684\n",
            "26     \t [ 5.38505352  0.27838384  8.          0.64624975 19.          0.94943729]. \t  -0.48384723995087875 \t -0.45152053563727684\n",
            "27     \t [ 0.2375092   5.20448002  7.          0.887766   16.          0.16167958]. \t  -0.7030972719979267 \t -0.45152053563727684\n",
            "28     \t [ 3.60668261  3.61026877 14.          0.9898327  13.          0.9620422 ]. \t  -0.4580160478583563 \t -0.45152053563727684\n",
            "29     \t [ 0.21025929  1.69343398  5.30363656  0.50567834 12.94783715  0.40063208]. \t  -0.6379687257083612 \t -0.45152053563727684\n",
            "30     \t [ 4.69322375  9.60744488 12.37861618  1.          1.          1.        ]. \t  \u001b[92m-0.44292971322345187\u001b[0m \t -0.44292971322345187\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.76665406708658"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4133e5-13ef-4d40-b8d2-c6646379fe97"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_approx_17 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_17 = GPGO_multi(surrogate_approx_17, Acquisition_new(util_approx), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "approx_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_17 = approx_17.getResult()[0]\n",
        "params_approx_17['max_depth'] = int(params_approx_17['max_depth'])\n",
        "params_approx_17['min_child_weight'] = int(params_approx_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_approx_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_approx_17 = xgb.train(params_approx_17, dX_approx_train17)\n",
        "pred_approx_17 = model_approx_17.predict(dX_approx_test17)\n",
        "\n",
        "rmse_approx_17 = np.sqrt(mean_squared_error(pred_approx_17, y_test17))\n",
        "rmse_approx_17"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]. \t  -0.48092361225642916 \t -0.48092361225642916\n",
            "init   \t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]. \t  -0.634455605137701 \t -0.48092361225642916\n",
            "init   \t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]. \t  -0.6046684392629649 \t -0.48092361225642916\n",
            "init   \t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]. \t  -0.6562801618178493 \t -0.48092361225642916\n",
            "init   \t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]. \t  -0.6415104035419145 \t -0.48092361225642916\n",
            "1      \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]. \t  -0.6424064809093688 \t -0.48092361225642916\n",
            "2      \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]. \t  -0.5250563773138615 \t -0.48092361225642916\n",
            "3      \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]. \t  -0.4855447166854706 \t -0.48092361225642916\n",
            "4      \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]. \t  -0.6592777931092744 \t -0.48092361225642916\n",
            "5      \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]. \t  -0.6482001920177487 \t -0.48092361225642916\n",
            "6      \t [9.9788934  2.15636979 6.         0.99768008 1.         0.76766471]. \t  -0.4941759850943699 \t -0.48092361225642916\n",
            "7      \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]. \t  -0.5824208509959975 \t -0.48092361225642916\n",
            "8      \t [ 0.80030762  5.97573055 10.          0.83426171  8.          0.65594116]. \t  -0.4925025307799194 \t -0.48092361225642916\n",
            "9      \t [ 1.2716555   3.78378689  5.          0.57556817 17.          0.18163876]. \t  -0.6597773245382103 \t -0.48092361225642916\n",
            "10     \t [ 9.80102397  1.97747829 14.          0.90631838  4.          0.75804043]. \t  \u001b[92m-0.47872283861791676\u001b[0m \t -0.47872283861791676\n",
            "11     \t [ 0.53370892  8.37682141  5.          0.86989913 13.          0.18237465]. \t  -0.6538884437793409 \t -0.47872283861791676\n",
            "12     \t [6.11014277 4.82394447 9.         0.70644548 3.         0.44997585]. \t  -0.5918645900207917 \t -0.47872283861791676\n",
            "13     \t [ 7.51514915  5.57821555 12.          0.8704045   9.          0.10769764]. \t  -0.6545410284856534 \t -0.47872283861791676\n",
            "14     \t [ 6.50720114  1.21776605  6.          0.73440759 16.          0.41004769]. \t  -0.6375743637451337 \t -0.47872283861791676\n",
            "15     \t [ 2.09834172  9.70848226 14.          0.77970461 12.          0.72363271]. \t  -0.4818384603005539 \t -0.47872283861791676\n",
            "16     \t [6.14842106 3.92031042 5.         0.80436272 5.         0.42842685]. \t  -0.6361132092867747 \t -0.47872283861791676\n",
            "17     \t [ 1.93531857  1.03643759  8.          0.58366211 11.          0.77260063]. \t  -0.502682327629841 \t -0.47872283861791676\n",
            "18     \t [ 0.92420069  7.86313854 11.          0.85701757 18.          0.6345725 ]. \t  -0.5015067417814894 \t -0.47872283861791676\n",
            "19     \t [ 8.33299562  3.08503037 14.          0.66982922 14.          0.17286547]. \t  -0.6611384255953584 \t -0.47872283861791676\n",
            "20     \t [3.85793665 5.66438778 6.0957294  0.5        9.81630439 0.1       ]. \t  -0.6651847272970921 \t -0.47872283861791676\n",
            "21     \t [ 2.84384196  0.26425531 12.          0.92278988 19.          0.53932453]. \t  -0.5879728608645983 \t -0.47872283861791676\n",
            "22     \t [ 6.72796419  6.10053296 14.          0.56325639  2.          0.91580991]. \t  -0.484930134033398 \t -0.47872283861791676\n",
            "23     \t [ 7.07271536  8.13007518  5.          0.98530219 19.          0.92839144]. \t  -0.5016527633767568 \t -0.47872283861791676\n",
            "24     \t [ 2.77593451  9.15139628 12.          0.75467287  5.          0.21563156]. \t  -0.6586697172204237 \t -0.47872283861791676\n",
            "25     \t [ 8.38209371  1.79436187  5.          0.95610423 10.          0.10723534]. \t  -0.6559711086452673 \t -0.47872283861791676\n",
            "26     \t [ 9.68199458  9.34620738 11.          0.57663541 14.          0.24521092]. \t  -0.6616124039375455 \t -0.47872283861791676\n",
            "27     \t [ 5.62137526  0.50742571 12.          0.60891749  1.          0.89299215]. \t  -0.4808990846134473 \t -0.47872283861791676\n",
            "28     \t [ 0.16736047  0.         14.13971902  0.5        13.67249036  1.        ]. \t  -0.4854485619947814 \t -0.47872283861791676\n",
            "29     \t [ 0.49450478  0.          8.30186376  1.         15.75058383  0.1       ]. \t  -0.6875778663047963 \t -0.47872283861791676\n",
            "30     \t [ 4.09975041  9.9807053   9.          0.85467215 15.          0.44460825]. \t  -0.5884461973684892 \t -0.47872283861791676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.654967820847159"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b378591-32fb-48f0-a2a7-443b4184854e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_approx_18 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_18 = GPGO_multi(surrogate_approx_18, Acquisition_new(util_approx), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "approx_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_18 = approx_18.getResult()[0]\n",
        "params_approx_18['max_depth'] = int(params_approx_18['max_depth'])\n",
        "params_approx_18['min_child_weight'] = int(params_approx_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_approx_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_approx_18 = xgb.train(params_approx_18, dX_approx_train18)\n",
        "pred_approx_18 = model_approx_18.predict(dX_approx_test18)\n",
        "\n",
        "rmse_approx_18 = np.sqrt(mean_squared_error(pred_approx_18, y_test18))\n",
        "rmse_approx_18"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]. \t  -0.6513740959050699 \t -0.4474949996843899\n",
            "init   \t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]. \t  -0.5068571689279089 \t -0.4474949996843899\n",
            "init   \t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]. \t  -0.6466851980958979 \t -0.4474949996843899\n",
            "init   \t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]. \t  -0.5514036168275981 \t -0.4474949996843899\n",
            "init   \t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]. \t  -0.4474949996843899 \t -0.4474949996843899\n",
            "1      \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]. \t  -0.5562589356787108 \t -0.4474949996843899\n",
            "2      \t [ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]. \t  \u001b[92m-0.4433734006799697\u001b[0m \t -0.4433734006799697\n",
            "3      \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]. \t  -0.5602631506416998 \t -0.4433734006799697\n",
            "4      \t [ 7.14073136  5.55994996  9.          0.83675129 19.          0.37545046]. \t  -0.541209700832818 \t -0.4433734006799697\n",
            "5      \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]. \t  -0.5112449621798897 \t -0.4433734006799697\n",
            "6      \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]. \t  -0.6484751089973615 \t -0.4433734006799697\n",
            "7      \t [ 0.08591204  9.74195655 12.          0.74151757  5.          0.3185873 ]. \t  -0.5422988717775798 \t -0.4433734006799697\n",
            "8      \t [ 3.1729404   6.2152728   5.          0.89368162 19.          0.6083566 ]. \t  -0.5181522764310995 \t -0.4433734006799697\n",
            "9      \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]. \t  -0.5413368089201347 \t -0.4433734006799697\n",
            "10     \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]. \t  \u001b[92m-0.432593733655084\u001b[0m \t -0.432593733655084\n",
            "11     \t [ 0.2637722   4.11659493  5.          0.61604637 11.          0.22374653]. \t  -0.6492744168634729 \t -0.432593733655084\n",
            "12     \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]. \t  -0.5585495399871547 \t -0.432593733655084\n",
            "13     \t [ 8.34050252  7.45495891 14.          0.58875591  8.          0.92669456]. \t  -0.45443542892982364 \t -0.432593733655084\n",
            "14     \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]. \t  -0.5454755819305526 \t -0.432593733655084\n",
            "15     \t [ 2.3725221   1.25906939 10.          0.50882646  1.          0.22780426]. \t  -0.6580514956819312 \t -0.432593733655084\n",
            "16     \t [ 0.71491502  0.67997826 10.          0.84656193 16.          0.26877596]. \t  -0.6453762638624181 \t -0.432593733655084\n",
            "17     \t [ 9.40597423  9.67323489  5.          0.96215948 17.          0.16332135]. \t  -0.6489897693395557 \t -0.432593733655084\n",
            "18     \t [ 9.91629947  4.09421745 10.27975129  0.5         5.74295575  1.        ]. \t  -0.4451967987456863 \t -0.432593733655084\n",
            "19     \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]. \t  -0.6503201385354563 \t -0.432593733655084\n",
            "20     \t [ 3.26915509 10.          5.          0.5         7.48301721  1.        ]. \t  -0.4495702527970831 \t -0.432593733655084\n",
            "21     \t [ 9.23733929  4.4641986  14.          0.5618978  13.          0.67359608]. \t  -0.5224388077461729 \t -0.432593733655084\n",
            "22     \t [ 3.44634229  0.73068286  6.          0.98116529 13.          0.55221155]. \t  -0.5523561794778635 \t -0.432593733655084\n",
            "23     \t [ 9.73631216  7.46194167 14.          0.919988    1.          0.18982878]. \t  -0.6496689010058144 \t -0.432593733655084\n",
            "24     \t [ 3.07095238  9.11590966 13.          0.52104481 10.          0.35982183]. \t  -0.5520412870824976 \t -0.432593733655084\n",
            "25     \t [ 0.   0.   5.   0.5 20.   0.1]. \t  -0.657436411574132 \t -0.432593733655084\n",
            "26     \t [7.57576188 9.88300946 9.87195495 0.61719607 8.01744578 0.67863944]. \t  -0.5172953288445937 \t -0.432593733655084\n",
            "27     \t [ 4.56042904  1.71688638  7.35163814  0.5        18.00874691  0.65484859]. \t  -0.5351367172780666 \t -0.432593733655084\n",
            "28     \t [4.87245891 0.03350161 6.         0.83466638 1.         0.44183056]. \t  -0.5542072696463398 \t -0.432593733655084\n",
            "29     \t [9.89337178 3.81875947 5.         0.59649267 7.         0.86884145]. \t  -0.46444951872029455 \t -0.432593733655084\n",
            "30     \t [ 9.94094117  9.96810229 11.          0.85509094 13.          0.23577872]. \t  -0.6452100691123155 \t -0.432593733655084\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.749647113906867"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3806da-2143-4fab-fb6a-5c5cb5e69fba"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_approx_19 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_19 = GPGO_multi(surrogate_approx_19, Acquisition_new(util_approx), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "approx_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_19 = approx_19.getResult()[0]\n",
        "params_approx_19['max_depth'] = int(params_approx_19['max_depth'])\n",
        "params_approx_19['min_child_weight'] = int(params_approx_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_approx_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_approx_19 = xgb.train(params_approx_19, dX_approx_train19)\n",
        "pred_approx_19 = model_approx_19.predict(dX_approx_test19)\n",
        "\n",
        "rmse_approx_19 = np.sqrt(mean_squared_error(pred_approx_19, y_test19))\n",
        "rmse_approx_19"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]. \t  -0.5851081958447377 \t -0.4870287725699859\n",
            "init   \t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]. \t  -0.5245729886945251 \t -0.4870287725699859\n",
            "init   \t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]. \t  -0.677999989539271 \t -0.4870287725699859\n",
            "init   \t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]. \t  -0.4940235599803803 \t -0.4870287725699859\n",
            "init   \t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]. \t  -0.4870287725699859 \t -0.4870287725699859\n",
            "1      \t [ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]. \t  \u001b[92m-0.48699206254226385\u001b[0m \t -0.48699206254226385\n",
            "2      \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]. \t  -0.5586571006723301 \t -0.48699206254226385\n",
            "3      \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]. \t  -0.6812597142899619 \t -0.48699206254226385\n",
            "4      \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]. \t  -0.5176144815279642 \t -0.48699206254226385\n",
            "5      \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]. \t  -0.5891547583463381 \t -0.48699206254226385\n",
            "6      \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]. \t  -0.5015490515597342 \t -0.48699206254226385\n",
            "7      \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]. \t  -0.50278430420039 \t -0.48699206254226385\n",
            "8      \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]. \t  -0.5141082374188205 \t -0.48699206254226385\n",
            "9      \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]. \t  -0.5768849774796976 \t -0.48699206254226385\n",
            "10     \t [ 4.45643696  6.43761151 10.          0.59521711 15.          0.91320177]. \t  \u001b[92m-0.46737499097766744\u001b[0m \t -0.46737499097766744\n",
            "11     \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]. \t  -0.48543607778126086 \t -0.46737499097766744\n",
            "12     \t [ 9.41792853  9.11293681  6.          0.87420995 11.          0.8007601 ]. \t  -0.49558651242536805 \t -0.46737499097766744\n",
            "13     \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]. \t  -0.6819669312627161 \t -0.46737499097766744\n",
            "14     \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]. \t  -0.5047568707535037 \t -0.46737499097766744\n",
            "15     \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]. \t  -0.5759745047951098 \t -0.46737499097766744\n",
            "16     \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]. \t  -0.5829439311579024 \t -0.46737499097766744\n",
            "17     \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]. \t  -0.5147410971984965 \t -0.46737499097766744\n",
            "18     \t [ 8.22438004  9.86720872 12.          0.98809303  7.          0.25782248]. \t  -0.6795747265865547 \t -0.46737499097766744\n",
            "19     \t [ 1.10650842  9.77537077 14.          0.83431584  1.          0.5884296 ]. \t  -0.5035756891739214 \t -0.46737499097766744\n",
            "20     \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]. \t  -0.4691498772137427 \t -0.46737499097766744\n",
            "21     \t [0.63927877 0.36518569 5.         0.86590497 1.         0.99444527]. \t  -0.47804555573878577 \t -0.46737499097766744\n",
            "22     \t [8.34385872 4.73799236 5.         1.         8.55094228 0.1       ]. \t  -0.6811297731696853 \t -0.46737499097766744\n",
            "23     \t [ 4.81184079  0.03027405 11.          0.96437956 10.          0.97759806]. \t  \u001b[92m-0.45753944845516925\u001b[0m \t -0.45753944845516925\n",
            "24     \t [9.88174523 0.         5.         1.         1.         0.1       ]. \t  -0.6817338875315634 \t -0.45753944845516925\n",
            "25     \t [ 3.58007301  3.24360874 11.          0.7006564   4.          0.72466158]. \t  -0.47488259516427683 \t -0.45753944845516925\n",
            "26     \t [ 9.2876216   9.23467155  9.          0.78119986 18.          0.66822771]. \t  -0.5059667117308673 \t -0.45753944845516925\n",
            "27     \t [0.98839209 0.         9.32336508 0.5        6.43243155 0.1       ]. \t  -0.6812235717330677 \t -0.45753944845516925\n",
            "28     \t [10.          4.67302058  9.43333465  1.          3.19355918  0.1       ]. \t  -0.6796162671654571 \t -0.45753944845516925\n",
            "29     \t [ 8.73793669  2.43663345 11.          0.74070373 19.          0.18745114]. \t  -0.6789732848722562 \t -0.45753944845516925\n",
            "30     \t [ 9.81457301  8.66419485 11.          0.75732484 12.          0.78456883]. \t  -0.48068307872342075 \t -0.45753944845516925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.673966048842431"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bde51d-23f6-48b1-8035-b3c49c435e23"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_approx_20 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_20 = GPGO_multi(surrogate_approx_20, Acquisition_new(util_approx), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "approx_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_20 = approx_20.getResult()[0]\n",
        "params_approx_20['max_depth'] = int(params_approx_20['max_depth'])\n",
        "params_approx_20['min_child_weight'] = int(params_approx_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_approx_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_approx_20 = xgb.train(params_approx_20, dX_approx_train20)\n",
        "pred_approx_20 = model_approx_20.predict(dX_approx_test20)\n",
        "\n",
        "rmse_approx_20 = np.sqrt(mean_squared_error(pred_approx_20, y_test20))\n",
        "rmse_approx_20"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]. \t  -0.4485352768858121 \t -0.4485352768858121\n",
            "init   \t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]. \t  -0.47208091450542966 \t -0.4485352768858121\n",
            "init   \t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]. \t  -0.7316473600840852 \t -0.4485352768858121\n",
            "init   \t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]. \t  -0.7314226542252507 \t -0.4485352768858121\n",
            "init   \t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]. \t  -0.6494230116583573 \t -0.4485352768858121\n",
            "1      \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]. \t  -0.6502222800629637 \t -0.4485352768858121\n",
            "2      \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]. \t  -0.7324821709443572 \t -0.4485352768858121\n",
            "3      \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]. \t  -0.48832123516521386 \t -0.4485352768858121\n",
            "4      \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]. \t  -0.495544167185156 \t -0.4485352768858121\n",
            "5      \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]. \t  -0.5656245491262217 \t -0.4485352768858121\n",
            "6      \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]. \t  -0.7322813451403996 \t -0.4485352768858121\n",
            "7      \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]. \t  -0.5131423970299518 \t -0.4485352768858121\n",
            "8      \t [ 2.63649501  9.62311075  7.          0.5192485  13.          0.19746315]. \t  -0.7309630421287494 \t -0.4485352768858121\n",
            "9      \t [ 9.18502444  7.06345806 13.          0.62385346 16.          0.94993271]. \t  -0.4697056546639762 \t -0.4485352768858121\n",
            "10     \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]. \t  -0.5164100755179035 \t -0.4485352768858121\n",
            "11     \t [ 1.427592    3.43787632  6.          0.91643951 11.          0.75231375]. \t  -0.4837818185403998 \t -0.4485352768858121\n",
            "12     \t [ 6.87684298  0.81341201 12.          0.63438989 19.          0.35708107]. \t  -0.6528095609241975 \t -0.4485352768858121\n",
            "13     \t [ 3.51322154  8.79998304 14.          0.91142182  1.          0.35103611]. \t  -0.6603269613793542 \t -0.4485352768858121\n",
            "14     \t [10.         10.          6.55723727  1.         16.31660133  1.        ]. \t  -0.46051843144548704 \t -0.4485352768858121\n",
            "15     \t [ 1.66070915  0.6971968  14.          0.69953824  6.          0.77654933]. \t  -0.45639156392393776 \t -0.4485352768858121\n",
            "16     \t [ 1.47808653  5.79832114 12.          0.95992435  9.          0.71524706]. \t  -0.4536409968490355 \t -0.4485352768858121\n",
            "17     \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]. \t  -0.479780992905768 \t -0.4485352768858121\n",
            "18     \t [ 0.7766431   8.0732046   5.          0.88801393 19.          0.19994543]. \t  -0.7311450688291956 \t -0.4485352768858121\n",
            "19     \t [8.67223652 9.66010575 6.         0.63457768 6.         0.86415257]. \t  -0.4780550911576794 \t -0.4485352768858121\n",
            "20     \t [ 0.02776244  1.53012881  8.          0.96273615 15.          0.27616872]. \t  -0.7304915378852037 \t -0.4485352768858121\n",
            "21     \t [ 2.16891361  0.40236972  6.          0.57865056 19.          0.33900997]. \t  -0.6538296947589674 \t -0.4485352768858121\n",
            "22     \t [7.09521948 1.98932663 6.         0.65989265 2.         0.73023722]. \t  -0.47757090861511503 \t -0.4485352768858121\n",
            "23     \t [ 9.71937523  0.84081751  8.          0.83815718 13.          0.15657647]. \t  -0.7323525847117764 \t -0.4485352768858121\n",
            "24     \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]. \t  -0.4532172863470342 \t -0.4485352768858121\n",
            "25     \t [ 9.4251418   2.62898513  5.          0.90450266 19.          0.92733176]. \t  -0.4855968658102518 \t -0.4485352768858121\n",
            "26     \t [1.90224479 9.48070592 6.         0.72300437 8.         0.6951933 ]. \t  -0.5164683343747268 \t -0.4485352768858121\n",
            "27     \t [2.74869289 0.         5.         1.         1.99981556 0.1       ]. \t  -0.6872293569216671 \t -0.4485352768858121\n",
            "28     \t [ 2.17713913 10.          5.          1.          1.          0.1       ]. \t  -0.6873898609911764 \t -0.4485352768858121\n",
            "29     \t [ 2.05797056  3.5679443  14.          0.67286552 19.          0.3168445 ]. \t  -0.6525256594469919 \t -0.4485352768858121\n",
            "30     \t [ 6.03995449  5.27575995 11.4463628   0.5        11.40051648  1.        ]. \t  -0.45801573209985946 \t -0.4485352768858121\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.454763173494824"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaedc6f6-ba72-4d24-8d92-17938aee2874"
      },
      "source": [
        "end_approx = time.time()\n",
        "end_approx\n",
        "\n",
        "time_approx = end_approx - start_approx\n",
        "time_approx\n",
        "\n",
        "start_exact = time.time()\n",
        "start_exact"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1645706812.0620196"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c16930f-31fa-4253-d547-0e449efa9fb0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_exact_1 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_1 = dGPGO(surrogate_exact_1, Acquisition_new(util_exact), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_1 = exact_1.getResult()[0]\n",
        "params_exact_1['max_depth'] = int(params_exact_1['max_depth'])\n",
        "params_exact_1['min_child_weight'] = int(params_exact_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_exact_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_exact_1 = xgb.train(params_exact_1, dX_exact_train1)\n",
        "pred_exact_1 = model_exact_1.predict(dX_exact_test1)\n",
        "\n",
        "rmse_exact_1 = np.sqrt(mean_squared_error(pred_exact_1, y_test1))\n",
        "rmse_exact_1"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [5.48813504 7.15189366 8.         0.92897281 8.         0.48128932]. \t  -0.5626915313589341 \t -0.46143572360276275\n",
            "init   \t [ 6.45894113  4.37587211 11.          0.52835649 13.          0.44509737]. \t  -0.5772881365468763 \t -0.46143572360276275\n",
            "init   \t [ 7.91725038  5.2889492  13.          0.6963924  14.          0.40365654]. \t  -0.5870544636272766 \t -0.46143572360276275\n",
            "init   \t [ 6.48171872  3.6824154  10.          0.88907838 16.          0.88307853]. \t  -0.46143572360276275 \t -0.46143572360276275\n",
            "init   \t [4.73608045 8.00910752 8.         0.83943977 8.         0.67592892]. \t  -0.5051288806760134 \t -0.46143572360276275\n",
            "1      \t [ 0.96098408  9.76459465  7.          0.75481219 17.          0.64436097]. \t  -0.5149059967458438 \t -0.46143572360276275\n",
            "2      \t [ 0.25662718  2.07470075 13.          0.86522109  6.          0.51721788]. \t  -0.5609779944418447 \t -0.46143572360276275\n",
            "3      \t [ 9.79573252  1.48478088 12.          0.94838058  2.          0.62192116]. \t  -0.5054179573676033 \t -0.46143572360276275\n",
            "4      \t [ 0.62636003  2.41901704  5.          0.63031433 15.          0.7957752 ]. \t  -0.5075878491448556 \t -0.46143572360276275\n",
            "5      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6779967301528039 \t -0.46143572360276275\n",
            "6      \t [8.51808583 9.62395074 8.         0.60054801 1.         0.9981946 ]. \t  -0.4825618268670315 \t -0.46143572360276275\n",
            "7      \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.4302853773034897\u001b[0m \t -0.4302853773034897\n",
            "8      \t [ 0.44571111  9.13283596 10.          0.7789937   1.          0.17342299]. \t  -0.6758674152983395 \t -0.4302853773034897\n",
            "9      \t [9.15647011 0.95123437 9.         0.70846698 8.         0.21386088]. \t  -0.6731394995355806 \t -0.4302853773034897\n",
            "10     \t [ 1.96496846  0.2988114  14.          0.81090497 13.          0.73057001]. \t  -0.46331696604270556 \t -0.4302853773034897\n",
            "11     \t [ 0.27653157  6.60338596 14.          0.97720044 12.          0.7490783 ]. \t  -0.45756183431510866 \t -0.4302853773034897\n",
            "12     \t [ 7.08074933  9.21915799  8.          0.86203626 18.          0.25849345]. \t  -0.6720522160474754 \t -0.4302853773034897\n",
            "13     \t [ 2.93798739  9.81816086 13.          0.97223708 19.          0.56506484]. \t  -0.5577120312708883 \t -0.4302853773034897\n",
            "14     \t [2.55030677 0.         7.30699698 0.5        7.30699698 0.1       ]. \t  -0.6775995969630643 \t -0.4302853773034897\n",
            "15     \t [ 9.61554311  1.21538233  6.          0.81124244 13.          0.27856607]. \t  -0.6710935853736035 \t -0.4302853773034897\n",
            "16     \t [ 4.582743    7.81781039 14.          0.82423418  5.          0.48937461]. \t  -0.5670489194422429 \t -0.4302853773034897\n",
            "17     \t [10.         10.         15.          1.          8.48465764  1.        ]. \t  \u001b[92m-0.42501822335102446\u001b[0m \t -0.42501822335102446\n",
            "18     \t [6.13744077 3.1762168  7.         0.71715124 1.         0.21437753]. \t  -0.6750122354871972 \t -0.42501822335102446\n",
            "19     \t [1.64428569 5.99961621 5.         0.5        1.         0.1       ]. \t  -0.678730856611528 \t -0.42501822335102446\n",
            "20     \t [ 4.49234285  8.67423062  5.          0.98662776 13.          0.49445311]. \t  -0.5818099564071246 \t -0.42501822335102446\n",
            "21     \t [0.57290039 5.56719442 5.         0.67279386 7.         0.53348581]. \t  -0.5895638008235796 \t -0.42501822335102446\n",
            "22     \t [10.          4.02943815 13.82894698  1.          6.82894698  1.        ]. \t  \u001b[92m-0.4250127961953966\u001b[0m \t -0.4250127961953966\n",
            "23     \t [ 4.38793869  1.41142449  7.          0.86080475 19.          0.94489508]. \t  -0.4777873033950965 \t -0.4250127961953966\n",
            "24     \t [ 0.49745643  7.19653642 11.          0.74387293  7.          0.13430429]. \t  -0.6757953351254289 \t -0.4250127961953966\n",
            "25     \t [ 2.48543324  2.77487947 14.          0.6702701   1.          0.4963196 ]. \t  -0.5782297244179342 \t -0.4250127961953966\n",
            "26     \t [ 3.920133   10.         14.97162954  1.         12.97162954  1.        ]. \t  \u001b[92m-0.4224229094097203\u001b[0m \t -0.4224229094097203\n",
            "27     \t [ 0.83008899  3.83635714  9.41027976  0.5        11.41027976  0.1       ]. \t  -0.6796033025458386 \t -0.4224229094097203\n",
            "28     \t [ 7.51283684  9.31635749 10.36124915  1.         11.36124915  1.        ]. \t  -0.43153390598423147 \t -0.4224229094097203\n",
            "29     \t [ 8.02471736  0.41289154 14.          0.69081331 19.          0.12069753]. \t  -0.6699490024623577 \t -0.4224229094097203\n",
            "30     \t [10.          5.00327564  7.69449908  1.          3.69449908  1.        ]. \t  -0.43280639037823576 \t -0.4224229094097203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.636203190294953"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc033ae3-bae8-451b-9a20-0bf32de4a3ff"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_exact_2 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_2 = dGPGO(surrogate_exact_2, Acquisition_new(util_exact), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_2 = exact_2.getResult()[0]\n",
        "params_exact_2['max_depth'] = int(params_exact_2['max_depth'])\n",
        "params_exact_2['min_child_weight'] = int(params_exact_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_exact_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_exact_2 = xgb.train(params_exact_2, dX_exact_train2)\n",
        "pred_exact_2 = model_exact_2.predict(dX_exact_test2)\n",
        "\n",
        "rmse_exact_2 = np.sqrt(mean_squared_error(pred_exact_2, y_test2))\n",
        "rmse_exact_2"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]. \t  -0.5147867600449749 \t -0.4765694615523879\n",
            "init   \t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]. \t  -0.4765694615523879 \t -0.4765694615523879\n",
            "init   \t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]. \t  -0.4946399399702889 \t -0.4765694615523879\n",
            "init   \t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]. \t  -0.5884370816585467 \t -0.4765694615523879\n",
            "init   \t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]. \t  -0.584982798458911 \t -0.4765694615523879\n",
            "1      \t [9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]. \t  -0.47692913742153503 \t -0.4765694615523879\n",
            "2      \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]. \t  \u001b[92m-0.42932966844762255\u001b[0m \t -0.42932966844762255\n",
            "3      \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]. \t  -0.5235565502085555 \t -0.42932966844762255\n",
            "4      \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]. \t  -0.5840366351865409 \t -0.42932966844762255\n",
            "5      \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]. \t  -0.5185020925938802 \t -0.42932966844762255\n",
            "6      \t [ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]. \t  -0.49484140351085004 \t -0.42932966844762255\n",
            "7      \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]. \t  -0.5305156688763031 \t -0.42932966844762255\n",
            "8      \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]. \t  -0.6754055457447411 \t -0.42932966844762255\n",
            "9      \t [ 4.57706999  8.33565192 11.          0.6188546   7.          0.54017925]. \t  -0.5200991055645933 \t -0.42932966844762255\n",
            "10     \t [0.43411125 0.         6.66146717 0.5        1.         0.1       ]. \t  -0.6772603800118844 \t -0.42932966844762255\n",
            "11     \t [4.59560507 9.66694693 5.         0.8652774  6.         0.90565092]. \t  \u001b[92m-0.428196714239337\u001b[0m \t -0.428196714239337\n",
            "12     \t [ 3.17448409  4.53454564 14.28015729  1.         19.28015729  1.        ]. \t  \u001b[92m-0.37381161287497683\u001b[0m \t -0.37381161287497683\n",
            "13     \t [ 6.62295179  6.77584978 14.          0.65936287 12.          0.50955919]. \t  -0.5199635069944675 \t -0.37381161287497683\n",
            "14     \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]. \t  -0.5119371184217966 \t -0.37381161287497683\n",
            "15     \t [ 9.80429676  9.59801315  7.          0.61168386 14.          0.66107461]. \t  -0.5048932382710399 \t -0.37381161287497683\n",
            "16     \t [ 0.57492216  8.73281603  8.          0.69247391 11.          0.62472664]. \t  -0.4970509796507859 \t -0.37381161287497683\n",
            "17     \t [ 9.61885664  9.78589131 14.          0.8903706   1.          0.14094172]. \t  -0.6776999663731892 \t -0.37381161287497683\n",
            "18     \t [ 6.40066412  4.91088177 10.          0.95515831  8.          0.83809993]. \t  -0.4705510421792326 \t -0.37381161287497683\n",
            "19     \t [ 0.34964202  6.10551304 14.          0.81887518  8.          0.79373024]. \t  -0.46222390225012616 \t -0.37381161287497683\n",
            "20     \t [0.62273619 1.29124124 6.         0.81123451 8.         0.42451055]. \t  -0.5869340733116714 \t -0.37381161287497683\n",
            "21     \t [ 9.43489051  1.92776052  5.          0.94651025 13.          0.65362327]. \t  -0.5250415492325773 \t -0.37381161287497683\n",
            "22     \t [10. 10. 15.  1. 20.  1.]. \t  -0.380079913763185 \t -0.37381161287497683\n",
            "23     \t [ 9.52098346  0.33052792 12.          0.76433264 19.          0.79735818]. \t  -0.4717031985185466 \t -0.37381161287497683\n",
            "24     \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]. \t  -0.5934955971475885 \t -0.37381161287497683\n",
            "25     \t [ 0.16062273  8.48138353 13.          0.56952276 19.          0.688064  ]. \t  -0.48832296665657715 \t -0.37381161287497683\n",
            "26     \t [ 9.33066006  2.69311478 11.          0.84131379 14.          0.25006316]. \t  -0.6777143400650546 \t -0.37381161287497683\n",
            "27     \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]. \t  -0.47327191349354314 \t -0.37381161287497683\n",
            "28     \t [ 7.32261517  3.77223908 13.          0.66532455  8.          0.34613674]. \t  -0.5914165793078185 \t -0.37381161287497683\n",
            "29     \t [10.          7.0069005  15.          1.          6.04827958  1.        ]. \t  -0.3763281294876623 \t -0.37381161287497683\n",
            "30     \t [ 9.52846941 10.         14.72335748  1.         14.72335748  1.        ]. \t  -0.378879064016483 \t -0.37381161287497683\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.632507471550557"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c408584-2563-4ada-9b0d-03e0d5566f02"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_exact_3 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_3 = dGPGO(surrogate_exact_3, Acquisition_new(util_exact), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_3 = exact_3.getResult()[0]\n",
        "params_exact_3['max_depth'] = int(params_exact_3['max_depth'])\n",
        "params_exact_3['min_child_weight'] = int(params_exact_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_exact_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_exact_3 = xgb.train(params_exact_3, dX_exact_train3)\n",
        "pred_exact_3 = model_exact_3.predict(dX_exact_test3)\n",
        "\n",
        "rmse_exact_3 = np.sqrt(mean_squared_error(pred_exact_3, y_test3))\n",
        "rmse_exact_3"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]. \t  -0.7165783188757435 \t -0.6409647951145182\n",
            "init   \t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]. \t  -0.7204431346766296 \t -0.6409647951145182\n",
            "init   \t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]. \t  -0.6409647951145182 \t -0.6409647951145182\n",
            "init   \t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]. \t  -0.7214290072967551 \t -0.6409647951145182\n",
            "init   \t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]. \t  -0.6558401549443296 \t -0.6409647951145182\n",
            "1      \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]. \t  -0.652766690473656 \t -0.6409647951145182\n",
            "2      \t [ 7.69133691  0.25025283 10.          0.52101543 12.          0.10383979]. \t  -0.7148542073105238 \t -0.6409647951145182\n",
            "3      \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]. \t  -0.7211360280437672 \t -0.6409647951145182\n",
            "4      \t [ 4.06522402  9.52384028  5.          0.68629723 13.          0.87617671]. \t  \u001b[92m-0.49349103668500904\u001b[0m \t -0.49349103668500904\n",
            "5      \t [3.68953475 2.95525094 5.         0.6894371  8.         0.99869195]. \t  \u001b[92m-0.4907212254462726\u001b[0m \t -0.4907212254462726\n",
            "6      \t [10.          4.44401369 15.          1.          5.92600478  1.        ]. \t  \u001b[92m-0.4608981647138533\u001b[0m \t -0.4608981647138533\n",
            "7      \t [9.34527135 5.20373839 7.         0.72717205 2.         0.5760477 ]. \t  -0.63446880770149 \t -0.4608981647138533\n",
            "8      \t [10.         10.         15.          1.         19.97701211  1.        ]. \t  -0.4715894798301793 \t -0.4608981647138533\n",
            "9      \t [ 2.90369752  3.11254054  6.          0.81932406 16.          0.23613277]. \t  -0.7197796376906721 \t -0.4608981647138533\n",
            "10     \t [ 4.43398983  0.1775468  13.          0.67757521 18.          0.85307217]. \t  -0.5210602575470441 \t -0.4608981647138533\n",
            "11     \t [ 1.02918863  9.32189805 13.          0.88333707  1.          0.86998588]. \t  \u001b[92m-0.45190108244647254\u001b[0m \t -0.45190108244647254\n",
            "12     \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]. \t  -0.4804793139396266 \t -0.45190108244647254\n",
            "13     \t [ 9.38226635  4.01107902 14.          0.88645966 17.          0.87374815]. \t  -0.47315524396225167 \t -0.45190108244647254\n",
            "14     \t [0.86375274 7.69964496 8.         0.67182269 1.         0.12474838]. \t  -0.7214117317911921 \t -0.45190108244647254\n",
            "15     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.7128635442438903 \t -0.45190108244647254\n",
            "16     \t [ 1.04436425  9.32284009 12.          0.59300158  7.          0.9522161 ]. \t  -0.46635534339044915 \t -0.45190108244647254\n",
            "17     \t [9.56016332 0.73003765 9.         0.53281522 5.         0.61724123]. \t  -0.6373982047393342 \t -0.45190108244647254\n",
            "18     \t [ 8.50267404  2.17033522  6.          0.50604942 19.          0.82390736]. \t  -0.537393179824783 \t -0.45190108244647254\n",
            "19     \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]. \t  -0.7096913524170247 \t -0.45190108244647254\n",
            "20     \t [6.03739837 7.88708686 5.         0.82648265 8.         0.58420151]. \t  -0.6285880374153235 \t -0.45190108244647254\n",
            "21     \t [ 3.40633968  0.23269315 10.          0.64291679  9.          0.50934585]. \t  -0.6564873254753503 \t -0.45190108244647254\n",
            "22     \t [4.54354591 0.7139453  5.         0.57307288 3.         0.89633084]. \t  -0.48788407395010636 \t -0.45190108244647254\n",
            "23     \t [ 6.64966697  8.448574    5.          0.65443865 19.          0.53636799]. \t  -0.6532290988903501 \t -0.45190108244647254\n",
            "24     \t [ 0.04997226  0.57243486  5.          0.9748128  12.          0.24835402]. \t  -0.7195165728779045 \t -0.45190108244647254\n",
            "25     \t [7.04836549 4.50704597 9.         0.81696224 8.         0.24681977]. \t  -0.7201857896723045 \t -0.45190108244647254\n",
            "26     \t [0.33454906 4.8293531  6.         0.75998498 5.         0.78354586]. \t  -0.5258469010005469 \t -0.45190108244647254\n",
            "27     \t [ 8.21944232  0.76315735 14.          0.70782001  3.          0.58640207]. \t  -0.639082678567249 \t -0.45190108244647254\n",
            "28     \t [ 7.24312708 10.         14.15470386  1.         14.15470386  1.        ]. \t  -0.46383505858855684 \t -0.45190108244647254\n",
            "29     \t [ 2.8976823   3.26382981  9.2713284   1.         19.2713284   1.        ]. \t  -0.4698342461158555 \t -0.45190108244647254\n",
            "30     \t [ 0.50646974  6.72570721  7.          0.51798099 18.          0.75487674]. \t  -0.530130659897067 \t -0.45190108244647254\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.649527586702978"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKX_nfEaaAwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e7f55e-26b7-4827-9495-963f6f7bac38"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_exact_4 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_4 = dGPGO(surrogate_exact_4, Acquisition_new(util_exact), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_4 = exact_4.getResult()[0]\n",
        "params_exact_4['max_depth'] = int(params_exact_4['max_depth'])\n",
        "params_exact_4['min_child_weight'] = int(params_exact_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_exact_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_exact_4 = xgb.train(params_exact_4, dX_exact_train4)\n",
        "pred_exact_4 = model_exact_4.predict(dX_exact_test4)\n",
        "\n",
        "rmse_exact_4 = np.sqrt(mean_squared_error(pred_exact_4, y_test4))\n",
        "rmse_exact_4"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]. \t  -0.5993772224326677 \t -0.4983304913999733\n",
            "init   \t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]. \t  -0.6069567430422909 \t -0.4983304913999733\n",
            "init   \t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]. \t  -0.7139334307278753 \t -0.4983304913999733\n",
            "init   \t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]. \t  -0.4983304913999733 \t -0.4983304913999733\n",
            "init   \t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]. \t  -0.7091576633146701 \t -0.4983304913999733\n",
            "1      \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]. \t  -0.7189305559932541 \t -0.4983304913999733\n",
            "2      \t [ 0.90674561  6.32290535 11.          0.94435129  1.          0.40346185]. \t  -0.659235838187788 \t -0.4983304913999733\n",
            "3      \t [ 7.37481669  1.69273565 11.          0.93066167  4.          0.26673965]. \t  -0.71175266619209 \t -0.4983304913999733\n",
            "4      \t [10.         10.         15.          1.         15.43495193  1.        ]. \t  \u001b[92m-0.4781108273515432\u001b[0m \t -0.4781108273515432\n",
            "5      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.7094830419675008 \t -0.4781108273515432\n",
            "6      \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]. \t  -0.7111637954440517 \t -0.4781108273515432\n",
            "7      \t [ 4.78239078  2.50215387 14.          0.69422942 12.          0.74303412]. \t  -0.5926245904955176 \t -0.4781108273515432\n",
            "8      \t [ 3.32085573  3.92632573  5.          0.69399916 17.          0.37025761]. \t  -0.659744871018594 \t -0.4781108273515432\n",
            "9      \t [2.90623288 8.58681802 5.         0.88137808 4.         0.34595373]. \t  -0.659126699328721 \t -0.4781108273515432\n",
            "10     \t [ 9.3450382   8.82768787 11.          0.76868692  7.          0.8502727 ]. \t  -0.5942242759669181 \t -0.4781108273515432\n",
            "11     \t [ 9.65147322  0.33792642 12.          0.92327424 17.          0.84355403]. \t  -0.5882916778627522 \t -0.4781108273515432\n",
            "12     \t [ 6.17075402  3.72287174 14.64649013  1.         20.          1.        ]. \t  \u001b[92m-0.47349932558131813\u001b[0m \t -0.47349932558131813\n",
            "13     \t [0.69118951 0.05924245 6.         0.53870729 9.         0.9249957 ]. \t  -0.517996124617491 \t -0.47349932558131813\n",
            "14     \t [ 0.51187296  7.77314276 11.          0.63389119 15.          0.16589245]. \t  -0.7108031779087576 \t -0.47349932558131813\n",
            "15     \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]. \t  -0.6194547986660568 \t -0.47349932558131813\n",
            "16     \t [ 1.59376327  9.3637724   5.          0.56698742 13.          0.29635446]. \t  -0.6589347550965012 \t -0.47349932558131813\n",
            "17     \t [10.          3.76108521 13.98637772  1.          8.98637772  1.        ]. \t  -0.48116475380927726 \t -0.47349932558131813\n",
            "18     \t [ 8.65389242  8.53460313 10.          0.87527068 19.          0.43097904]. \t  -0.6260384457753234 \t -0.47349932558131813\n",
            "19     \t [6.04758549 0.99675153 5.         0.67521977 7.         0.8442095 ]. \t  -0.6044447660961294 \t -0.47349932558131813\n",
            "20     \t [ 5.45995334  4.47434923 10.          0.95360601  8.          0.67665191]. \t  -0.6037728152697166 \t -0.47349932558131813\n",
            "21     \t [ 2.53595099  3.58249861 14.          0.85804634  5.          0.53784435]. \t  -0.6296598249453945 \t -0.47349932558131813\n",
            "22     \t [ 7.63464915  2.26565433  8.          0.71110251 14.          0.25276999]. \t  -0.7117541403159702 \t -0.47349932558131813\n",
            "23     \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]. \t  -0.7139636713851948 \t -0.47349932558131813\n",
            "24     \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]. \t  -0.524958204283032 \t -0.47349932558131813\n",
            "25     \t [ 2.07051041  1.52366516 10.          0.69512439 11.          0.21098416]. \t  -0.7130630485402061 \t -0.47349932558131813\n",
            "26     \t [ 3.54197257 10.         13.35585451  1.         20.          1.        ]. \t  \u001b[92m-0.47246580665078924\u001b[0m \t -0.47246580665078924\n",
            "27     \t [ 6.95280947  8.17057871 13.84240759  1.         11.54563865  1.        ]. \t  -0.476678529741508 \t -0.47246580665078924\n",
            "28     \t [ 0.40130386  1.97007932 14.          0.94919936  9.          0.10604155]. \t  -0.7155582417169046 \t -0.47246580665078924\n",
            "29     \t [0.03619008 1.10829759 9.         0.94653474 4.         0.47066305]. \t  -0.6261794289942604 \t -0.47246580665078924\n",
            "30     \t [ 8.64902545  3.53966492  8.52589206  1.         19.52589206  1.        ]. \t  -0.486707852944061 \t -0.47246580665078924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.873157106793727"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d38fb4-95d8-45c6-d275-d30f1872c46c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_exact_5 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_5 = dGPGO(surrogate_exact_5, Acquisition_new(util_exact), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_5 = exact_5.getResult()[0]\n",
        "params_exact_5['max_depth'] = int(params_exact_5['max_depth'])\n",
        "params_exact_5['min_child_weight'] = int(params_exact_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_exact_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_exact_5 = xgb.train(params_exact_5, dX_exact_train5)\n",
        "pred_exact_5 = model_exact_5.predict(dX_exact_test5)\n",
        "\n",
        "rmse_exact_5 = np.sqrt(mean_squared_error(pred_exact_5, y_test5))\n",
        "rmse_exact_5"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]. \t  -0.5323233521622429 \t -0.4868347596133297\n",
            "init   \t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]. \t  -0.4868347596133297 \t -0.4868347596133297\n",
            "init   \t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]. \t  -0.586475577548452 \t -0.4868347596133297\n",
            "init   \t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]. \t  -0.633609225551848 \t -0.4868347596133297\n",
            "init   \t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]. \t  -0.6326249738244012 \t -0.4868347596133297\n",
            "1      \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]. \t  -0.5882279171378358 \t -0.4868347596133297\n",
            "2      \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]. \t  -0.6326090413479479 \t -0.4868347596133297\n",
            "3      \t [ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]. \t  -0.5345515814760515 \t -0.4868347596133297\n",
            "4      \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]. \t  -0.63240536298746 \t -0.4868347596133297\n",
            "5      \t [10.         10.         13.46923759  1.         20.          1.        ]. \t  \u001b[92m-0.4315727514475647\u001b[0m \t -0.4315727514475647\n",
            "6      \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]. \t  -0.5654109525719464 \t -0.4315727514475647\n",
            "7      \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]. \t  -0.5157271802459567 \t -0.4315727514475647\n",
            "8      \t [ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]. \t  -0.43338395515567535 \t -0.4315727514475647\n",
            "9      \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]. \t  -0.6323995483897046 \t -0.4315727514475647\n",
            "10     \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]. \t  -0.44834224855405436 \t -0.4315727514475647\n",
            "11     \t [ 9.88162042  4.98501997  7.          0.71514689 11.          0.88825005]. \t  -0.4486026878328516 \t -0.4315727514475647\n",
            "12     \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]. \t  -0.47422527111773516 \t -0.4315727514475647\n",
            "13     \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]. \t  -0.5043962477805882 \t -0.4315727514475647\n",
            "14     \t [ 0.58203439  2.93434953  5.          0.5        13.97241802  0.1       ]. \t  -0.635809960698837 \t -0.4315727514475647\n",
            "15     \t [ 1.02937954  1.87162456 12.          0.80403735 18.          0.49076122]. \t  -0.5307136605231835 \t -0.4315727514475647\n",
            "16     \t [ 9.85923825  0.4401096  14.          0.51176114 16.          0.65114761]. \t  -0.5095834513256413 \t -0.4315727514475647\n",
            "17     \t [ 1.11081165  8.62779853  7.          0.59553888 14.          0.69059047]. \t  -0.5086079472605 \t -0.4315727514475647\n",
            "18     \t [ 6.81824956  0.34511024  6.          0.68216555 12.          0.49718858]. \t  -0.5600482769316893 \t -0.4315727514475647\n",
            "19     \t [ 9.84068455 10.          8.11153884  1.         15.11153884  1.        ]. \t  -0.4372402749770904 \t -0.4315727514475647\n",
            "20     \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]. \t  -0.5167803781864203 \t -0.4315727514475647\n",
            "21     \t [ 8.47395372 10.         14.26552884  1.          4.26552884  1.        ]. \t  \u001b[92m-0.4285493221295626\u001b[0m \t -0.4285493221295626\n",
            "22     \t [1.25829691 6.65743124 9.00266256 0.5        6.00266256 0.1       ]. \t  -0.635813808515634 \t -0.4285493221295626\n",
            "23     \t [ 9.60183769  3.43959486 14.          0.61022694  4.          0.76574329]. \t  -0.47161269058910615 \t -0.4285493221295626\n",
            "24     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6365240351934163 \t -0.4285493221295626\n",
            "25     \t [ 7.8290944   6.65463898 14.          0.74840184 15.          0.9196642 ]. \t  -0.43664120595115535 \t -0.4285493221295626\n",
            "26     \t [ 0.65904826  3.00639193 10.          0.88267232 10.          0.15011078]. \t  -0.6326313583048015 \t -0.4285493221295626\n",
            "27     \t [10.          3.7224514  13.63198658  1.         20.          1.        ]. \t  -0.4316511845970837 \t -0.4285493221295626\n",
            "28     \t [9.64880583 0.85455793 9.         0.80366346 1.         0.54097439]. \t  -0.5442200644862888 \t -0.4285493221295626\n",
            "29     \t [ 4.55827125  5.55360957  5.          0.63524357 11.          0.36911555]. \t  -0.5905722413685737 \t -0.4285493221295626\n",
            "30     \t [ 5.73044668  0.89641415 13.          0.75668794  1.          0.63369635]. \t  -0.5012513473439557 \t -0.4285493221295626\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.622205923248069"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulhEolsxaG4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c338893-a0f8-42aa-9f31-313ecf0d666b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_exact_6 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_6 = dGPGO(surrogate_exact_6, Acquisition_new(util_exact), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_6 = exact_6.getResult()[0]\n",
        "params_exact_6['max_depth'] = int(params_exact_6['max_depth'])\n",
        "params_exact_6['min_child_weight'] = int(params_exact_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_exact_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_exact_6 = xgb.train(params_exact_6, dX_exact_train6)\n",
        "pred_exact_6 = model_exact_6.predict(dX_exact_test6)\n",
        "\n",
        "rmse_exact_6 = np.sqrt(mean_squared_error(pred_exact_6, y_test6))\n",
        "rmse_exact_6"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]. \t  -0.5719256944003751 \t -0.5405445954433028\n",
            "init   \t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]. \t  -0.6047098118480896 \t -0.5405445954433028\n",
            "init   \t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]. \t  -0.5405445954433028 \t -0.5405445954433028\n",
            "init   \t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]. \t  -0.5678490550489279 \t -0.5405445954433028\n",
            "init   \t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]. \t  -0.6145131146454834 \t -0.5405445954433028\n",
            "1      \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]. \t  -0.691031094679315 \t -0.5405445954433028\n",
            "2      \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]. \t  -0.6923819935110469 \t -0.5405445954433028\n",
            "3      \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.45961383649052767\u001b[0m \t -0.45961383649052767\n",
            "4      \t [ 9.72322443  9.21177696  5.          0.87917074 11.          0.86681736]. \t  -0.4929247454390112 \t -0.45961383649052767\n",
            "5      \t [ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]. \t  -0.476867228842187 \t -0.45961383649052767\n",
            "6      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6973217959617746 \t -0.45961383649052767\n",
            "7      \t [ 9.63031278  5.84246315  5.          0.67198611 19.          0.39028114]. \t  -0.6281448254171889 \t -0.45961383649052767\n",
            "8      \t [0.89868821 8.1396473  7.         0.63042404 9.         0.55598816]. \t  -0.6158392533783641 \t -0.45961383649052767\n",
            "9      \t [ 9.71529788  1.00762418 13.          0.62572379 11.          0.79719654]. \t  -0.5514151907416402 \t -0.45961383649052767\n",
            "10     \t [ 7.86118021  0.9120861  13.          0.79963906  4.          0.57767943]. \t  -0.5613341986087586 \t -0.45961383649052767\n",
            "11     \t [ 6.40351874  0.13565515 11.          0.58564403 18.          0.80232868]. \t  -0.5473825188827347 \t -0.45961383649052767\n",
            "12     \t [ 1.03080361  6.70895845  7.          0.73336025 19.          0.31104879]. \t  -0.6191870905906407 \t -0.45961383649052767\n",
            "13     \t [ 8.56184369  5.9405938   9.          0.75681771 14.          0.40679249]. \t  -0.6194133932344276 \t -0.45961383649052767\n",
            "14     \t [9.89801174 9.77563967 9.         0.68555662 3.         0.83921118]. \t  -0.5428995234335529 \t -0.45961383649052767\n",
            "15     \t [ 0.81201206  8.38911567 10.          0.69531918  2.          0.65392368]. \t  -0.568530469482912 \t -0.45961383649052767\n",
            "16     \t [ 8.27965778  0.50999055  5.          0.77678861 11.          0.85564655]. \t  -0.5578599886839161 \t -0.45961383649052767\n",
            "17     \t [9.69945315 4.54046025 8.         0.65261085 8.         0.4333888 ]. \t  -0.6146704906060295 \t -0.45961383649052767\n",
            "18     \t [10.         10.         13.39365582  1.         13.39365582  1.        ]. \t  -0.46143294097954507 \t -0.45961383649052767\n",
            "19     \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]. \t  -0.692321289717216 \t -0.45961383649052767\n",
            "20     \t [3.17596775 0.         5.         0.5        6.26071179 0.1       ]. \t  -0.6943453173394896 \t -0.45961383649052767\n",
            "21     \t [ 0.02519374  5.62854699 13.          0.51256455 19.          0.19799464]. \t  -0.6949144583274668 \t -0.45961383649052767\n",
            "22     \t [ 4.367309    8.81527067  9.          0.92883242 13.          0.50948476]. \t  -0.6069423947623707 \t -0.45961383649052767\n",
            "23     \t [ 4.93940722  2.67316592 10.87631453  1.          7.87631453  1.        ]. \t  \u001b[92m-0.45047064589547964\u001b[0m \t -0.45047064589547964\n",
            "24     \t [ 3.2089954   7.98885441 11.          0.74347413  7.          0.34430429]. \t  -0.6185988563792412 \t -0.45047064589547964\n",
            "25     \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]. \t  -0.48611573402244906 \t -0.45047064589547964\n",
            "26     \t [10.          7.44066463 15.          1.          8.71300275  1.        ]. \t  -0.4577708962671858 \t -0.45047064589547964\n",
            "27     \t [ 0.41362502  1.49760501 13.          0.83609721 16.          0.65630591]. \t  -0.56259350016892 \t -0.45047064589547964\n",
            "28     \t [ 5.07679212  1.16970894  6.          0.64799435 18.          0.77259117]. \t  -0.5516264813413544 \t -0.45047064589547964\n",
            "29     \t [ 1.0021313   4.9490761  14.          0.62016719  1.          0.18537333]. \t  -0.7015073974139394 \t -0.45047064589547964\n",
            "30     \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]. \t  -0.5634086343110793 \t -0.45047064589547964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.792966213759572"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYebx3RVaJ1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af445ac3-411f-4634-8d34-78419ac7b3ce"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_exact_7 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_7 = dGPGO(surrogate_exact_7, Acquisition_new(util_exact), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_7 = exact_7.getResult()[0]\n",
        "params_exact_7['max_depth'] = int(params_exact_7['max_depth'])\n",
        "params_exact_7['min_child_weight'] = int(params_exact_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_exact_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_exact_7 = xgb.train(params_exact_7, dX_exact_train7)\n",
        "pred_exact_7 = model_exact_7.predict(dX_exact_test7)\n",
        "\n",
        "rmse_exact_7 = np.sqrt(mean_squared_error(pred_exact_7, y_test7))\n",
        "rmse_exact_7"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]. \t  -0.44500885348659536 \t -0.44173641078261416\n",
            "init   \t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]. \t  -0.4488374676936292 \t -0.44173641078261416\n",
            "init   \t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]. \t  -0.5669653799025498 \t -0.44173641078261416\n",
            "init   \t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]. \t  -0.4661284696195417 \t -0.44173641078261416\n",
            "init   \t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]. \t  -0.44173641078261416 \t -0.44173641078261416\n",
            "1      \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]. \t  -0.5720117286339644 \t -0.44173641078261416\n",
            "2      \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]. \t  -0.5040023079321674 \t -0.44173641078261416\n",
            "3      \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.44162641630164357\u001b[0m \t -0.44162641630164357\n",
            "4      \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]. \t  -0.4882732220224809 \t -0.44162641630164357\n",
            "5      \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]. \t  -0.568100519925974 \t -0.44162641630164357\n",
            "6      \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]. \t  -0.44744611331217216 \t -0.44162641630164357\n",
            "7      \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]. \t  -0.6941989633599238 \t -0.44162641630164357\n",
            "8      \t [ 1.95327375  0.09413692  7.          0.63967551 19.          0.52105045]. \t  -0.5139990320068838 \t -0.44162641630164357\n",
            "9      \t [ 9.43398236  5.14820353 11.          0.95240771 10.          0.75059461]. \t  -0.454116883517573 \t -0.44162641630164357\n",
            "10     \t [ 0.25030147  5.86047618  7.          0.62148035 15.          0.70956246]. \t  -0.49234467840129764 \t -0.44162641630164357\n",
            "11     \t [0.         0.         5.         0.5        9.51343669 0.1       ]. \t  -0.6894229799199877 \t -0.44162641630164357\n",
            "12     \t [1.58883627 9.28820775 5.         0.93909681 3.         0.6284681 ]. \t  -0.4806756100759113 \t -0.44162641630164357\n",
            "13     \t [ 8.68686713  7.27037095  5.          0.65538775 10.          0.84203491]. \t  -0.483133641434514 \t -0.44162641630164357\n",
            "14     \t [ 5.05369665  2.67147005  5.          0.51290284 10.          0.64085   ]. \t  -0.5141066990730631 \t -0.44162641630164357\n",
            "15     \t [7.56007588 9.31763773 8.         0.9626622  1.         0.9152255 ]. \t  -0.4495767577917391 \t -0.44162641630164357\n",
            "16     \t [ 8.74666383  0.43179289 13.          0.67076843  6.          0.55612407]. \t  -0.5025434533496459 \t -0.44162641630164357\n",
            "17     \t [ 0.08258912  2.04682383 12.          0.59206459 18.          0.58057909]. \t  -0.47949559740392883 \t -0.44162641630164357\n",
            "18     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6900797807513596 \t -0.44162641630164357\n",
            "19     \t [ 9.52986466 10.         15.          1.          8.44250106  1.        ]. \t  \u001b[92m-0.43092064403292785\u001b[0m \t -0.43092064403292785\n",
            "20     \t [7.65600902 9.97286134 7.         0.9314906  6.         0.20089488]. \t  -0.6825558150002408 \t -0.43092064403292785\n",
            "21     \t [ 1.02977609  0.66145279  7.          0.5528148  14.          0.97405529]. \t  -0.47370825812268763 \t -0.43092064403292785\n",
            "22     \t [ 7.08221125  2.69405583  7.95899478  1.         19.95899478  1.        ]. \t  -0.4521011392910722 \t -0.43092064403292785\n",
            "23     \t [ 4.45475741  9.04863317  5.          0.93353577 13.          0.79638216]. \t  -0.4748410465478646 \t -0.43092064403292785\n",
            "24     \t [ 4.2776564   9.48283936 11.          0.71877499 12.          0.19591223]. \t  -0.6824030520219181 \t -0.43092064403292785\n",
            "25     \t [ 6.47734132 10.         15.          1.         14.40523842  1.        ]. \t  -0.4368433693884118 \t -0.43092064403292785\n",
            "26     \t [ 5.03032449  1.46993678 12.          0.54826603 16.          0.88093043]. \t  -0.46556482001154686 \t -0.43092064403292785\n",
            "27     \t [9.91546913 0.35662679 7.         0.87706909 8.         0.31009443]. \t  -0.5699297548076715 \t -0.43092064403292785\n",
            "28     \t [ 8.54306227 10.          9.36250562  1.         18.36250562  1.        ]. \t  -0.4470196011783332 \t -0.43092064403292785\n",
            "29     \t [ 7.19768346  0.7672239  11.          0.81471216 11.          0.73682143]. \t  -0.45412172002030005 \t -0.43092064403292785\n",
            "30     \t [ 8.69754174  1.30629516 14.          0.58134507  2.          0.42871645]. \t  -0.505490214660777 \t -0.43092064403292785\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.58514934982099"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba120b0-7b72-42ce-bf44-faab83a79ed4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_exact_8 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_8 = dGPGO(surrogate_exact_8, Acquisition_new(util_exact), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_8 = exact_8.getResult()[0]\n",
        "params_exact_8['max_depth'] = int(params_exact_8['max_depth'])\n",
        "params_exact_8['min_child_weight'] = int(params_exact_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_exact_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_exact_8 = xgb.train(params_exact_8, dX_exact_train8)\n",
        "pred_exact_8 = model_exact_8.predict(dX_exact_test8)\n",
        "\n",
        "rmse_exact_8 = np.sqrt(mean_squared_error(pred_exact_8, y_test8))\n",
        "rmse_exact_8"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]. \t  -0.5450023023990902 \t -0.47785117417083445\n",
            "init   \t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]. \t  -0.48415390639601685 \t -0.47785117417083445\n",
            "init   \t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]. \t  -0.5514374023096014 \t -0.47785117417083445\n",
            "init   \t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]. \t  -0.509390123714371 \t -0.47785117417083445\n",
            "init   \t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]. \t  -0.47785117417083445 \t -0.47785117417083445\n",
            "1      \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]. \t  -0.4933129789895931 \t -0.47785117417083445\n",
            "2      \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]. \t  -0.6339615084112526 \t -0.47785117417083445\n",
            "3      \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]. \t  -0.5297996778038847 \t -0.47785117417083445\n",
            "4      \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]. \t  -0.5527447722333402 \t -0.47785117417083445\n",
            "5      \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]. \t  -0.5047189705784817 \t -0.47785117417083445\n",
            "6      \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]. \t  -0.4848490795565376 \t -0.47785117417083445\n",
            "7      \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]. \t  -0.5564925838622898 \t -0.47785117417083445\n",
            "8      \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]. \t  -0.5530199153286809 \t -0.47785117417083445\n",
            "9      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6382770211623013 \t -0.47785117417083445\n",
            "10     \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]. \t  -0.4791797818281145 \t -0.47785117417083445\n",
            "11     \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]. \t  -0.635838370822804 \t -0.47785117417083445\n",
            "12     \t [ 6.07416022  0.73060636  9.          0.91953118 17.          0.26381452]. \t  -0.6308165287808005 \t -0.47785117417083445\n",
            "13     \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]. \t  -0.6330775313057753 \t -0.47785117417083445\n",
            "14     \t [1.36072521 8.96337054 5.         0.74382165 2.         0.12580076]. \t  -0.6310296426785355 \t -0.47785117417083445\n",
            "15     \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.46870913378803636\u001b[0m \t -0.46870913378803636\n",
            "16     \t [0.05861183 0.85510206 7.         0.55669041 9.         0.24118856]. \t  -0.6331690218855945 \t -0.46870913378803636\n",
            "17     \t [ 0.09889076  5.63526532 14.          0.81316857 16.          0.71340054]. \t  -0.4965834253575623 \t -0.46870913378803636\n",
            "18     \t [ 8.81884199  0.29557486 11.          0.94612367  2.          0.80082225]. \t  -0.4752232906149384 \t -0.46870913378803636\n",
            "19     \t [ 1.3544572   9.55649539 12.          0.53328948 12.          0.91626416]. \t  -0.47805019356168055 \t -0.46870913378803636\n",
            "20     \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]. \t  -0.4812223540836058 \t -0.46870913378803636\n",
            "21     \t [8.49304258 9.45420615 6.         0.52298498 5.         0.36186114]. \t  -0.5693257561055802 \t -0.46870913378803636\n",
            "22     \t [ 0.76637948  1.6718521   5.          0.89180884 15.          0.76035097]. \t  -0.5096944757591124 \t -0.46870913378803636\n",
            "23     \t [ 9.54274406  9.98737528 14.8800219   1.          3.8800219   1.        ]. \t  \u001b[92m-0.46239274654907536\u001b[0m \t -0.46239274654907536\n",
            "24     \t [ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]. \t  -0.4805143253081433 \t -0.46239274654907536\n",
            "25     \t [ 2.00363843  0.25557305 13.          0.79852696 19.          0.41982126]. \t  -0.5500644701753457 \t -0.46239274654907536\n",
            "26     \t [5.48236526 0.         5.         0.5        6.5382367  0.1       ]. \t  -0.6375931368891397 \t -0.46239274654907536\n",
            "27     \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]. \t  -0.5440457259258048 \t -0.46239274654907536\n",
            "28     \t [ 1.06330602  9.84698732  5.          0.70744161 15.          0.6986094 ]. \t  -0.5340764790757249 \t -0.46239274654907536\n",
            "29     \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]. \t  -0.5059919280994952 \t -0.46239274654907536\n",
            "30     \t [8.66270612 8.68970778 9.         0.80306345 1.         0.23433357]. \t  -0.6376715740042693 \t -0.46239274654907536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.427129179249198"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0edb127c-6a70-4708-beff-6d7c450eab2b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_exact_9 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_9 = dGPGO(surrogate_exact_9, Acquisition_new(util_exact), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_9 = exact_9.getResult()[0]\n",
        "params_exact_9['max_depth'] = int(params_exact_9['max_depth'])\n",
        "params_exact_9['min_child_weight'] = int(params_exact_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_exact_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_exact_9 = xgb.train(params_exact_9, dX_exact_train9)\n",
        "pred_exact_9 = model_exact_9.predict(dX_exact_test9)\n",
        "\n",
        "rmse_exact_9 = np.sqrt(mean_squared_error(pred_exact_9, y_test9))\n",
        "rmse_exact_9"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]. \t  -0.6545930802207814 \t -0.4584168030068045\n",
            "init   \t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]. \t  -0.7166132091943936 \t -0.4584168030068045\n",
            "init   \t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]. \t  -0.4584168030068045 \t -0.4584168030068045\n",
            "init   \t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]. \t  -0.48839211091816903 \t -0.4584168030068045\n",
            "init   \t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]. \t  -0.46354466019784824 \t -0.4584168030068045\n",
            "1      \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]. \t  -0.7145926373770018 \t -0.4584168030068045\n",
            "2      \t [ 8.16285902  8.43489929  9.          0.96605421 10.          0.79940153]. \t  -0.48073960577713015 \t -0.4584168030068045\n",
            "3      \t [ 3.67545472  4.78145311 14.          0.63123486 17.          0.4863889 ]. \t  -0.4908200532861475 \t -0.4584168030068045\n",
            "4      \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]. \t  -0.489212631501365 \t -0.4584168030068045\n",
            "5      \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.4552859414238041\u001b[0m \t -0.4552859414238041\n",
            "6      \t [ 0.58316798  9.10724777  7.          0.55034291 18.          0.73246248]. \t  -0.49170853859809416 \t -0.4552859414238041\n",
            "7      \t [ 0.65024006  0.20015298 14.          0.90298726 13.          0.95798937]. \t  \u001b[92m-0.4476685066942845\u001b[0m \t -0.4476685066942845\n",
            "8      \t [ 0.56883492  2.21937218  6.          0.84490274 16.          0.30898926]. \t  -0.6312116357615551 \t -0.4476685066942845\n",
            "9      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.7197334224449741 \t -0.4476685066942845\n",
            "10     \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]. \t  -0.48879793709138014 \t -0.4476685066942845\n",
            "11     \t [2.63920029 2.84662126 8.         0.81372528 9.         0.70958016]. \t  -0.481015707138382 \t -0.4476685066942845\n",
            "12     \t [1.13081555 8.89608809 5.         0.68242063 1.         0.25767085]. \t  -0.7144450806724659 \t -0.4476685066942845\n",
            "13     \t [ 9.90759058  1.21564186 12.          0.74911905 17.          0.244927  ]. \t  -0.7170237831333186 \t -0.4476685066942845\n",
            "14     \t [ 4.6542071   1.48576825 11.          0.81087875 13.          0.32744452]. \t  -0.6282581260258235 \t -0.4476685066942845\n",
            "15     \t [6.5099841  8.70472582 8.         0.63069736 4.         0.74098062]. \t  -0.4853601630559038 \t -0.4476685066942845\n",
            "16     \t [ 6.38850056  0.81549118  7.          0.65603835 17.          0.33403782]. \t  -0.6320886144629803 \t -0.4476685066942845\n",
            "17     \t [ 7.81834149  9.72965303  8.          0.64259089 17.          0.22077726]. \t  -0.7151995908111178 \t -0.4476685066942845\n",
            "18     \t [ 9.00084206  1.85673124 10.          0.98011614  2.          0.25530052]. \t  -0.7164537739094682 \t -0.4476685066942845\n",
            "19     \t [ 1.5375546   6.06327242 13.          0.75086004 12.          0.81590341]. \t  -0.4754995179849649 \t -0.4476685066942845\n",
            "20     \t [ 9.14575231  1.66654712 10.          0.55201264 11.          0.27200008]. \t  -0.7181048214632002 \t -0.4476685066942845\n",
            "21     \t [ 2.60018347  8.33426121 13.          0.92542949  6.          0.59638435]. \t  -0.4707736397331013 \t -0.4476685066942845\n",
            "22     \t [ 4.99585633  9.84423212 13.          0.58601629 15.          0.62308889]. \t  -0.4890091779718368 \t -0.4476685066942845\n",
            "23     \t [ 0.79581704  0.44548953 10.          0.5535323   5.          0.9139619 ]. \t  -0.46390854310405005 \t -0.4476685066942845\n",
            "24     \t [ 9.95533251  4.91396811  9.          0.78537658 18.          0.25524459]. \t  -0.7169455661304175 \t -0.4476685066942845\n",
            "25     \t [8.2007632  5.80436627 6.         0.76635233 7.         0.49444634]. \t  -0.49510134469445033 \t -0.4476685066942845\n",
            "26     \t [ 5.75909078  1.20590443 14.          0.50716182 19.          0.51292385]. \t  -0.4984458299133214 \t -0.4476685066942845\n",
            "27     \t [10.          3.16270507 14.55867001  1.          3.55867001  1.        ]. \t  \u001b[92m-0.4433593431964754\u001b[0m \t -0.4433593431964754\n",
            "28     \t [0.06433695 6.57876132 6.         0.81327092 7.         0.85975218]. \t  -0.46583285163728017 \t -0.4433593431964754\n",
            "29     \t [ 7.12320801  5.62079639  5.          0.57720044 19.          0.34391463]. \t  -0.6359029428486718 \t -0.4433593431964754\n",
            "30     \t [5.7069599  0.         8.87800483 0.5        6.87800483 0.1       ]. \t  -0.72133901268268 \t -0.4433593431964754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.596433439654059"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5904e797-791a-4993-e19f-f6fc06b54f3a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_exact_10 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_10 = dGPGO(surrogate_exact_10, Acquisition_new(util_exact), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_10 = exact_10.getResult()[0]\n",
        "params_exact_10['max_depth'] = int(params_exact_10['max_depth'])\n",
        "params_exact_10['min_child_weight'] = int(params_exact_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_exact_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_exact_10 = xgb.train(params_exact_10, dX_exact_train10)\n",
        "pred_exact_10 = model_exact_10.predict(dX_exact_test10)\n",
        "\n",
        "rmse_exact_10 = np.sqrt(mean_squared_error(pred_exact_10, y_test10))\n",
        "rmse_exact_10"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]. \t  -0.7090674967614334 \t -0.4737745634473992\n",
            "init   \t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]. \t  -0.4737745634473992 \t -0.4737745634473992\n",
            "init   \t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]. \t  -0.4755277191484213 \t -0.4737745634473992\n",
            "init   \t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]. \t  -0.48811859212530173 \t -0.4737745634473992\n",
            "init   \t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]. \t  -0.7057210222477256 \t -0.4737745634473992\n",
            "1      \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]. \t  \u001b[92m-0.46336171949490257\u001b[0m \t -0.46336171949490257\n",
            "2      \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]. \t  -0.5661654396843121 \t -0.46336171949490257\n",
            "3      \t [ 2.20772511  4.37663949 11.          0.65455258  3.          0.57545511]. \t  -0.47392585264437637 \t -0.46336171949490257\n",
            "4      \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]. \t  -0.5586941817481679 \t -0.46336171949490257\n",
            "5      \t [ 3.75041373  9.81989522 14.          0.71370546 14.          0.97207881]. \t  \u001b[92m-0.4452927087494185\u001b[0m \t -0.4452927087494185\n",
            "6      \t [ 9.8195229   7.4353827   6.          0.61370759 10.          0.85798549]. \t  -0.4774086118126461 \t -0.4452927087494185\n",
            "7      \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.4402446003458868\u001b[0m \t -0.4402446003458868\n",
            "8      \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]. \t  -0.5719468802009684 \t -0.4402446003458868\n",
            "9      \t [ 7.94637587  1.09220418 14.          0.87360164  2.          0.44305882]. \t  -0.5655799355515964 \t -0.4402446003458868\n",
            "10     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.7119158055476253 \t -0.4402446003458868\n",
            "11     \t [ 8.93111312  8.02668001 11.          0.9737866   2.          0.19035402]. \t  -0.7049595405898625 \t -0.4402446003458868\n",
            "12     \t [0.3261262  0.3175016  8.         0.74340245 7.         0.15256221]. \t  -0.7081182561718788 \t -0.4402446003458868\n",
            "13     \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]. \t  -0.7078125731141747 \t -0.4402446003458868\n",
            "14     \t [ 0.17384891  6.43364358 13.          0.60012539 17.          0.33877166]. \t  -0.6128844704738586 \t -0.4402446003458868\n",
            "15     \t [ 9.72703693  6.521415    7.          0.50173837 17.          0.28475777]. \t  -0.712139282553683 \t -0.4402446003458868\n",
            "16     \t [ 0.          3.00646874  5.          0.5        13.37638723  0.1       ]. \t  -0.7112938606402814 \t -0.4402446003458868\n",
            "17     \t [ 2.976945    3.09934964 13.          0.72508505  8.          0.38866253]. \t  -0.6131484549573958 \t -0.4402446003458868\n",
            "18     \t [ 3.35903512  5.65946459  5.          0.99895528 10.          0.94028903]. \t  -0.46372677958736086 \t -0.4402446003458868\n",
            "19     \t [7.41359935 9.62915623 5.         0.57018445 3.         0.88569107]. \t  -0.4761028082603852 \t -0.4402446003458868\n",
            "20     \t [ 7.82589487  6.41368619 10.          0.59911364  7.          0.18950068]. \t  -0.7123364851577245 \t -0.4402446003458868\n",
            "21     \t [10.         10.         15.          1.         13.00284732  1.        ]. \t  \u001b[92m-0.4366598332008085\u001b[0m \t -0.4366598332008085\n",
            "22     \t [ 9.43678992  0.9880373   6.          0.64942758 10.          0.75777997]. \t  -0.48440674681729484 \t -0.4366598332008085\n",
            "23     \t [ 2.74221131  5.84944735  9.          0.78328007 14.          0.26186905]. \t  -0.7087495301079402 \t -0.4366598332008085\n",
            "24     \t [ 7.31542224  8.03204047 11.00369604  0.78983823 14.5050738   0.65314335]. \t  -0.47671335133410314 \t -0.4366598332008085\n",
            "25     \t [4.66195218 5.96776172 7.         0.68043003 1.         0.11094684]. \t  -0.7112331451390336 \t -0.4366598332008085\n",
            "26     \t [ 0.41334249  8.31887156 14.          0.56806567  3.          0.60385777]. \t  -0.47257013632190087 \t -0.4366598332008085\n",
            "27     \t [ 8.4662657   4.43414414  9.          0.87315205 12.          0.38094136]. \t  -0.6044231534866459 \t -0.4366598332008085\n",
            "28     \t [ 6.48383214  6.24282509 10.93394656  1.         20.          1.        ]. \t  -0.4439281605730443 \t -0.4366598332008085\n",
            "29     \t [ 7.25858886  0.05284455 11.          0.66498317  6.          0.51372905]. \t  -0.5698164077896465 \t -0.4366598332008085\n",
            "30     \t [3.54357697 3.86346702 5.         0.71857207 5.         0.34059938]. \t  -0.6117522192119104 \t -0.4366598332008085\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.594914366277459"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8890ef3-2009-4255-a4f4-75fdd4eb8f6b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_exact_11 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_11 = dGPGO(surrogate_exact_11, Acquisition_new(util_exact), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_11 = exact_11.getResult()[0]\n",
        "params_exact_11['max_depth'] = int(params_exact_11['max_depth'])\n",
        "params_exact_11['min_child_weight'] = int(params_exact_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_exact_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_exact_11 = xgb.train(params_exact_11, dX_exact_train11)\n",
        "pred_exact_11 = model_exact_11.predict(dX_exact_test11)\n",
        "\n",
        "rmse_exact_11 = np.sqrt(mean_squared_error(pred_exact_11, y_test11))\n",
        "rmse_exact_11"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]. \t  -0.5922349044250168 \t -0.49898623219170346\n",
            "init   \t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]. \t  -0.49898623219170346 \t -0.49898623219170346\n",
            "init   \t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]. \t  -0.5404544349803458 \t -0.49898623219170346\n",
            "init   \t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]. \t  -0.5108833748715963 \t -0.49898623219170346\n",
            "init   \t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]. \t  -0.5545314939891337 \t -0.49898623219170346\n",
            "1      \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]. \t  -0.5252491147925742 \t -0.49898623219170346\n",
            "2      \t [ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]. \t  \u001b[92m-0.47168134756234376\u001b[0m \t -0.47168134756234376\n",
            "3      \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]. \t  -0.6079929413869166 \t -0.47168134756234376\n",
            "4      \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]. \t  -0.6940792524812075 \t -0.47168134756234376\n",
            "5      \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]. \t  -0.5917636590409376 \t -0.47168134756234376\n",
            "6      \t [10.         10.         15.          1.         15.72304244  1.        ]. \t  \u001b[92m-0.46294681984157116\u001b[0m \t -0.46294681984157116\n",
            "7      \t [ 4.15094515  7.09288961  8.          0.62079813 14.          0.58741281]. \t  -0.5591311622225863 \t -0.46294681984157116\n",
            "8      \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]. \t  -0.5804776283328665 \t -0.46294681984157116\n",
            "9      \t [ 7.64065289  8.8630116  14.          0.9254486   9.          0.47351621]. \t  -0.5729502491617717 \t -0.46294681984157116\n",
            "10     \t [ 1.06054513  2.23745512 13.          0.92745502  9.          0.16992758]. \t  -0.6898161429627192 \t -0.46294681984157116\n",
            "11     \t [ 0.23708771  7.99354078 13.          0.65974332 19.          0.67724424]. \t  -0.5490702388089634 \t -0.46294681984157116\n",
            "12     \t [2.49649648 9.56561388 5.         0.80281761 9.         0.94453549]. \t  -0.4960673921571031 \t -0.46294681984157116\n",
            "13     \t [5.25943475 8.43895766 9.         0.84239601 5.         0.23871726]. \t  -0.68668808252312 \t -0.46294681984157116\n",
            "14     \t [3.05804163 0.         6.87570538 0.5        1.         0.1       ]. \t  -0.6992952019720133 \t -0.46294681984157116\n",
            "15     \t [1.11163956 4.97558037 7.         0.57979481 7.         0.49674445]. \t  -0.5860842685141006 \t -0.46294681984157116\n",
            "16     \t [ 5.74887715  9.86632111 12.79719093  1.         19.79719093  1.        ]. \t  \u001b[92m-0.4624492543821338\u001b[0m \t -0.4624492543821338\n",
            "17     \t [ 8.48915323  3.24520975 10.          0.86295164 12.          0.82257583]. \t  -0.48840439848756684 \t -0.4624492543821338\n",
            "18     \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]. \t  -0.5472760809270729 \t -0.4624492543821338\n",
            "19     \t [ 8.80621297  1.41648139 14.          0.58742169  8.          0.82618778]. \t  -0.5033855071125977 \t -0.4624492543821338\n",
            "20     \t [ 1.82088725  9.15875432 13.          0.70714197  2.          0.23699913]. \t  -0.6961247511825034 \t -0.4624492543821338\n",
            "21     \t [9.80647192 0.96870215 6.         0.98951642 2.         0.21475285]. \t  -0.687227580453077 \t -0.4624492543821338\n",
            "22     \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]. \t  -0.5035711766098606 \t -0.4624492543821338\n",
            "23     \t [ 7.09999192  4.47345685  5.          0.9460382  13.          0.80427626]. \t  -0.5138043771719756 \t -0.4624492543821338\n",
            "24     \t [9.06829377 8.93961606 6.         0.58229519 2.         0.64167434]. \t  -0.5639693784977007 \t -0.4624492543821338\n",
            "25     \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]. \t  -0.6952750251234912 \t -0.4624492543821338\n",
            "26     \t [ 1.02271184  6.5446919   5.          0.65061276 18.          0.87810946]. \t  -0.5095834365788608 \t -0.4624492543821338\n",
            "27     \t [ 5.60304207  8.06257727 15.          1.         13.60557657  1.        ]. \t  \u001b[92m-0.4517844633535562\u001b[0m \t -0.4517844633535562\n",
            "28     \t [ 6.57413965  8.74101239 15.          1.          2.29751588  1.        ]. \t  \u001b[92m-0.44334962937783\u001b[0m \t -0.44334962937783\n",
            "29     \t [ 7.97865216  2.16562098  6.          0.65030877 17.          0.41483603]. \t  -0.5980756065580175 \t -0.44334962937783\n",
            "30     \t [ 8.10551012  3.72451437 13.83426537  1.         19.83426537  1.        ]. \t  -0.462539665690689 \t -0.44334962937783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.615552028387216"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46537f00-76b3-4ddf-f109-42357db8886f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_exact_12 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_12 = dGPGO(surrogate_exact_12, Acquisition_new(util_exact), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_12 = exact_12.getResult()[0]\n",
        "params_exact_12['max_depth'] = int(params_exact_12['max_depth'])\n",
        "params_exact_12['min_child_weight'] = int(params_exact_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_exact_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_exact_12 = xgb.train(params_exact_12, dX_exact_train12)\n",
        "pred_exact_12 = model_exact_12.predict(dX_exact_test12)\n",
        "\n",
        "rmse_exact_12 = np.sqrt(mean_squared_error(pred_exact_12, y_test12))\n",
        "rmse_exact_12"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]. \t  -0.6840535846029854 \t -0.5032799564384677\n",
            "init   \t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]. \t  -0.6305456734924068 \t -0.5032799564384677\n",
            "init   \t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]. \t  -0.6144010633484512 \t -0.5032799564384677\n",
            "init   \t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]. \t  -0.5032799564384677 \t -0.5032799564384677\n",
            "init   \t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]. \t  -0.6516977337723864 \t -0.5032799564384677\n",
            "1      \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]. \t  -0.5227768283895782 \t -0.5032799564384677\n",
            "2      \t [ 7.57473716  9.63637997 12.          0.83444517 10.          0.18761713]. \t  -0.6734912089891107 \t -0.5032799564384677\n",
            "3      \t [ 9.04517621  0.80881017 13.          0.96890904  5.          0.75400021]. \t  \u001b[92m-0.4806753007187634\u001b[0m \t -0.4806753007187634\n",
            "4      \t [ 2.73241117  0.55778587 14.          0.70282167 15.          0.8966204 ]. \t  \u001b[92m-0.4777748953827142\u001b[0m \t -0.4777748953827142\n",
            "5      \t [ 6.66970674  0.03985694  6.          0.76922453 11.          0.18327615]. \t  -0.6744989447281609 \t -0.4777748953827142\n",
            "6      \t [ 1.23389285  0.85357459 13.          0.93854198  3.          0.52598214]. \t  -0.6188016111425869 \t -0.4777748953827142\n",
            "7      \t [ 0.57203639  5.0857779   9.          0.68290949 10.          0.94408458]. \t  -0.4796925982784261 \t -0.4777748953827142\n",
            "8      \t [0.         0.62408293 5.         0.5        1.         0.1       ]. \t  -0.6836372225983716 \t -0.4777748953827142\n",
            "9      \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]. \t  -0.5048487748496318 \t -0.4777748953827142\n",
            "10     \t [ 9.20470536  7.96480391  5.          0.84400217 12.          0.74025549]. \t  -0.5139346401947209 \t -0.4777748953827142\n",
            "11     \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.46456194090516634\u001b[0m \t -0.46456194090516634\n",
            "12     \t [ 1.1215575   6.61045389 13.          0.73682382 17.          0.82385484]. \t  -0.49353840013950256 \t -0.46456194090516634\n",
            "13     \t [ 7.99081854  5.0575051  13.50130195  0.98071153 18.50130195  0.90073845]. \t  -0.47601152395387347 \t -0.46456194090516634\n",
            "14     \t [ 0.609825    8.87388875 14.          0.9069446   2.          0.82580346]. \t  -0.47762228125207995 \t -0.46456194090516634\n",
            "15     \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]. \t  -0.6803041052338227 \t -0.46456194090516634\n",
            "16     \t [ 9.91089284  0.69508059 10.          0.66205579 17.          0.21826652]. \t  -0.6764293037998119 \t -0.46456194090516634\n",
            "17     \t [0.         0.05401904 7.82874268 0.5        7.82874268 0.1       ]. \t  -0.6807352194117176 \t -0.46456194090516634\n",
            "18     \t [ 1.40667435  9.60801033 13.          0.60326903 11.          0.82424216]. \t  -0.49226466238259936 \t -0.46456194090516634\n",
            "19     \t [4.91421669 4.36804321 9.         0.94450832 6.         0.31554207]. \t  -0.6315765617885719 \t -0.46456194090516634\n",
            "20     \t [ 9.92540237  8.39911553  5.          0.57889981 18.          0.71150738]. \t  -0.5641934100536196 \t -0.46456194090516634\n",
            "21     \t [ 6.19343348  4.5836704  14.60518694  1.          8.60518694  1.        ]. \t  \u001b[92m-0.45244640475986475\u001b[0m \t -0.45244640475986475\n",
            "22     \t [5.23276718 4.70765383 5.         0.5        1.         0.1       ]. \t  -0.6839557091494329 \t -0.45244640475986475\n",
            "23     \t [ 9.56538914  5.60856219 11.40360718  1.          5.40360718  1.        ]. \t  -0.46142626971349426 \t -0.45244640475986475\n",
            "24     \t [ 1.47973338  1.45058818 11.          0.74181509 19.          0.60410465]. \t  -0.540645853977064 \t -0.45244640475986475\n",
            "25     \t [ 5.4440963   9.15124188 14.43346693  1.         15.43346693  1.        ]. \t  -0.45780771943135967 \t -0.45244640475986475\n",
            "26     \t [ 5.24462228  0.17690887 10.          0.5616325   9.          0.71732742]. \t  -0.5029609828267528 \t -0.45244640475986475\n",
            "27     \t [2.44263238 9.92102351 7.1546772  1.         8.1546772  1.        ]. \t  -0.46287924548632714 \t -0.45244640475986475\n",
            "28     \t [ 9.13327668  0.92433654 12.          0.91412474 10.          0.85058075]. \t  -0.48583373996276313 \t -0.45244640475986475\n",
            "29     \t [ 3.8544074   5.22723842 10.          0.76354194  1.          0.13710805]. \t  -0.6788335648158361 \t -0.45244640475986475\n",
            "30     \t [ 9.91784767  9.45201168 10.27023226  1.         18.27023226  0.96485621]. \t  -0.4794812912022765 \t -0.45244640475986475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.57605623688618"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e290537-5a92-4132-d33d-8f9c41351e9e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_exact_13 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_13 = dGPGO(surrogate_exact_13, Acquisition_new(util_exact), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_13 = exact_13.getResult()[0]\n",
        "params_exact_13['max_depth'] = int(params_exact_13['max_depth'])\n",
        "params_exact_13['min_child_weight'] = int(params_exact_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_exact_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_exact_13 = xgb.train(params_exact_13, dX_exact_train13)\n",
        "pred_exact_13 = model_exact_13.predict(dX_exact_test13)\n",
        "\n",
        "rmse_exact_13 = np.sqrt(mean_squared_error(pred_exact_13, y_test13))\n",
        "rmse_exact_13"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]. \t  -0.5099204187421568 \t -0.5099204187421568\n",
            "init   \t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]. \t  -0.7086153631136594 \t -0.5099204187421568\n",
            "init   \t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]. \t  -0.6372461781857162 \t -0.5099204187421568\n",
            "init   \t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]. \t  -0.5702017504451442 \t -0.5099204187421568\n",
            "init   \t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]. \t  -0.7101125715665313 \t -0.5099204187421568\n",
            "1      \t [1.1119361  5.43221306 6.         0.56899303 8.         0.32100319]. \t  -0.6493427493033831 \t -0.5099204187421568\n",
            "2      \t [ 6.78607938  6.56608561 12.          0.84765686  1.          0.65153116]. \t  -0.587676594976195 \t -0.5099204187421568\n",
            "3      \t [ 9.24780874  8.51103418  5.          0.85105015 14.          0.11807471]. \t  -0.7114804394826701 \t -0.5099204187421568\n",
            "4      \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]. \t  -0.5162956828123637 \t -0.5099204187421568\n",
            "5      \t [0.54332874 9.16801531 5.         0.98374535 2.         0.17662624]. \t  -0.7151583517662211 \t -0.5099204187421568\n",
            "6      \t [10.         10.         15.          1.          6.08794028  1.        ]. \t  \u001b[92m-0.4410362828317778\u001b[0m \t -0.4410362828317778\n",
            "7      \t [2.42114726 2.21731466 7.         0.52977639 2.         0.33969965]. \t  -0.6396660621664843 \t -0.4410362828317778\n",
            "8      \t [ 1.89221513  8.5037767  14.          0.86717015  6.          0.11990372]. \t  -0.7161815730157779 \t -0.4410362828317778\n",
            "9      \t [10.         10.         15.          1.         18.08803147  1.        ]. \t  -0.4560312851731446 \t -0.4410362828317778\n",
            "10     \t [8.4190306  4.87720164 8.         0.76266952 5.         0.57713014]. \t  -0.5767417095171845 \t -0.4410362828317778\n",
            "11     \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]. \t  -0.5916305851001364 \t -0.4410362828317778\n",
            "12     \t [ 7.42000681  1.27539351  5.          0.54650948 11.          0.38725518]. \t  -0.6590542581211495 \t -0.4410362828317778\n",
            "13     \t [ 1.24784615  8.5302667   7.          0.99055025 14.          0.52610034]. \t  -0.6214626581302563 \t -0.4410362828317778\n",
            "14     \t [ 0.56153062  1.99964994 12.          0.65527832 19.          0.67862516]. \t  -0.5700144382222918 \t -0.4410362828317778\n",
            "15     \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]. \t  -0.4816663211789673 \t -0.4410362828317778\n",
            "16     \t [6.71071456 9.12714369 6.         0.73542247 8.         0.83203993]. \t  -0.5310008171943694 \t -0.4410362828317778\n",
            "17     \t [ 9.50305523  1.39719827 14.          0.80515064 17.          0.21967579]. \t  -0.70999762624118 \t -0.4410362828317778\n",
            "18     \t [ 0.94229296  2.02450761 13.          0.65000924  1.          0.22250131]. \t  -0.7194219871093057 \t -0.4410362828317778\n",
            "19     \t [1.99026917 9.93375929 9.         0.83098378 9.         0.22686148]. \t  -0.7090696008737745 \t -0.4410362828317778\n",
            "20     \t [ 9.35280568  2.44132886  8.          0.87489385 18.          0.92170626]. \t  -0.49123124118162603 \t -0.4410362828317778\n",
            "21     \t [ 8.79523185  3.72755126 14.          0.50499174  7.          0.18146663]. \t  -0.7138267221716003 \t -0.4410362828317778\n",
            "22     \t [8.1634571  7.58766207 7.         0.64490867 1.         0.97002079]. \t  -0.493572330458003 \t -0.4410362828317778\n",
            "23     \t [ 2.05622909  9.08047387  8.          0.8397078  17.          0.73365999]. \t  -0.5126218176815447 \t -0.4410362828317778\n",
            "24     \t [ 5.54617933  1.56123407 12.          0.78374404  3.          0.15837523]. \t  -0.7116408134257192 \t -0.4410362828317778\n",
            "25     \t [ 6.42740487  9.98435007 11.          0.94043739  5.          0.88360313]. \t  -0.47417754626332054 \t -0.4410362828317778\n",
            "26     \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]. \t  -0.4857795506507053 \t -0.4410362828317778\n",
            "27     \t [ 0.          0.          5.          0.5        12.91733241  0.1       ]. \t  -0.7095178022370769 \t -0.4410362828317778\n",
            "28     \t [ 0.          8.33081417 12.45127877  0.5         1.45127877  0.1       ]. \t  -0.7174154361788747 \t -0.4410362828317778\n",
            "29     \t [ 1.1665804   8.5178555  13.          0.63744653 19.          0.35989497]. \t  -0.639729050995518 \t -0.4410362828317778\n",
            "30     \t [0.43091775 0.3532639  5.         0.76123896 7.         0.49074528]. \t  -0.6279630584555015 \t -0.4410362828317778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.531646397942748"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAuEsXYbtOnC",
        "outputId": "ed27f195-84dd-4163-fb2f-2cfbd6360b76"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_exact_14 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_14 = dGPGO(surrogate_exact_14, Acquisition_new(util_exact), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_14 = exact_14.getResult()[0]\n",
        "params_exact_14['max_depth'] = int(params_exact_14['max_depth'])\n",
        "params_exact_14['min_child_weight'] = int(params_exact_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_exact_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_exact_14 = xgb.train(params_exact_14, dX_exact_train14)\n",
        "pred_exact_14 = model_exact_14.predict(dX_exact_test14)\n",
        "\n",
        "rmse_exact_14 = np.sqrt(mean_squared_error(pred_exact_14, y_test14))\n",
        "rmse_exact_14"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]. \t  -0.558794499921046 \t -0.4448140077853999\n",
            "init   \t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]. \t  -0.49979629433789113 \t -0.4448140077853999\n",
            "init   \t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]. \t  -0.5741697988899073 \t -0.4448140077853999\n",
            "init   \t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]. \t  -0.4448140077853999 \t -0.4448140077853999\n",
            "init   \t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]. \t  -0.6214151152359092 \t -0.4448140077853999\n",
            "1      \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]. \t  -0.6294794339238933 \t -0.4448140077853999\n",
            "2      \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]. \t  -0.5666498709303299 \t -0.4448140077853999\n",
            "3      \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]. \t  -0.45935750652191915 \t -0.4448140077853999\n",
            "4      \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]. \t  -0.6240299412135976 \t -0.4448140077853999\n",
            "5      \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]. \t  -0.5637683506571429 \t -0.4448140077853999\n",
            "6      \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]. \t  -0.6233774536812148 \t -0.4448140077853999\n",
            "7      \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.4356616035409925\u001b[0m \t -0.4356616035409925\n",
            "8      \t [ 0.63353879  9.61017877  8.          0.96421247 18.          0.39200727]. \t  -0.5519186326582054 \t -0.4356616035409925\n",
            "9      \t [ 2.48800603  5.10093097 14.          0.58870342  6.          0.75046851]. \t  -0.4824172014541183 \t -0.4356616035409925\n",
            "10     \t [ 1.6361515   9.65601963  6.          0.78645605 10.          0.24059194]. \t  -0.6204080143724908 \t -0.4356616035409925\n",
            "11     \t [ 9.88809977  3.72297385  6.          0.68686416 11.          0.16446157]. \t  -0.6244460447585098 \t -0.4356616035409925\n",
            "12     \t [ 7.35080411  8.42969833  8.          0.54853874 19.          0.64845929]. \t  -0.5108161270152252 \t -0.4356616035409925\n",
            "13     \t [ 0.25039867  4.81148287 14.          0.83239345 15.          0.88911818]. \t  \u001b[92m-0.43183090108974975\u001b[0m \t -0.43183090108974975\n",
            "14     \t [1.24708975e+00 5.12660675e-03 1.20000000e+01 6.61878749e-01\n",
            " 5.00000000e+00 4.24017934e-01]. \t  -0.5542524330062069 \t -0.43183090108974975\n",
            "15     \t [5.73566512 8.66603361 8.         0.81300017 7.         0.72050723]. \t  -0.4761200926863527 \t -0.43183090108974975\n",
            "16     \t [10.         10.         14.44045025  1.          5.44045025  1.        ]. \t  \u001b[92m-0.4229434636769286\u001b[0m \t -0.4229434636769286\n",
            "17     \t [ 4.83871117  1.89317253 13.          0.87688851 13.          0.10679344]. \t  -0.6230760569149346 \t -0.4229434636769286\n",
            "18     \t [ 9.40706915  0.91600736 13.          0.648599    7.          0.62885715]. \t  -0.5088292837339503 \t -0.4229434636769286\n",
            "19     \t [ 6.11645628  0.17500507  7.          0.96263937 18.          0.49631453]. \t  -0.5028982542163177 \t -0.4229434636769286\n",
            "20     \t [2.04199783 5.19845215 9.         0.76637639 9.         0.59817635]. \t  -0.4958630522259 \t -0.4229434636769286\n",
            "21     \t [ 3.88545099  7.01272757 13.84814588  1.         17.84814588  1.        ]. \t  -0.4274110893536328 \t -0.4229434636769286\n",
            "22     \t [0.         0.         5.         0.5        6.93649143 0.1       ]. \t  -0.6286807074277094 \t -0.4229434636769286\n",
            "23     \t [ 4.17679297  9.93263668 14.          0.80854532  5.          0.52091746]. \t  -0.49051156399083773 \t -0.4229434636769286\n",
            "24     \t [ 9.76732171  6.02688461 10.          0.61683421 16.          0.31201459]. \t  -0.5696202173566095 \t -0.4229434636769286\n",
            "25     \t [ 5.5386478   9.30162083  6.          0.50498383 14.          0.37570322]. \t  -0.5724302466366937 \t -0.4229434636769286\n",
            "26     \t [ 9.26541797 10.         11.78783642  1.         10.78783642  1.        ]. \t  -0.4276694614594086 \t -0.4229434636769286\n",
            "27     \t [ 0.19921359  1.33183456 11.          0.79119941 11.          0.23591371]. \t  -0.6237999374821301 \t -0.4229434636769286\n",
            "28     \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]. \t  -0.49388442575081426 \t -0.4229434636769286\n",
            "29     \t [6.22873759 4.62377431 9.71372081 0.5        8.71372081 0.1       ]. \t  -0.6306908807804147 \t -0.4229434636769286\n",
            "30     \t [ 1.26617981  4.03386415  8.          0.85223134 19.          0.86958504]. \t  -0.4481330730823694 \t -0.4229434636769286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.556355052698233"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee49f872-dc30-4087-d203-fbce49dee5f7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_exact_15 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_15 = dGPGO(surrogate_exact_15, Acquisition_new(util_exact), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_15 = exact_15.getResult()[0]\n",
        "params_exact_15['max_depth'] = int(params_exact_15['max_depth'])\n",
        "params_exact_15['min_child_weight'] = int(params_exact_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_exact_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_exact_15 = xgb.train(params_exact_15, dX_exact_train15)\n",
        "pred_exact_15 = model_exact_15.predict(dX_exact_test15)\n",
        "\n",
        "rmse_exact_15 = np.sqrt(mean_squared_error(pred_exact_15, y_test15))\n",
        "rmse_exact_15"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]. \t  -0.489437914006383 \t -0.489437914006383\n",
            "init   \t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]. \t  -0.6992441679399787 \t -0.489437914006383\n",
            "init   \t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]. \t  -0.69945028775584 \t -0.489437914006383\n",
            "init   \t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]. \t  -0.6264981748624211 \t -0.489437914006383\n",
            "init   \t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]. \t  -0.6964615643692806 \t -0.489437914006383\n",
            "1      \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]. \t  -0.56524595824364 \t -0.489437914006383\n",
            "2      \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]. \t  -0.6976766501007658 \t -0.489437914006383\n",
            "3      \t [ 1.91126037  0.99517267  5.          0.54111286 13.          0.82351196]. \t  -0.5203297112050622 \t -0.489437914006383\n",
            "4      \t [ 9.65016643  9.36315476  6.          0.59817648 12.          0.93115055]. \t  -0.5035725842878749 \t -0.489437914006383\n",
            "5      \t [ 7.92634325  7.5869497  10.          0.81214373  5.          0.71583728]. \t  \u001b[92m-0.48077564047020915\u001b[0m \t -0.48077564047020915\n",
            "6      \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]. \t  -0.6854377590797448 \t -0.48077564047020915\n",
            "7      \t [ 1.16848639  8.05538533  5.          0.78038294 17.          0.39890654]. \t  -0.6820374964576017 \t -0.48077564047020915\n",
            "8      \t [ 2.92030295  6.55213539  7.          0.85743112 11.          0.10721562]. \t  -0.6994232506027507 \t -0.48077564047020915\n",
            "9      \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]. \t  -0.512561519837635 \t -0.48077564047020915\n",
            "10     \t [ 7.63220266  0.71776488 13.          0.94235703 19.          0.50312607]. \t  -0.6214609326165444 \t -0.48077564047020915\n",
            "11     \t [7.86329715 0.45193827 6.         0.68312899 1.         0.69810196]. \t  -0.5708964123226768 \t -0.48077564047020915\n",
            "12     \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.4662835424155933\u001b[0m \t -0.4662835424155933\n",
            "13     \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]. \t  -0.4948532295288583 \t -0.4662835424155933\n",
            "14     \t [ 7.74771021  6.65318771  6.          0.83647538 17.          0.81072392]. \t  -0.5116796961222467 \t -0.4662835424155933\n",
            "15     \t [ 0.95566099  3.27803887  7.          0.79832937 17.          0.8547564 ]. \t  -0.49941107970962745 \t -0.4662835424155933\n",
            "16     \t [ 1.01000548  1.96777104 12.          0.51504561  8.          0.68970296]. \t  -0.5746890275202554 \t -0.4662835424155933\n",
            "17     \t [ 5.62432323  9.73264602 14.          0.97476986  1.          0.26183863]. \t  -0.6994874674494638 \t -0.4662835424155933\n",
            "18     \t [ 1.86027286  4.35430307 13.          0.53536444 15.          0.92334731]. \t  -0.4824087135892917 \t -0.4662835424155933\n",
            "19     \t [7.35570048 8.26460229 5.         0.55162663 8.         0.77748758]. \t  -0.5227497315623809 \t -0.4662835424155933\n",
            "20     \t [10.        10.        15.         1.        12.3081196  1.       ]. \t  \u001b[92m-0.4613579199587862\u001b[0m \t -0.4613579199587862\n",
            "21     \t [8.81149616 6.28323965 6.         0.50689458 2.         0.19421846]. \t  -0.7005581625473822 \t -0.4613579199587862\n",
            "22     \t [ 9.31305405  2.68340802  7.          0.59348541 12.          0.97471219]. \t  -0.4968862489406364 \t -0.4613579199587862\n",
            "23     \t [ 6.04262604  3.49698263 14.          0.62988823  3.          0.21136394]. \t  -0.70208811902736 \t -0.4613579199587862\n",
            "24     \t [ 7.10649672  5.73981655 15.          1.          8.9429031   1.        ]. \t  \u001b[92m-0.45298434111413394\u001b[0m \t -0.45298434111413394\n",
            "25     \t [10.          4.86441454 15.          1.         20.          1.        ]. \t  -0.46632547363442745 \t -0.45298434111413394\n",
            "26     \t [ 9.94949799  1.08169388  7.          0.92613621 17.          0.96922841]. \t  -0.48659227193417476 \t -0.45298434111413394\n",
            "27     \t [ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]. \t  -0.4745561015346341 \t -0.45298434111413394\n",
            "28     \t [ 3.42213683  0.18628291 11.85405411  0.5         1.          0.1       ]. \t  -0.7027720779206807 \t -0.45298434111413394\n",
            "29     \t [ 4.12412467 10.         15.          1.         20.          1.        ]. \t  -0.4545174279866976 \t -0.45298434111413394\n",
            "30     \t [ 9.40435768  7.598465   10.          0.97457018 15.          0.31309738]. \t  -0.6891569408822912 \t -0.45298434111413394\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.518172101554047"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TaP6RoGuiNT",
        "outputId": "33db3731-b43d-489e-a390-fdd1e4f843ca"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_exact_16 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_16 = dGPGO(surrogate_exact_16, Acquisition_new(util_exact), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_16 = exact_16.getResult()[0]\n",
        "params_exact_16['max_depth'] = int(params_exact_16['max_depth'])\n",
        "params_exact_16['min_child_weight'] = int(params_exact_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_exact_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_exact_16 = xgb.train(params_exact_16, dX_exact_train16)\n",
        "pred_exact_16 = model_exact_16.predict(dX_exact_test16)\n",
        "\n",
        "rmse_exact_16 = np.sqrt(mean_squared_error(pred_exact_16, y_test16))\n",
        "rmse_exact_16"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]. \t  -0.6357813258069683 \t -0.6345701590947206\n",
            "init   \t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]. \t  -0.7029752724132097 \t -0.6345701590947206\n",
            "init   \t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]. \t  -0.6345701590947206 \t -0.6345701590947206\n",
            "init   \t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]. \t  -0.7076230970293895 \t -0.6345701590947206\n",
            "init   \t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]. \t  -0.7061563820165734 \t -0.6345701590947206\n",
            "1      \t [ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]. \t  \u001b[92m-0.5498317738591506\u001b[0m \t -0.5498317738591506\n",
            "2      \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]. \t  -0.5694622631948656 \t -0.5498317738591506\n",
            "3      \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]. \t  -0.5668863692096254 \t -0.5498317738591506\n",
            "4      \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]. \t  -0.7034666397019427 \t -0.5498317738591506\n",
            "5      \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]. \t  -0.5723152354991565 \t -0.5498317738591506\n",
            "6      \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]. \t  \u001b[92m-0.5394691206821607\u001b[0m \t -0.5394691206821607\n",
            "7      \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]. \t  -0.6464801434165215 \t -0.5394691206821607\n",
            "8      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.7101090677178151 \t -0.5394691206821607\n",
            "9      \t [6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]. \t  \u001b[92m-0.459858810359861\u001b[0m \t -0.459858810359861\n",
            "10     \t [ 9.49073008  1.95543967  6.          0.82312132 10.          0.92175057]. \t  -0.48473337499557195 \t -0.459858810359861\n",
            "11     \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]. \t  -0.7073064797779202 \t -0.459858810359861\n",
            "12     \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]. \t  -0.5373324936054761 \t -0.459858810359861\n",
            "13     \t [ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]. \t  \u001b[92m-0.45152053563727684\u001b[0m \t -0.45152053563727684\n",
            "14     \t [10. 10. 15.  1. 20.  1.]. \t  -0.46362391476067477 \t -0.45152053563727684\n",
            "15     \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]. \t  -0.6336754873953304 \t -0.45152053563727684\n",
            "16     \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]. \t  -0.5493386366741839 \t -0.45152053563727684\n",
            "17     \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]. \t  -0.7009377489720375 \t -0.45152053563727684\n",
            "18     \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]. \t  -0.6372685525181103 \t -0.45152053563727684\n",
            "19     \t [ 2.38304891  0.39103582  5.          0.8629475  11.          0.24144597]. \t  -0.7033260165918873 \t -0.45152053563727684\n",
            "20     \t [ 8.60177792  1.89933469  8.          0.92909045 16.          0.35782775]. \t  -0.6315391555988348 \t -0.45152053563727684\n",
            "21     \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]. \t  -0.7036971150142254 \t -0.45152053563727684\n",
            "22     \t [ 9.99926575  9.6578075   8.          0.78804094 15.          0.34788136]. \t  -0.6328497181925594 \t -0.45152053563727684\n",
            "23     \t [10.         10.         12.68302249  1.          7.68302249  1.        ]. \t  \u001b[92m-0.44613317747352693\u001b[0m \t -0.44613317747352693\n",
            "24     \t [ 0.6221621   5.97682344 10.          0.77872519 13.          0.10493686]. \t  -0.7037775544724159 \t -0.44613317747352693\n",
            "25     \t [ 2.55150092  4.01459914  6.          0.7124862  16.          0.27260814]. \t  -0.7056586993332014 \t -0.44613317747352693\n",
            "26     \t [9.53244977 7.04235321 6.         0.75218774 7.         0.15792958]. \t  -0.7066876914321328 \t -0.44613317747352693\n",
            "27     \t [ 9.26334332  8.65557634  6.          0.701058   19.          0.33944267]. \t  -0.6349707145125356 \t -0.44613317747352693\n",
            "28     \t [ 1.9619463   0.16028995 10.          0.50330845  2.          0.6207421 ]. \t  -0.5509647997606063 \t -0.44613317747352693\n",
            "29     \t [ 2.85481198  1.91621026 14.          0.54622477 17.          0.11441312]. \t  -0.7042897147876945 \t -0.44613317747352693\n",
            "30     \t [ 4.01121013  8.67321012 14.7787861   1.          3.7787861   0.91924164]. \t  -0.46163905141079997 \t -0.44613317747352693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.693011014948751"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiOaMUmgulbx",
        "outputId": "6ba814f2-2b3b-44e3-90bd-f44d1f27bc94"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_exact_17 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_17 = dGPGO(surrogate_exact_17, Acquisition_new(util_exact), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_17 = exact_17.getResult()[0]\n",
        "params_exact_17['max_depth'] = int(params_exact_17['max_depth'])\n",
        "params_exact_17['min_child_weight'] = int(params_exact_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_exact_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_exact_17 = xgb.train(params_exact_17, dX_exact_train17)\n",
        "pred_exact_17 = model_exact_17.predict(dX_exact_test17)\n",
        "\n",
        "rmse_exact_17 = np.sqrt(mean_squared_error(pred_exact_17, y_test17))\n",
        "rmse_exact_17"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]. \t  -0.48092361225642916 \t -0.48092361225642916\n",
            "init   \t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]. \t  -0.634455605137701 \t -0.48092361225642916\n",
            "init   \t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]. \t  -0.6046684392629649 \t -0.48092361225642916\n",
            "init   \t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]. \t  -0.6562801618178493 \t -0.48092361225642916\n",
            "init   \t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]. \t  -0.6415104035419145 \t -0.48092361225642916\n",
            "1      \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]. \t  -0.6424064809093688 \t -0.48092361225642916\n",
            "2      \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]. \t  -0.5250563773138615 \t -0.48092361225642916\n",
            "3      \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]. \t  -0.4855447166854706 \t -0.48092361225642916\n",
            "4      \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]. \t  -0.6592777931092744 \t -0.48092361225642916\n",
            "5      \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]. \t  -0.6482001920177487 \t -0.48092361225642916\n",
            "6      \t [9.9788934  2.15636979 6.         0.99768008 1.         0.76766471]. \t  -0.4941759850943699 \t -0.48092361225642916\n",
            "7      \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]. \t  -0.5824208509959975 \t -0.48092361225642916\n",
            "8      \t [ 0.80030762  5.97573055 10.          0.83426171  8.          0.65594116]. \t  -0.4925025307799194 \t -0.48092361225642916\n",
            "9      \t [ 1.2716555   3.78378689  5.          0.57556817 17.          0.18163876]. \t  -0.6597773245382103 \t -0.48092361225642916\n",
            "10     \t [ 9.80102397  1.97747829 14.          0.90631838  4.          0.75804043]. \t  \u001b[92m-0.47872283861791676\u001b[0m \t -0.47872283861791676\n",
            "11     \t [ 0.53370892  8.37682141  5.          0.86989913 13.          0.18237465]. \t  -0.6538884437793409 \t -0.47872283861791676\n",
            "12     \t [6.11014277 4.82394447 9.         0.70644548 3.         0.44997585]. \t  -0.5918645900207917 \t -0.47872283861791676\n",
            "13     \t [10. 10. 15.  1. 20.  1.]. \t  \u001b[92m-0.478716870694923\u001b[0m \t -0.478716870694923\n",
            "14     \t [ 5.3932      4.97212702 14.          0.7625444   7.          0.47228799]. \t  -0.5887683002646946 \t -0.478716870694923\n",
            "15     \t [ 9.19532326  8.42928342 11.          0.5289521  11.          0.74996998]. \t  -0.5099725794606587 \t -0.478716870694923\n",
            "16     \t [6.14842106 3.92031042 5.         0.80436272 5.         0.42842685]. \t  -0.6361132092867747 \t -0.478716870694923\n",
            "17     \t [ 4.70144225  0.6323766   5.          0.62149803 11.          0.33887991]. \t  -0.640490429668799 \t -0.478716870694923\n",
            "18     \t [0.3455857 0.        5.        0.5       1.        0.1      ]. \t  -0.6604746654186592 \t -0.478716870694923\n",
            "19     \t [ 0.45348627  9.34732483 12.          0.95759453 19.          0.71400033]. \t  -0.4964469628665989 \t -0.478716870694923\n",
            "20     \t [ 6.88175573  0.68997438  9.          0.55006192 19.          0.74555899]. \t  -0.5119349325314342 \t -0.478716870694923\n",
            "21     \t [ 7.71210856  3.55646865 13.64329471  1.         13.64329471  1.        ]. \t  \u001b[92m-0.47274733213468584\u001b[0m \t -0.47274733213468584\n",
            "22     \t [ 0.          3.29244423  6.39438503  0.5        10.39438503  0.1       ]. \t  -0.6630752606848158 \t -0.47274733213468584\n",
            "23     \t [ 0.18550893  0.5977981  10.          0.79794342 13.          0.78229338]. \t  -0.48375747455230594 \t -0.47274733213468584\n",
            "24     \t [ 2.77593451  9.15139628 12.          0.75467287  5.          0.21563156]. \t  -0.6586697172204237 \t -0.47274733213468584\n",
            "25     \t [ 4.24090262  9.11303687 15.          1.         13.57743084  1.        ]. \t  \u001b[92m-0.4648623732189188\u001b[0m \t -0.4648623732189188\n",
            "26     \t [6.13419869 4.27363654 8.77858911 0.5        9.77858911 0.1       ]. \t  -0.6651911441762481 \t -0.4648623732189188\n",
            "27     \t [ 5.48379726  6.58855631  5.          0.91493075 18.          0.89669113]. \t  -0.4996699593334831 \t -0.4648623732189188\n",
            "28     \t [ 3.3191017   1.36482014 13.          0.77172143  1.          0.73147858]. \t  -0.4783964328894935 \t -0.4648623732189188\n",
            "29     \t [ 0.30609514  2.49894713 14.          0.69397027 18.          0.71750058]. \t  -0.48863847757861834 \t -0.4648623732189188\n",
            "30     \t [ 4.09975041  9.9807053   9.          0.85467215 15.          0.44460825]. \t  -0.5884461973684892 \t -0.4648623732189188\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.701590190159117"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6cc86f-63b7-470b-ae76-a04a40aef272"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_exact_18 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_18 = dGPGO(surrogate_exact_18, Acquisition_new(util_exact), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_18 = exact_18.getResult()[0]\n",
        "params_exact_18['max_depth'] = int(params_exact_18['max_depth'])\n",
        "params_exact_18['min_child_weight'] = int(params_exact_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_exact_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_exact_18 = xgb.train(params_exact_18, dX_exact_train18)\n",
        "pred_exact_18 = model_exact_18.predict(dX_exact_test18)\n",
        "\n",
        "rmse_exact_18 = np.sqrt(mean_squared_error(pred_exact_18, y_test18))\n",
        "rmse_exact_18"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]. \t  -0.6408812889056655 \t -0.45563901799042095\n",
            "init   \t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]. \t  -0.5015618704267137 \t -0.45563901799042095\n",
            "init   \t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]. \t  -0.6438813467576416 \t -0.45563901799042095\n",
            "init   \t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]. \t  -0.5434165841486521 \t -0.45563901799042095\n",
            "init   \t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]. \t  -0.45563901799042095 \t -0.45563901799042095\n",
            "1      \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]. \t  -0.5446894741691042 \t -0.45563901799042095\n",
            "2      \t [ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]. \t  \u001b[92m-0.44303108951637993\u001b[0m \t -0.44303108951637993\n",
            "3      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6425312957388465 \t -0.44303108951637993\n",
            "4      \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]. \t  -0.6122960379993414 \t -0.44303108951637993\n",
            "5      \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]. \t  -0.49923184035684337 \t -0.44303108951637993\n",
            "6      \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]. \t  -0.6436150859688133 \t -0.44303108951637993\n",
            "7      \t [3.44338621 0.02606641 7.         0.55815806 9.         0.24029821]. \t  -0.6409667902467774 \t -0.44303108951637993\n",
            "8      \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]. \t  -0.540500539465401 \t -0.44303108951637993\n",
            "9      \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]. \t  -0.5387988919240001 \t -0.44303108951637993\n",
            "10     \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]. \t  \u001b[92m-0.4269330271140799\u001b[0m \t -0.4269330271140799\n",
            "11     \t [ 8.47511857  0.73864041 14.          0.94302087 10.          0.89112309]. \t  -0.43395812272336676 \t -0.4269330271140799\n",
            "12     \t [ 0.62191196  4.69754177  5.          0.72971917 15.          0.95903084]. \t  -0.4535756712182466 \t -0.4269330271140799\n",
            "13     \t [ 8.34050252  7.45495891 14.          0.58875591  8.          0.92669456]. \t  -0.44261634162821706 \t -0.4269330271140799\n",
            "14     \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]. \t  -0.5381512346287322 \t -0.4269330271140799\n",
            "15     \t [ 8.70623364  5.12068114  9.          0.56483465 12.          0.70223422]. \t  -0.501415146701387 \t -0.4269330271140799\n",
            "16     \t [ 0.71491502  0.67997826 10.          0.84656193 16.          0.26877596]. \t  -0.643457100693489 \t -0.4269330271140799\n",
            "17     \t [ 5.01391374  9.05765577 13.          0.9768187   1.          0.92456281]. \t  -0.4305811739400264 \t -0.4269330271140799\n",
            "18     \t [ 3.48086193  0.         11.20109331  0.5         2.20109331  0.1       ]. \t  -0.6480669538309776 \t -0.4269330271140799\n",
            "19     \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]. \t  -0.6420979999371168 \t -0.4269330271140799\n",
            "20     \t [ 4.23655307  7.87924419  8.          0.59960078 19.          0.10947028]. \t  -0.6410908226958714 \t -0.4269330271140799\n",
            "21     \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]. \t  -0.5451493033299312 \t -0.4269330271140799\n",
            "22     \t [10.          8.79205164  8.86549354  1.          7.11592996  1.        ]. \t  -0.4358526909870921 \t -0.4269330271140799\n",
            "23     \t [ 5.84006958  2.28845581  8.          0.66010373 19.          0.76603621]. \t  -0.4597886389545997 \t -0.4269330271140799\n",
            "24     \t [3.30805236 5.9652029  7.         0.78356556 9.         0.44348022]. \t  -0.5401537407055166 \t -0.4269330271140799\n",
            "25     \t [1.07172211 9.91320527 6.         0.98176043 4.         0.24706724]. \t  -0.6412881271086113 \t -0.4269330271140799\n",
            "26     \t [ 9.36260231  5.32226919 10.25404617  1.         17.25404617  1.        ]. \t  -0.43266639374096244 \t -0.4269330271140799\n",
            "27     \t [ 2.85160719  9.66497931 14.56961252  1.         15.56961252  0.8037902 ]. \t  -0.443542382906758 \t -0.4269330271140799\n",
            "28     \t [4.87245891 0.03350161 6.         0.83466638 1.         0.44183056]. \t  -0.5395094791280007 \t -0.4269330271140799\n",
            "29     \t [9.89337178 3.81875947 5.         0.59649267 7.         0.86884145]. \t  -0.45930221618892775 \t -0.4269330271140799\n",
            "30     \t [ 9.28797719 10.         15.          1.         12.72477654  1.        ]. \t  \u001b[92m-0.4264134870127956\u001b[0m \t -0.4264134870127956\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.685216580070881"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-zaPbk2uuzH",
        "outputId": "ddc35ee1-bdc9-455d-f04e-79709377f582"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_exact_19 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_19 = dGPGO(surrogate_exact_19, Acquisition_new(util_exact), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_19 = exact_19.getResult()[0]\n",
        "params_exact_19['max_depth'] = int(params_exact_19['max_depth'])\n",
        "params_exact_19['min_child_weight'] = int(params_exact_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_exact_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_exact_19 = xgb.train(params_exact_19, dX_exact_train19)\n",
        "pred_exact_19 = model_exact_19.predict(dX_exact_test19)\n",
        "\n",
        "rmse_exact_19 = np.sqrt(mean_squared_error(pred_exact_19, y_test19))\n",
        "rmse_exact_19"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]. \t  -0.5851081958447377 \t -0.4870287725699859\n",
            "init   \t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]. \t  -0.5245729886945251 \t -0.4870287725699859\n",
            "init   \t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]. \t  -0.677999989539271 \t -0.4870287725699859\n",
            "init   \t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]. \t  -0.4940235599803803 \t -0.4870287725699859\n",
            "init   \t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]. \t  -0.4870287725699859 \t -0.4870287725699859\n",
            "1      \t [ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]. \t  \u001b[92m-0.48699206254226385\u001b[0m \t -0.48699206254226385\n",
            "2      \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]. \t  -0.5586571006723301 \t -0.48699206254226385\n",
            "3      \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]. \t  -0.6812597142899619 \t -0.48699206254226385\n",
            "4      \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]. \t  -0.5176144815279642 \t -0.48699206254226385\n",
            "5      \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]. \t  -0.5891547583463381 \t -0.48699206254226385\n",
            "6      \t [ 1.26780724  6.08446535  5.          0.5        11.25827455  0.1       ]. \t  -0.678347001459937 \t -0.48699206254226385\n",
            "7      \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]. \t  -0.50278430420039 \t -0.48699206254226385\n",
            "8      \t [ 8.78531367  5.16236615 10.          0.71284072  9.          0.88546543]. \t  \u001b[92m-0.47023345063528244\u001b[0m \t -0.47023345063528244\n",
            "9      \t [ 2.19431997  0.03640407  7.          0.62674231 12.          0.80025129]. \t  -0.48719453484160435 \t -0.47023345063528244\n",
            "10     \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.6807548522242486 \t -0.47023345063528244\n",
            "11     \t [ 8.347612    9.05501181  5.          0.50033019 10.          0.41046448]. \t  -0.59152247561381 \t -0.47023345063528244\n",
            "12     \t [ 7.02064539 10.         14.04761045  1.         12.04761045  1.        ]. \t  \u001b[92m-0.44783406435655004\u001b[0m \t -0.44783406435655004\n",
            "13     \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]. \t  -0.6819669312627161 \t -0.44783406435655004\n",
            "14     \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]. \t  -0.5047568707535037 \t -0.44783406435655004\n",
            "15     \t [ 8.99876272  0.14180428 14.          0.5207566  10.          0.28841204]. \t  -0.5833706866586879 \t -0.44783406435655004\n",
            "16     \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]. \t  -0.5829439311579024 \t -0.44783406435655004\n",
            "17     \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]. \t  -0.5147410971984965 \t -0.44783406435655004\n",
            "18     \t [ 4.53712581  0.82823489 12.          0.77278662  7.          0.49955948]. \t  -0.560919955413549 \t -0.44783406435655004\n",
            "19     \t [ 9.97958622  9.03409533 12.          0.51772082  4.          0.45869101]. \t  -0.5663519655313095 \t -0.44783406435655004\n",
            "20     \t [10.         10.          9.78981169  1.         20.          1.        ]. \t  -0.4556962650164745 \t -0.44783406435655004\n",
            "21     \t [ 3.16526468  9.88957695 14.          0.66718624  2.          0.49421519]. \t  -0.5687706781654549 \t -0.44783406435655004\n",
            "22     \t [ 6.38845426  7.47702482  9.          0.88968497 15.          0.37901416]. \t  -0.5871401131917249 \t -0.44783406435655004\n",
            "23     \t [9.69395621 3.02000208 9.         0.64387395 1.         0.9318623 ]. \t  -0.4805334733833469 \t -0.44783406435655004\n",
            "24     \t [ 2.76287935  0.832992   10.          0.52421602  1.          0.77581255]. \t  -0.48677212674395187 \t -0.44783406435655004\n",
            "25     \t [ 8.28202559  0.45721202  6.          0.9018841  19.          0.27559296]. \t  -0.6794837707583252 \t -0.44783406435655004\n",
            "26     \t [9.50174298 5.95601551 5.         0.75663915 5.         0.34859645]. \t  -0.592770920101058 \t -0.44783406435655004\n",
            "27     \t [10.          3.34745077  9.85764106  1.         18.85764106  1.        ]. \t  -0.4555798886037842 \t -0.44783406435655004\n",
            "28     \t [ 6.15913994 10.         13.94693822  1.          6.94693822  1.        ]. \t  \u001b[92m-0.4446914278841304\u001b[0m \t -0.4446914278841304\n",
            "29     \t [ 1.41648695  0.         12.40756663  0.5        14.40756663  0.16595026]. \t  -0.6795433757896141 \t -0.4446914278841304\n",
            "30     \t [10.         10.          9.61248828  1.         10.61248828  1.        ]. \t  -0.4584859123121764 \t -0.4446914278841304\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.58901026336843"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvkuHKlQuxRy",
        "outputId": "d209a01e-13b6-4cfa-d234-00ba9ea4fb73"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_exact_20 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_20 = dGPGO(surrogate_exact_20, Acquisition_new(util_exact), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_20 = exact_20.getResult()[0]\n",
        "params_exact_20['max_depth'] = int(params_exact_20['max_depth'])\n",
        "params_exact_20['min_child_weight'] = int(params_exact_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_exact_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_exact_20 = xgb.train(params_exact_20, dX_exact_train20)\n",
        "pred_exact_20 = model_exact_20.predict(dX_exact_test20)\n",
        "\n",
        "rmse_exact_20 = np.sqrt(mean_squared_error(pred_exact_20, y_test20))\n",
        "rmse_exact_20"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]. \t  -0.4485352768858121 \t -0.4485352768858121\n",
            "init   \t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]. \t  -0.47208091450542966 \t -0.4485352768858121\n",
            "init   \t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]. \t  -0.7316473600840852 \t -0.4485352768858121\n",
            "init   \t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]. \t  -0.7314226542252507 \t -0.4485352768858121\n",
            "init   \t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]. \t  -0.6494230116583573 \t -0.4485352768858121\n",
            "1      \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]. \t  -0.6502222800629637 \t -0.4485352768858121\n",
            "2      \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]. \t  -0.7324821709443572 \t -0.4485352768858121\n",
            "3      \t [10.         10.         15.          1.         18.33946642  1.        ]. \t  \u001b[92m-0.4398376487694103\u001b[0m \t -0.4398376487694103\n",
            "4      \t [0.  0.  5.  0.5 1.  0.1]. \t  -0.7340609389889516 \t -0.4398376487694103\n",
            "5      \t [ 7.50758902  2.31989813 13.          0.92794435  1.          0.52943075]. \t  -0.5674078616440736 \t -0.4398376487694103\n",
            "6      \t [ 0.55198982  4.75264073 14.          0.93528567 13.          0.58376745]. \t  -0.49127876318565455 \t -0.4398376487694103\n",
            "7      \t [ 1.01837104  4.41995744  6.          0.52021829 12.          0.99601116]. \t  -0.4841049369464135 \t -0.4398376487694103\n",
            "8      \t [ 0.54239845  2.74182658 10.          0.793938    8.          0.40512022]. \t  -0.6545634444151911 \t -0.4398376487694103\n",
            "9      \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]. \t  -0.7370447750424807 \t -0.4398376487694103\n",
            "10     \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]. \t  -0.5164100755179035 \t -0.4398376487694103\n",
            "11     \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]. \t  -0.7343026266151267 \t -0.4398376487694103\n",
            "12     \t [ 1.82697381  3.23883023 14.          0.52727974  1.          0.42452427]. \t  -0.668566126531007 \t -0.4398376487694103\n",
            "13     \t [ 3.51322154  8.79998304 14.          0.91142182  1.          0.35103611]. \t  -0.6603269613793542 \t -0.4398376487694103\n",
            "14     \t [ 2.78517086  0.20608894 12.          0.52669069 17.          0.68320382]. \t  -0.5112264951423564 \t -0.4398376487694103\n",
            "15     \t [ 9.90619221  7.05528672  5.          0.91932487 18.          0.63366006]. \t  -0.5240891052988247 \t -0.4398376487694103\n",
            "16     \t [ 8.02810804 10.         13.97951279  1.         12.97951279  1.        ]. \t  \u001b[92m-0.4331549146168022\u001b[0m \t -0.4331549146168022\n",
            "17     \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]. \t  -0.479780992905768 \t -0.4331549146168022\n",
            "18     \t [ 9.6068935   0.80663714  8.          0.73945426 19.          0.81169876]. \t  -0.4767212179608549 \t -0.4331549146168022\n",
            "19     \t [ 7.64837961  0.1568478  14.          0.90745944  9.          0.55147766]. \t  -0.5639262933108221 \t -0.4331549146168022\n",
            "20     \t [9.77613663 2.80327235 8.         0.65089037 2.         0.68605672]. \t  -0.5009688631868908 \t -0.4331549146168022\n",
            "21     \t [ 2.16891361  0.40236972  6.          0.57865056 19.          0.33900997]. \t  -0.6538296947589674 \t -0.4331549146168022\n",
            "22     \t [ 2.39999736  8.25935251 10.          0.76621897 14.          0.97994917]. \t  -0.45897702011719793 \t -0.4331549146168022\n",
            "23     \t [ 9.71937523  0.84081751  8.          0.83815718 13.          0.15657647]. \t  -0.7323525847117764 \t -0.4331549146168022\n",
            "24     \t [8.80668839 9.74974177 8.         0.78186711 8.         0.24236328]. \t  -0.7323744012163753 \t -0.4331549146168022\n",
            "25     \t [2.4937097  5.10954421 6.         0.82084417 5.         0.44962516]. \t  -0.5700816397450084 \t -0.4331549146168022\n",
            "26     \t [ 0.96616103  8.61825128  6.          0.54652057 18.          0.73561745]. \t  -0.49584377474147956 \t -0.4331549146168022\n",
            "27     \t [ 5.67979603  3.81138296 15.          1.          5.9097705   1.        ]. \t  \u001b[92m-0.41977805411781377\u001b[0m \t -0.41977805411781377\n",
            "28     \t [ 9.80915324  4.43988946 11.          0.57733564  9.          0.18237693]. \t  -0.7362250414877497 \t -0.41977805411781377\n",
            "29     \t [10.         10.         15.          1.          3.63320546  1.        ]. \t  \u001b[92m-0.4158575081159315\u001b[0m \t -0.4158575081159315\n",
            "30     \t [ 0.89195001  6.01604215 14.          0.84121292  7.          0.44798682]. \t  -0.5692790270110697 \t -0.4158575081159315\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.460405323615097"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFKuwvS3uzrs",
        "outputId": "29e597dc-5f83-40e2-9019-f06b152b9ce0"
      },
      "source": [
        "end_exact = time.time()\n",
        "end_exact\n",
        "\n",
        "time_exact = end_exact - start_exact\n",
        "time_exact"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "658.2825448513031"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4197ec-2fe7-4a13-b48c-e5ee4250bb2a"
      },
      "source": [
        "rmse_approx = [rmse_approx_1,\n",
        "rmse_approx_2,\n",
        "rmse_approx_3,\n",
        "rmse_approx_4,\n",
        "rmse_approx_5,\n",
        "rmse_approx_6,\n",
        "rmse_approx_7,\n",
        "rmse_approx_8,\n",
        "rmse_approx_9,\n",
        "rmse_approx_10,\n",
        "rmse_approx_11,\n",
        "rmse_approx_12,\n",
        "rmse_approx_13,\n",
        "rmse_approx_14,\n",
        "rmse_approx_15,\n",
        "rmse_approx_16,\n",
        "rmse_approx_17,\n",
        "rmse_approx_18,\n",
        "rmse_approx_19,\n",
        "rmse_approx_20]\n",
        "\n",
        "np.mean(rmse_approx)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.708242555567739"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ53FsWXu3J1",
        "outputId": "d38d2f11-35d9-4a24-bdc0-359dd62f2788"
      },
      "source": [
        "rmse_exact = [rmse_exact_1,\n",
        "rmse_exact_2,\n",
        "rmse_exact_3,\n",
        "rmse_exact_4,\n",
        "rmse_exact_5,\n",
        "rmse_exact_6,\n",
        "rmse_exact_7,\n",
        "rmse_exact_8,\n",
        "rmse_exact_9,\n",
        "rmse_exact_10,\n",
        "rmse_exact_11,\n",
        "rmse_exact_12,\n",
        "rmse_exact_13,\n",
        "rmse_exact_14,\n",
        "rmse_exact_15,\n",
        "rmse_exact_16,\n",
        "rmse_exact_17,\n",
        "rmse_exact_18,\n",
        "rmse_exact_19,\n",
        "rmse_exact_20]\n",
        "\n",
        "np.mean(rmse_exact)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.6168604508491145"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9FOyoH8u5Wx",
        "outputId": "c2a4c9eb-6785-4ccc-dd1d-6263fc282167"
      },
      "source": [
        "min_rmse_approx = min_max_array(rmse_approx)\n",
        "min_rmse_approx, len(min_rmse_approx)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([4.825774204956716,\n",
              "  4.67160405397526,\n",
              "  4.649527586702978,\n",
              "  4.649527586702978,\n",
              "  4.649527586702978,\n",
              "  4.649527586702978,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.499924380514474,\n",
              "  4.454763173494824],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc7473dc-3a82-4488-c94d-24a8df5c0ac7"
      },
      "source": [
        "min_rmse_exact = min_max_array(rmse_exact)\n",
        "min_rmse_exact, len(min_rmse_exact)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([4.636203190294953,\n",
              "  4.632507471550557,\n",
              "  4.632507471550557,\n",
              "  4.632507471550557,\n",
              "  4.622205923248069,\n",
              "  4.622205923248069,\n",
              "  4.58514934982099,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198,\n",
              "  4.427129179249198],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "3fcd26fa-11ab-4ac6-8a30-7a6c13269b94"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_approx, color = 'Green', label='RMSE: GP ERM optimized with Approx GP ERM gradients')\n",
        "plt.plot(min_rmse_exact, color = 'Blue', label='RMSE:  GP ERM optimized with Exact GP dERM gradients', ls='--')# r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold', family = 'Arial') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_approx)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualize!\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bf57d1-e788-4c13-80a1-dc0fb1ec1cf9"
      },
      "source": [
        "time_approx, time_exact\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610.4452085494995, 658.2825448513031)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4265eed3-cc51-4e89-8c3b-3bef6f863e4d"
      },
      "source": [
        "min(min_rmse_exact), min(min_rmse_approx)\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.427129179249198, 4.454763173494824)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [
        ""
      ],
      "execution_count": 81,
      "outputs": []
    }
  ]
}